{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "#df = pd.read_excel('Urut-Data-20Fitur-20Citra-20Sel-20Darah.xlsx', header=0)\n",
    "df = pd.read_excel('Data-20Fitur-20Citra-20Sel-20Darah.xlsx', header=0,sheet_name='Data Fitur Citra Sel Darah2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "head = ['Jenis', 'KIperKP', 'KontrasP', 'Solidity_Inti', 'HomogenitasP',\n",
    "        'Circularity_Inti', 'Keliling_Inti', 'LIperLP ', 'KelilingP',\n",
    "        'EntropiP', 'LuasNormal_P', 'EnergiP', 'Homogenitas_Inti',\n",
    "        'KelilingNormal_I', 'Entropi_Inti', 'Granularity_Inti',\n",
    "        'RerataGP', 'SolidityP', 'Energi_Inti', 'RerataRP',\n",
    "        'RerataR_Inti', 'CircularityP', 'LuasP', 'GranularityP',\n",
    "        'RerataG_Inti', 'RerataBP', 'Eccentricity', 'RerataB_Inti',\n",
    "        'Kontras_Inti', 'Luas_Inti']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k1 =[ 'Luas_Inti','Keliling_Inti']\n",
    "k2 = ['Granularity_Inti','GranularityP']\n",
    "k3 = ['Circularity_Inti','CircularityP','Eccentricity']\n",
    "k4 = ['RerataR_Inti','RerataG_Inti','RerataB_Inti']\n",
    "k5 = ['Solidity_Inti','Entropi_Inti','Energi_Inti','Kontras_Inti','Homogenitas_Inti']\n",
    "k6 = ['LuasP','KelilingP']\n",
    "k7 = ['RerataRP','RerataGP','RerataBP']\n",
    "k8 = ['SolidityP','EntropiP','EnergiP','KontrasP','HomogenitasP']\n",
    "k9 = ['LuasNormal_P','KelilingNormal_I']\n",
    "k10 =[ 'LIperLP ','KIperKP']\n",
    "\n",
    "datset = [k1,k2,k3,k4,k5,k6,k7,k8,k9,k10]\n",
    "\n",
    "#adam\n",
    "#    1          2         3         4         5          6          7          8           9         10\n",
    "#[99.15, 99.15, 99.15, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 99.15]\n",
    "#[88.24, 86.27, 86.27, 88.24, 86.27, 88.24, 88.24, 82.35, 84.31, 86.27]\n",
    "\n",
    "#lbfgs\n",
    "#    1          2         3         4         5          6          7          8           9         10\n",
    "#[100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0]\n",
    "#[90.2, 84.31, 82.35, 86.27, 90.2, 88.24, 86.27, 80.39, 88.24, 80.39]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tolen= 0\n",
    "for i in range(len(datset)):\n",
    "    tolen = tolen +len(datset[i])\n",
    "print(tolen)\n",
    "len(datset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#lbfgs finish\n",
    "k2 = ['Jenis','Granularity_Inti','GranularityP']\n",
    "k8 = ['Jenis','Granularity_Inti','GranularityP','SolidityP','EntropiP','EnergiP','KontrasP','HomogenitasP']\n",
    "k10 =['Jenis','Granularity_Inti','GranularityP','SolidityP','EntropiP','EnergiP','KontrasP','HomogenitasP', 'LIperLP ','KIperKP']\n",
    "k7 = ['Jenis','Granularity_Inti','GranularityP','SolidityP','EntropiP','EnergiP','KontrasP','HomogenitasP', 'LIperLP ','KIperKP','RerataRP','RerataGP','RerataBP']\n",
    "k4 = ['Jenis','Granularity_Inti','GranularityP','SolidityP','EntropiP','EnergiP','KontrasP','HomogenitasP', 'LIperLP ','KIperKP','RerataRP','RerataGP','RerataBP','RerataR_Inti','RerataG_Inti','RerataB_Inti']\n",
    "k9 = ['Jenis','Granularity_Inti','GranularityP','SolidityP','EntropiP','EnergiP','KontrasP','HomogenitasP', 'LIperLP ','KIperKP','RerataRP','RerataGP','RerataBP','RerataR_Inti','RerataG_Inti','RerataB_Inti','LuasNormal_P','KelilingNormal_I']\n",
    "k3 = ['Jenis','Granularity_Inti','GranularityP','SolidityP','EntropiP','EnergiP','KontrasP','HomogenitasP', 'LIperLP ','KIperKP','RerataRP','RerataGP','RerataBP','RerataR_Inti','RerataG_Inti','RerataB_Inti','LuasNormal_P','KelilingNormal_I','Circularity_Inti','CircularityP','Eccentricity']\n",
    "k1 = [ 'Jenis','Granularity_Inti','GranularityP','SolidityP','EntropiP','EnergiP','KontrasP','HomogenitasP', 'LIperLP ','KIperKP','RerataRP','RerataGP','RerataBP','RerataR_Inti','RerataG_Inti','RerataB_Inti','LuasNormal_P','KelilingNormal_I','Circularity_Inti','CircularityP','Eccentricity','Luas_Inti','Keliling_Inti']\n",
    "k6 = ['Jenis','Granularity_Inti','GranularityP','SolidityP','EntropiP','EnergiP','KontrasP','HomogenitasP', 'LIperLP ','KIperKP','RerataRP','RerataGP','RerataBP','RerataR_Inti','RerataG_Inti','RerataB_Inti','LuasNormal_P','KelilingNormal_I','Circularity_Inti','CircularityP','Eccentricity','Luas_Inti','Keliling_Inti','LuasP','KelilingP']\n",
    "k5 = ['Jenis','Granularity_Inti','GranularityP','SolidityP','EntropiP','EnergiP','KontrasP','HomogenitasP', 'LIperLP ','KIperKP','RerataRP','RerataGP','RerataBP','RerataR_Inti','RerataG_Inti','RerataB_Inti','LuasNormal_P','KelilingNormal_I','Circularity_Inti','CircularityP','Eccentricity','Luas_Inti','Keliling_Inti','LuasP','KelilingP','Solidity_Inti','Entropi_Inti','Energi_Inti','Kontras_Inti','Homogenitas_Inti']\n",
    "\n",
    "datset = [k2, k8, k10, k7, k4, k9, k3, k1, k6, k5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Reordering Columns by name\n",
    "df = pd.read_excel('Urut-Data-20Fitur-20Citra-20Sel-20Darah.xlsx', header=0)\n",
    "df = df[k2]\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([22333, 31025, 36832, 34974, 31828, 23701, 31947, 28686, 28145,\n",
       "       26639, 54900, 37200, 35263, 24821, 32936, 27179, 28187, 40821,\n",
       "       30883, 28100, 35217, 35026, 25218, 41732, 29861, 28558, 30928,\n",
       "       27450, 28391, 23243, 35642, 34159, 26744, 35215, 24559, 25111,\n",
       "       29645, 34941, 29239, 31878, 29096, 46363, 38425, 38508, 29013,\n",
       "       20039, 39126, 33502, 29962, 31247, 35741, 48805, 46334, 44978,\n",
       "       43862, 53046, 43184, 31470, 45508, 48103, 51359, 40934, 53864,\n",
       "       52353, 52080, 50335, 50442, 48755, 47642, 47233, 52077, 21508,\n",
       "       24217, 22615, 23241, 26865, 23915, 26241, 29848, 21213, 26120,\n",
       "       23583, 30839, 28876, 37029, 27191, 27971, 34446, 40094, 37051,\n",
       "       47121, 38332, 30701, 33049, 22332, 35618, 25826, 38926, 21003,\n",
       "       44015, 37634, 40912, 41935, 51278, 52381, 26609, 24340, 24398,\n",
       "       26219, 23057, 23964, 23342, 21365, 27013, 32231, 18785, 21873,\n",
       "       27453, 17420, 20281, 38943, 17616, 24379, 28643, 26880, 28772,\n",
       "       28557, 22772, 28053, 20288, 25075, 25146, 16601, 29893, 26247,\n",
       "       28145, 26884, 29734, 30825, 27735, 23246, 34538, 28092, 22351,\n",
       "       33949, 26293, 32943, 25048, 35055, 25568, 32077, 30445, 21874,\n",
       "       25627, 23815, 33162, 33581, 34914, 41947, 43530, 34076, 30867,\n",
       "       37977, 30674, 33072, 30591, 48803, 35799, 30208], dtype=int64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "daf = pd.read_excel('Urut-Data-20Fitur-20Citra-20Sel-20Darah.xlsx', header=0)\n",
    "#df = daf.drop(datset[0], axis=1)\n",
    "print(df[0:0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Empty DataFrame\n",
      "Columns: [Jenis, Solidity_Inti, Granularity_Inti, Circularity_Inti, RerataR_Inti, RerataG_Inti, RerataB_Inti, Entropi_Inti, Energi_Inti, Kontras_Inti, Homogenitas_Inti, LuasP, KelilingP, SolidityP, GranularityP, CircularityP, RerataRP, RerataGP, RerataBP, EntropiP, EnergiP, KontrasP, HomogenitasP, LuasNormal_P, KelilingNormal_I, Eccentricity, LIperLP , KIperKP]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 28 columns]\n",
      "MLPClassifier(activation='relu', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=16, learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=2000, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
      "       solver='lbfgs', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "Akurasi:  91.75\n",
      "SD:  6.04\n",
      "[[ 9  1  0  0  1]\n",
      " [ 1  0  1  0  0]\n",
      " [ 0  0 11  0  1]\n",
      " [ 0  1  1  3  0]\n",
      " [ 0  0  2  0 19]]\n",
      "akurasi latih:  100.0\n",
      "akurasi uji:  82.35\n",
      "\n",
      "1\n",
      "Empty DataFrame\n",
      "Columns: [Jenis, Luas_Inti, Keliling_Inti, Solidity_Inti, Circularity_Inti, RerataR_Inti, RerataG_Inti, RerataB_Inti, Entropi_Inti, Energi_Inti, Kontras_Inti, Homogenitas_Inti, LuasP, KelilingP, SolidityP, CircularityP, RerataRP, RerataGP, RerataBP, EntropiP, EnergiP, KontrasP, HomogenitasP, LuasNormal_P, KelilingNormal_I, Eccentricity, LIperLP , KIperKP]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 28 columns]\n",
      "MLPClassifier(activation='relu', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=16, learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=2000, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
      "       solver='lbfgs', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "Akurasi:  90.99000000000001\n",
      "SD:  6.819999999999999\n",
      "[[10  0  0  0  1]\n",
      " [ 1  0  1  0  0]\n",
      " [ 0  0 11  0  1]\n",
      " [ 0  1  1  3  0]\n",
      " [ 0  0  1  0 20]]\n",
      "akurasi latih:  100.0\n",
      "akurasi uji:  86.27\n",
      "\n",
      "2\n",
      "Empty DataFrame\n",
      "Columns: [Jenis, Luas_Inti, Keliling_Inti, Solidity_Inti, Granularity_Inti, RerataR_Inti, RerataG_Inti, RerataB_Inti, Entropi_Inti, Energi_Inti, Kontras_Inti, Homogenitas_Inti, LuasP, KelilingP, SolidityP, GranularityP, RerataRP, RerataGP, RerataBP, EntropiP, EnergiP, KontrasP, HomogenitasP, LuasNormal_P, KelilingNormal_I, LIperLP , KIperKP]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 27 columns]\n",
      "MLPClassifier(activation='relu', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=16, learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=2000, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
      "       solver='lbfgs', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "Akurasi:  93.53\n",
      "SD:  8.959999999999999\n",
      "[[11  0  0  0  0]\n",
      " [ 1  0  1  0  0]\n",
      " [ 0  0 10  0  2]\n",
      " [ 1  1  0  3  0]\n",
      " [ 0  0  1  0 20]]\n",
      "akurasi latih:  100.0\n",
      "akurasi uji:  86.27\n",
      "\n",
      "3\n",
      "Empty DataFrame\n",
      "Columns: [Jenis, Luas_Inti, Keliling_Inti, Solidity_Inti, Granularity_Inti, Circularity_Inti, Entropi_Inti, Energi_Inti, Kontras_Inti, Homogenitas_Inti, LuasP, KelilingP, SolidityP, GranularityP, CircularityP, RerataRP, RerataGP, RerataBP, EntropiP, EnergiP, KontrasP, HomogenitasP, LuasNormal_P, KelilingNormal_I, Eccentricity, LIperLP , KIperKP]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 27 columns]\n",
      "MLPClassifier(activation='relu', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=16, learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=2000, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
      "       solver='lbfgs', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "Akurasi:  91.02\n",
      "SD:  8.44\n",
      "[[ 9  2  0  0  0]\n",
      " [ 1  0  1  0  0]\n",
      " [ 0  0 11  0  1]\n",
      " [ 0  1  1  3  0]\n",
      " [ 0  0  2  0 19]]\n",
      "akurasi latih:  100.0\n",
      "akurasi uji:  82.35\n",
      "\n",
      "4\n",
      "Empty DataFrame\n",
      "Columns: [Jenis, Luas_Inti, Keliling_Inti, Granularity_Inti, Circularity_Inti, RerataR_Inti, RerataG_Inti, RerataB_Inti, LuasP, KelilingP, SolidityP, GranularityP, CircularityP, RerataRP, RerataGP, RerataBP, EntropiP, EnergiP, KontrasP, HomogenitasP, LuasNormal_P, KelilingNormal_I, Eccentricity, LIperLP , KIperKP]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 25 columns]\n",
      "MLPClassifier(activation='relu', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=16, learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=2000, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
      "       solver='lbfgs', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "Akurasi:  92.66\n",
      "SD:  7.35\n",
      "[[ 9  2  0  0  0]\n",
      " [ 1  0  1  0  0]\n",
      " [ 0  0 11  0  1]\n",
      " [ 1  1  1  2  0]\n",
      " [ 0  0  1  0 20]]\n",
      "akurasi latih:  100.0\n",
      "akurasi uji:  82.35\n",
      "\n",
      "5\n",
      "Empty DataFrame\n",
      "Columns: [Jenis, Luas_Inti, Keliling_Inti, Solidity_Inti, Granularity_Inti, Circularity_Inti, RerataR_Inti, RerataG_Inti, RerataB_Inti, Entropi_Inti, Energi_Inti, Kontras_Inti, Homogenitas_Inti, SolidityP, GranularityP, CircularityP, RerataRP, RerataGP, RerataBP, EntropiP, EnergiP, KontrasP, HomogenitasP, LuasNormal_P, KelilingNormal_I, Eccentricity, LIperLP , KIperKP]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 28 columns]\n",
      "MLPClassifier(activation='relu', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=16, learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=2000, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
      "       solver='lbfgs', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "Akurasi:  91.67999999999999\n",
      "SD:  4.22\n",
      "[[ 9  1  0  0  1]\n",
      " [ 1  0  1  0  0]\n",
      " [ 0  0 11  0  1]\n",
      " [ 0  0  2  3  0]\n",
      " [ 0  0  2  0 19]]\n",
      "akurasi latih:  100.0\n",
      "akurasi uji:  82.35\n",
      "\n",
      "6\n",
      "Empty DataFrame\n",
      "Columns: [Jenis, Luas_Inti, Keliling_Inti, Solidity_Inti, Granularity_Inti, Circularity_Inti, RerataR_Inti, RerataG_Inti, RerataB_Inti, Entropi_Inti, Energi_Inti, Kontras_Inti, Homogenitas_Inti, LuasP, KelilingP, SolidityP, GranularityP, CircularityP, EntropiP, EnergiP, KontrasP, HomogenitasP, LuasNormal_P, KelilingNormal_I, Eccentricity, LIperLP , KIperKP]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 27 columns]\n",
      "MLPClassifier(activation='relu', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=16, learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=2000, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
      "       solver='lbfgs', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "Akurasi:  90.81\n",
      "SD:  4.64\n",
      "[[ 8  3  0  0  0]\n",
      " [ 1  0  1  0  0]\n",
      " [ 0  0 10  1  1]\n",
      " [ 0  1  1  3  0]\n",
      " [ 0  0  1  0 20]]\n",
      "akurasi latih:  100.0\n",
      "akurasi uji:  80.39\n",
      "\n",
      "7\n",
      "Empty DataFrame\n",
      "Columns: [Jenis, Luas_Inti, Keliling_Inti, Solidity_Inti, Granularity_Inti, Circularity_Inti, RerataR_Inti, RerataG_Inti, RerataB_Inti, Entropi_Inti, Energi_Inti, Kontras_Inti, Homogenitas_Inti, LuasP, KelilingP, GranularityP, CircularityP, RerataRP, RerataGP, RerataBP, LuasNormal_P, KelilingNormal_I, Eccentricity, LIperLP , KIperKP]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 25 columns]\n",
      "MLPClassifier(activation='relu', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=16, learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=2000, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
      "       solver='lbfgs', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "Akurasi:  90.08\n",
      "SD:  7.26\n",
      "[[10  1  0  0  0]\n",
      " [ 1  0  1  0  0]\n",
      " [ 0  0 11  0  1]\n",
      " [ 0  1  1  3  0]\n",
      " [ 0  0  1  0 20]]\n",
      "akurasi latih:  100.0\n",
      "akurasi uji:  86.27\n",
      "\n",
      "8\n",
      "Empty DataFrame\n",
      "Columns: [Jenis, Luas_Inti, Keliling_Inti, Solidity_Inti, Granularity_Inti, Circularity_Inti, RerataR_Inti, RerataG_Inti, RerataB_Inti, Entropi_Inti, Energi_Inti, Kontras_Inti, Homogenitas_Inti, LuasP, KelilingP, SolidityP, GranularityP, CircularityP, RerataRP, RerataGP, RerataBP, EntropiP, EnergiP, KontrasP, HomogenitasP, Eccentricity, LIperLP , KIperKP]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 28 columns]\n",
      "MLPClassifier(activation='relu', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=16, learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=2000, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
      "       solver='lbfgs', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "Akurasi:  91.75\n",
      "SD:  6.63\n",
      "[[ 8  3  0  0  0]\n",
      " [ 1  0  1  0  0]\n",
      " [ 0  0 10  1  1]\n",
      " [ 0  2  0  3  0]\n",
      " [ 0  0  1  0 20]]\n",
      "akurasi latih:  100.0\n",
      "akurasi uji:  80.39\n",
      "\n",
      "9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Jenis, Luas_Inti, Keliling_Inti, Solidity_Inti, Granularity_Inti, Circularity_Inti, RerataR_Inti, RerataG_Inti, RerataB_Inti, Entropi_Inti, Energi_Inti, Kontras_Inti, Homogenitas_Inti, LuasP, KelilingP, SolidityP, GranularityP, CircularityP, RerataRP, RerataGP, RerataBP, EntropiP, EnergiP, KontrasP, HomogenitasP, LuasNormal_P, KelilingNormal_I, Eccentricity]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 28 columns]\n",
      "MLPClassifier(activation='relu', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=16, learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=2000, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
      "       solver='lbfgs', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "Akurasi:  93.42\n",
      "SD:  6.92\n",
      "[[ 8  3  0  0  0]\n",
      " [ 1  0  1  0  0]\n",
      " [ 0  0 10  1  1]\n",
      " [ 0  2  0  3  0]\n",
      " [ 1  0  1  0 19]]\n",
      "akurasi latih:  100.0\n",
      "akurasi uji:  78.43\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train = [ ]\n",
    "test = [ ]\n",
    "cv_score = [ ]\n",
    "cv_std = [ ]\n",
    "for i in range(10):\n",
    "    print(i)\n",
    "    import pandas as pd\n",
    "    daf = pd.read_excel('Data-20Fitur-20Citra-20Sel-20Darah.xlsx', header=0, sheet_name ='Data Fitur Citra Sel Darah2')\n",
    "    df = daf.drop(datset[i], axis=1)\n",
    "    #df = daf[datset[i]]\n",
    "    print(df[0:0])\n",
    "\n",
    "    import numpy as np\n",
    "    y= np.array(df)[:,0]           #membuat dataset target y\n",
    "    X = np.array(df)[:,1:30]    #membuat dataset input X\n",
    "\n",
    "    # Pisahkan dataset menjadi data latih dan uji dengan perbandingan 80:20\n",
    "    from sklearn.cross_validation import train_test_split\n",
    "    X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.30, random_state=0)\n",
    "\n",
    "    # Penyekalaan fitur dilakukan pada data latih dan uji.\n",
    "    # Detail kenapa ini penting dijelaskan di sini: http://scikit-learn.org/stable/auto_examples/preprocessing/plot_scaling_importance.html\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    sc = StandardScaler()\n",
    "\n",
    "    # Fungsi fit_transform hanya dilakukan di data latih\n",
    "    X_train = sc.fit_transform(X_train)\n",
    "    X_test = sc.transform(X_test)\n",
    "\n",
    "    # Latih kecerdasan buatan dengan data latih, menggunakan MLP-NN\n",
    "    from sklearn.neural_network import MLPClassifier\n",
    "    import time\n",
    "\n",
    "    clf = MLPClassifier(activation='relu',solver='lbfgs', alpha=1e-5, max_iter=2000,\n",
    "                hidden_layer_sizes=(16), random_state=1)\n",
    "    start = time.time()\n",
    "    print(clf.fit(X_train, y_train))\n",
    "    end = time.time()\n",
    "    waktuTrain = end - start\n",
    "\n",
    "    from sklearn.model_selection import cross_val_score\n",
    "    scoring='accuracy'\n",
    "    accuracies = cross_val_score(estimator=clf, X=X_train, y=y_train, cv=5,scoring=scoring)\n",
    "    avg_accuracy = float('{0:.4f}'.format(accuracies.mean()))*100\n",
    "    std_accuracy =  float('{0:.4f}'.format(accuracies.std()))*100\n",
    "    print('Akurasi: ', avg_accuracy)\n",
    "    print('SD: ', std_accuracy)\n",
    "\n",
    "    #prediksi\n",
    "    start = time.time()\n",
    "    result = clf.predict(X_test)\n",
    "    end = time.time()\n",
    "    waktuTest = end - start\n",
    "\n",
    "    #Confusion Matriks Hasil Prediksi dengan Nilai Sebenarnya\n",
    "    from sklearn.metrics import classification_report,confusion_matrix, roc_auc_score\n",
    "    print(confusion_matrix(y_test,result))\n",
    "\n",
    "    # Cek kemampuan kecerdasan buatan dengan data uji \n",
    "    train_accuracy = float('{0:.4f}'.format(clf.score(X_train, y_train)))*100\n",
    "    print(\"akurasi latih: \",train_accuracy)\n",
    "\n",
    "    # Cek kemampuan kecerdasan buatan dengan data uji \n",
    "    test_accuracy = float('{0:.4f}'.format(clf.score(X_test, y_test)))*100\n",
    "    print(\"akurasi uji: \",test_accuracy)\n",
    "\n",
    "    train.append(train_accuracy)\n",
    "    cv_score.append(avg_accuracy)\n",
    "    cv_std.append(std_accuracy)\n",
    "    test.append(test_accuracy)\n",
    "    print()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#lbfgs finish\n",
    "k2 = ['Jenis','Granularity_Inti','GranularityP']\n",
    "k8 = ['Jenis','Granularity_Inti','GranularityP','SolidityP','EntropiP','EnergiP','KontrasP','HomogenitasP']\n",
    "k10 =['Jenis','Granularity_Inti','GranularityP','SolidityP','EntropiP','EnergiP','KontrasP','HomogenitasP', 'LIperLP ','KIperKP']\n",
    "k7 = ['Jenis','Granularity_Inti','GranularityP','SolidityP','EntropiP','EnergiP','KontrasP','HomogenitasP', 'LIperLP ','KIperKP','RerataRP','RerataGP','RerataBP']\n",
    "k4 = ['Jenis','Granularity_Inti','GranularityP','SolidityP','EntropiP','EnergiP','KontrasP','HomogenitasP', 'LIperLP ','KIperKP','RerataRP','RerataGP','RerataBP','RerataR_Inti','RerataG_Inti','RerataB_Inti']\n",
    "k9 = ['Jenis','Granularity_Inti','GranularityP','SolidityP','EntropiP','EnergiP','KontrasP','HomogenitasP', 'LIperLP ','KIperKP','RerataRP','RerataGP','RerataBP','RerataR_Inti','RerataG_Inti','RerataB_Inti','LuasNormal_P','KelilingNormal_I']\n",
    "k3 = ['Jenis','Granularity_Inti','GranularityP','SolidityP','EntropiP','EnergiP','KontrasP','HomogenitasP', 'LIperLP ','KIperKP','RerataRP','RerataGP','RerataBP','RerataR_Inti','RerataG_Inti','RerataB_Inti','LuasNormal_P','KelilingNormal_I','Circularity_Inti','CircularityP','Eccentricity']\n",
    "k1 =[ 'Jenis','Granularity_Inti','GranularityP','SolidityP','EntropiP','EnergiP','KontrasP','HomogenitasP', 'LIperLP ','KIperKP','RerataRP','RerataGP','RerataBP','RerataR_Inti','RerataG_Inti','RerataB_Inti','LuasNormal_P','KelilingNormal_I','Circularity_Inti','CircularityP','Eccentricity','Luas_Inti','Keliling_Inti']\n",
    "k6 = ['Jenis','Granularity_Inti','GranularityP','SolidityP','EntropiP','EnergiP','KontrasP','HomogenitasP', 'LIperLP ','KIperKP','RerataRP','RerataGP','RerataBP','RerataR_Inti','RerataG_Inti','RerataB_Inti','LuasNormal_P','KelilingNormal_I','Circularity_Inti','CircularityP','Eccentricity','Luas_Inti','Keliling_Inti','LuasP','KelilingP']\n",
    "k5 = ['Jenis','Granularity_Inti','GranularityP','SolidityP','EntropiP','EnergiP','KontrasP','HomogenitasP', 'LIperLP ','KIperKP','RerataRP','RerataGP','RerataBP','RerataR_Inti','RerataG_Inti','RerataB_Inti','LuasNormal_P','KelilingNormal_I','Circularity_Inti','CircularityP','Eccentricity','Luas_Inti','Keliling_Inti','LuasP','KelilingP','Solidity_Inti','Entropi_Inti','Energi_Inti','Kontras_Inti','Homogenitas_Inti']\n",
    "\n",
    "datset = [k2, k8, k10, k7, k4, k9, k3, k1, k6, k5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Jenis, Granularity_Inti, GranularityP, SolidityP, EntropiP, EnergiP, KontrasP, HomogenitasP, LIperLP , KIperKP, RerataRP, RerataGP, RerataBP, RerataR_Inti, RerataG_Inti, RerataB_Inti]\n",
      "Index: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramFiles\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier(activation='relu', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=10, learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=2000, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
      "       solver='lbfgs', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "Loss Pelatihan :  8.69554580262e-05\n",
      "Jumlah iterasi :  30\n",
      "Akurasi:  88.37\n",
      "SD:  8.36\n",
      "[[11  0  0  0  0]\n",
      " [ 1  1  0  0  0]\n",
      " [ 0  0 10  0  2]\n",
      " [ 0  0  0  5  0]\n",
      " [ 1  0  1  0 19]]\n",
      "Akurasi Data Uji: 0.901960784314 = 0.901960784314\n",
      "Akurasi Data Latih: 1.0\n",
      "\n",
      "MLPClassifier(activation='relu', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=11, learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=2000, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
      "       solver='lbfgs', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "Loss Pelatihan :  4.89246515627e-05\n",
      "Jumlah iterasi :  21\n",
      "Akurasi:  87.42999999999999\n",
      "SD:  7.13\n",
      "[[11  0  0  0  0]\n",
      " [ 1  0  1  0  0]\n",
      " [ 1  0 11  0  0]\n",
      " [ 1  0  0  4  0]\n",
      " [ 1  0  1  0 19]]\n",
      "Akurasi Data Uji: 0.882352941176 = 0.882352941176\n",
      "Akurasi Data Latih: 1.0\n",
      "\n",
      "MLPClassifier(activation='relu', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=12, learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=2000, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
      "       solver='lbfgs', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "Loss Pelatihan :  4.338393318e-05\n",
      "Jumlah iterasi :  25\n",
      "Akurasi:  87.5\n",
      "SD:  7.76\n",
      "[[10  1  0  0  0]\n",
      " [ 1  1  0  0  0]\n",
      " [ 1  0 11  0  0]\n",
      " [ 0  0  0  5  0]\n",
      " [ 1  0  1  0 19]]\n",
      "Akurasi Data Uji: 0.901960784314 = 0.901960784314\n",
      "Akurasi Data Latih: 1.0\n",
      "\n",
      "MLPClassifier(activation='relu', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=13, learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=2000, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
      "       solver='lbfgs', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "Loss Pelatihan :  6.51667851597e-05\n",
      "Jumlah iterasi :  23\n",
      "Akurasi:  84.82\n",
      "SD:  8.33\n",
      "[[11  0  0  0  0]\n",
      " [ 1  0  1  0  0]\n",
      " [ 0  0 11  0  1]\n",
      " [ 1  0  0  4  0]\n",
      " [ 1  0  1  0 19]]\n",
      "Akurasi Data Uji: 0.882352941176 = 0.882352941176\n",
      "Akurasi Data Latih: 1.0\n",
      "\n",
      "MLPClassifier(activation='relu', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=14, learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=2000, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
      "       solver='lbfgs', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "Loss Pelatihan :  8.86197180709e-05\n",
      "Jumlah iterasi :  33\n",
      "Akurasi:  89.24\n",
      "SD:  8.83\n",
      "[[11  0  0  0  0]\n",
      " [ 0  2  0  0  0]\n",
      " [ 0  0 10  0  2]\n",
      " [ 0  0  0  5  0]\n",
      " [ 0  0  1  0 20]]\n",
      "Akurasi Data Uji: 0.941176470588 = 0.941176470588\n",
      "Akurasi Data Latih: 1.0\n",
      "\n",
      "MLPClassifier(activation='relu', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=15, learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=2000, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
      "       solver='lbfgs', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "Loss Pelatihan :  6.87224207849e-05\n",
      "Jumlah iterasi :  27\n",
      "Akurasi:  85.76\n",
      "SD:  7.6899999999999995\n",
      "[[11  0  0  0  0]\n",
      " [ 1  1  0  0  0]\n",
      " [ 0  0 11  0  1]\n",
      " [ 0  0  0  5  0]\n",
      " [ 0  0  1  0 20]]\n",
      "Akurasi Data Uji: 0.941176470588 = 0.941176470588\n",
      "Akurasi Data Latih: 1.0\n",
      "\n",
      "MLPClassifier(activation='relu', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=16, learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=2000, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
      "       solver='lbfgs', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "Loss Pelatihan :  8.66925361936e-05\n",
      "Jumlah iterasi :  24\n",
      "Akurasi:  88.38000000000001\n",
      "SD:  9.56\n",
      "[[11  0  0  0  0]\n",
      " [ 0  2  0  0  0]\n",
      " [ 0  0 11  0  1]\n",
      " [ 0  0  0  5  0]\n",
      " [ 1  0  1  0 19]]\n",
      "Akurasi Data Uji: 0.941176470588 = 0.941176470588\n",
      "Akurasi Data Latih: 1.0\n",
      "\n",
      "MLPClassifier(activation='relu', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=17, learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=2000, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
      "       solver='lbfgs', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "Loss Pelatihan :  6.89341019945e-05\n",
      "Jumlah iterasi :  21\n",
      "Akurasi:  87.58\n",
      "SD:  9.139999999999999\n",
      "[[11  0  0  0  0]\n",
      " [ 1  0  1  0  0]\n",
      " [ 0  0 11  0  1]\n",
      " [ 0  0  0  5  0]\n",
      " [ 0  0  1  0 20]]\n",
      "Akurasi Data Uji: 0.921568627451 = 0.921568627451\n",
      "Akurasi Data Latih: 1.0\n",
      "\n",
      "MLPClassifier(activation='relu', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=18, learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=2000, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
      "       solver='lbfgs', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "Loss Pelatihan :  5.7325626373e-05\n",
      "Jumlah iterasi :  26\n",
      "Akurasi:  85.76\n",
      "SD:  7.180000000000001\n",
      "[[11  0  0  0  0]\n",
      " [ 1  0  1  0  0]\n",
      " [ 0  0 10  0  2]\n",
      " [ 0  0  0  5  0]\n",
      " [ 0  0  1  0 20]]\n",
      "Akurasi Data Uji: 0.901960784314 = 0.901960784314\n",
      "Akurasi Data Latih: 1.0\n",
      "\n",
      "MLPClassifier(activation='relu', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=19, learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=2000, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
      "       solver='lbfgs', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "Loss Pelatihan :  0.000108223554422\n",
      "Jumlah iterasi :  21\n",
      "Akurasi:  88.37\n",
      "SD:  8.36\n",
      "[[11  0  0  0  0]\n",
      " [ 1  1  0  0  0]\n",
      " [ 0  0 10  1  1]\n",
      " [ 0  0  0  5  0]\n",
      " [ 0  0  1  0 20]]\n",
      "Akurasi Data Uji: 0.921568627451 = 0.921568627451\n",
      "Akurasi Data Latih: 1.0\n",
      "\n",
      "MLPClassifier(activation='relu', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=20, learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=2000, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
      "       solver='lbfgs', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "Loss Pelatihan :  6.0471417583e-05\n",
      "Jumlah iterasi :  26\n",
      "Akurasi:  89.25\n",
      "SD:  7.85\n",
      "[[11  0  0  0  0]\n",
      " [ 1  1  0  0  0]\n",
      " [ 0  0 10  0  2]\n",
      " [ 0  0  0  5  0]\n",
      " [ 0  0  1  0 20]]\n",
      "Akurasi Data Uji: 0.921568627451 = 0.921568627451\n",
      "Akurasi Data Latih: 1.0\n",
      "\n",
      "MLPClassifier(activation='relu', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=21, learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=2000, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
      "       solver='lbfgs', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "Loss Pelatihan :  4.02981939173e-05\n",
      "Jumlah iterasi :  26\n",
      "Akurasi:  86.63\n",
      "SD:  7.53\n",
      "[[11  0  0  0  0]\n",
      " [ 1  0  1  0  0]\n",
      " [ 0  0 11  0  1]\n",
      " [ 0  0  0  5  0]\n",
      " [ 0  0  1  0 20]]\n",
      "Akurasi Data Uji: 0.921568627451 = 0.921568627451\n",
      "Akurasi Data Latih: 1.0\n",
      "\n",
      "MLPClassifier(activation='relu', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=22, learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=2000, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
      "       solver='lbfgs', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "Loss Pelatihan :  6.44600436546e-05\n",
      "Jumlah iterasi :  25\n",
      "Akurasi:  88.37\n",
      "SD:  8.36\n",
      "[[11  0  0  0  0]\n",
      " [ 1  1  0  0  0]\n",
      " [ 1  0 11  0  0]\n",
      " [ 1  0  0  4  0]\n",
      " [ 1  0  1  0 19]]\n",
      "Akurasi Data Uji: 0.901960784314 = 0.901960784314\n",
      "Akurasi Data Latih: 1.0\n",
      "\n",
      "MLPClassifier(activation='relu', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=23, learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=2000, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
      "       solver='lbfgs', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "Loss Pelatihan :  5.5805754052e-05\n",
      "Jumlah iterasi :  21\n",
      "Akurasi:  88.41\n",
      "SD:  8.790000000000001\n",
      "[[11  0  0  0  0]\n",
      " [ 1  1  0  0  0]\n",
      " [ 0  0 10  0  2]\n",
      " [ 0  0  0  5  0]\n",
      " [ 0  0  1  0 20]]\n",
      "Akurasi Data Uji: 0.921568627451 = 0.921568627451\n",
      "Akurasi Data Latih: 1.0\n",
      "\n",
      "MLPClassifier(activation='relu', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=24, learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=2000, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
      "       solver='lbfgs', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "Loss Pelatihan :  5.77695067128e-05\n",
      "Jumlah iterasi :  22\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Akurasi:  87.47\n",
      "SD:  6.58\n",
      "[[11  0  0  0  0]\n",
      " [ 1  1  0  0  0]\n",
      " [ 0  0 11  0  1]\n",
      " [ 1  0  0  4  0]\n",
      " [ 1  0  1  0 19]]\n",
      "Akurasi Data Uji: 0.901960784314 = 0.901960784314\n",
      "Akurasi Data Latih: 1.0\n",
      "\n",
      "MLPClassifier(activation='relu', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=25, learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=2000, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
      "       solver='lbfgs', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "Loss Pelatihan :  8.58342460209e-05\n",
      "Jumlah iterasi :  24\n",
      "Akurasi:  90.99000000000001\n",
      "SD:  8.110000000000001\n",
      "[[11  0  0  0  0]\n",
      " [ 0  2  0  0  0]\n",
      " [ 0  0 11  0  1]\n",
      " [ 1  0  0  4  0]\n",
      " [ 1  0  1  0 19]]\n",
      "Akurasi Data Uji: 0.921568627451 = 0.921568627451\n",
      "Akurasi Data Latih: 1.0\n",
      "\n",
      "MLPClassifier(activation='relu', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=26, learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=2000, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
      "       solver='lbfgs', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "Loss Pelatihan :  5.21263457331e-05\n",
      "Jumlah iterasi :  22\n",
      "Akurasi:  89.17\n",
      "SD:  6.800000000000001\n",
      "[[11  0  0  0  0]\n",
      " [ 1  1  0  0  0]\n",
      " [ 0  0 10  0  2]\n",
      " [ 0  0  0  5  0]\n",
      " [ 1  0  1  0 19]]\n",
      "Akurasi Data Uji: 0.901960784314 = 0.901960784314\n",
      "Akurasi Data Latih: 1.0\n",
      "\n",
      "MLPClassifier(activation='relu', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=27, learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=2000, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
      "       solver='lbfgs', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "Loss Pelatihan :  5.71362063673e-05\n",
      "Jumlah iterasi :  23\n",
      "Akurasi:  88.41\n",
      "SD:  8.35\n",
      "[[11  0  0  0  0]\n",
      " [ 1  1  0  0  0]\n",
      " [ 0  0 11  0  1]\n",
      " [ 1  0  1  3  0]\n",
      " [ 1  0  1  0 19]]\n",
      "Akurasi Data Uji: 0.882352941176 = 0.882352941176\n",
      "Akurasi Data Latih: 1.0\n",
      "\n",
      "MLPClassifier(activation='relu', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=28, learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=2000, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
      "       solver='lbfgs', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "Loss Pelatihan :  8.87600332473e-05\n",
      "Jumlah iterasi :  21\n",
      "Akurasi:  88.34\n",
      "SD:  6.74\n",
      "[[11  0  0  0  0]\n",
      " [ 1  1  0  0  0]\n",
      " [ 0  0 11  0  1]\n",
      " [ 1  0  0  4  0]\n",
      " [ 0  0  1  0 20]]\n",
      "Akurasi Data Uji: 0.921568627451 = 0.921568627451\n",
      "Akurasi Data Latih: 1.0\n",
      "\n",
      "MLPClassifier(activation='relu', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=29, learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=2000, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
      "       solver='lbfgs', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "Loss Pelatihan :  5.33039571303e-05\n",
      "Jumlah iterasi :  23\n",
      "Akurasi:  90.08\n",
      "SD:  7.26\n",
      "[[11  0  0  0  0]\n",
      " [ 1  1  0  0  0]\n",
      " [ 0  0 11  0  1]\n",
      " [ 1  0  0  4  0]\n",
      " [ 1  0  1  0 19]]\n",
      "Akurasi Data Uji: 0.901960784314 = 0.901960784314\n",
      "Akurasi Data Latih: 1.0\n",
      "\n",
      "MLPClassifier(activation='relu', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=30, learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=2000, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
      "       solver='lbfgs', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "Loss Pelatihan :  5.16119794042e-05\n",
      "Jumlah iterasi :  24\n",
      "Akurasi:  89.32\n",
      "SD:  9.26\n",
      "[[11  0  0  0  0]\n",
      " [ 1  1  0  0  0]\n",
      " [ 0  0 11  0  1]\n",
      " [ 0  0  0  5  0]\n",
      " [ 1  0  1  0 19]]\n",
      "Akurasi Data Uji: 0.921568627451 = 0.921568627451\n",
      "Akurasi Data Latih: 1.0\n",
      "\n",
      "MLPClassifier(activation='relu', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=35, learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=2000, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
      "       solver='lbfgs', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "Loss Pelatihan :  8.37587755399e-05\n",
      "Jumlah iterasi :  21\n",
      "Akurasi:  88.34\n",
      "SD:  6.74\n",
      "[[11  0  0  0  0]\n",
      " [ 1  1  0  0  0]\n",
      " [ 0  0 10  0  2]\n",
      " [ 0  0  0  5  0]\n",
      " [ 0  0  1  0 20]]\n",
      "Akurasi Data Uji: 0.921568627451 = 0.921568627451\n",
      "Akurasi Data Latih: 1.0\n",
      "\n",
      "MLPClassifier(activation='relu', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=40, learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=2000, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
      "       solver='lbfgs', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "Loss Pelatihan :  6.78707084406e-05\n",
      "Jumlah iterasi :  21\n",
      "Akurasi:  90.99000000000001\n",
      "SD:  8.110000000000001\n",
      "[[11  0  0  0  0]\n",
      " [ 1  1  0  0  0]\n",
      " [ 0  0 11  0  1]\n",
      " [ 1  0  0  4  0]\n",
      " [ 1  0  1  0 19]]\n",
      "Akurasi Data Uji: 0.901960784314 = 0.901960784314\n",
      "Akurasi Data Latih: 1.0\n",
      "\n",
      "MLPClassifier(activation='relu', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=45, learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=2000, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
      "       solver='lbfgs', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "Loss Pelatihan :  4.13612358796e-05\n",
      "Jumlah iterasi :  23\n",
      "Akurasi:  89.24\n",
      "SD:  9.25\n",
      "[[11  0  0  0  0]\n",
      " [ 1  1  0  0  0]\n",
      " [ 0  0 11  0  1]\n",
      " [ 1  0  0  4  0]\n",
      " [ 1  0  1  0 19]]\n",
      "Akurasi Data Uji: 0.901960784314 = 0.901960784314\n",
      "Akurasi Data Latih: 1.0\n",
      "\n",
      "MLPClassifier(activation='relu', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=50, learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=2000, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
      "       solver='lbfgs', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "Loss Pelatihan :  5.31852379572e-05\n",
      "Jumlah iterasi :  22\n",
      "Akurasi:  89.32\n",
      "SD:  9.66\n",
      "[[11  0  0  0  0]\n",
      " [ 1  1  0  0  0]\n",
      " [ 0  0 10  0  2]\n",
      " [ 0  0  1  4  0]\n",
      " [ 1  0  1  0 19]]\n",
      "Akurasi Data Uji: 0.882352941176 = 0.882352941176\n",
      "Akurasi Data Latih: 1.0\n",
      "\n",
      "MLPClassifier(activation='relu', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=55, learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=2000, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
      "       solver='lbfgs', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "Loss Pelatihan :  6.42457480246e-05\n",
      "Jumlah iterasi :  20\n",
      "Akurasi:  88.38000000000001\n",
      "SD:  9.56\n",
      "[[11  0  0  0  0]\n",
      " [ 1  1  0  0  0]\n",
      " [ 0  0 11  0  1]\n",
      " [ 0  0  1  4  0]\n",
      " [ 0  0  1  0 20]]\n",
      "Akurasi Data Uji: 0.921568627451 = 0.921568627451\n",
      "Akurasi Data Latih: 1.0\n",
      "\n",
      "MLPClassifier(activation='relu', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=60, learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=2000, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
      "       solver='lbfgs', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "Loss Pelatihan :  0.000184129830026\n",
      "Jumlah iterasi :  18\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Akurasi:  86.63\n",
      "SD:  8.469999999999999\n",
      "[[11  0  0  0  0]\n",
      " [ 1  1  0  0  0]\n",
      " [ 0  0 10  0  2]\n",
      " [ 0  0  1  4  0]\n",
      " [ 0  0  1  0 20]]\n",
      "Akurasi Data Uji: 0.901960784314 = 0.901960784314\n",
      "Akurasi Data Latih: 1.0\n",
      "\n",
      "MLPClassifier(activation='relu', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=65, learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=2000, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
      "       solver='lbfgs', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "Loss Pelatihan :  0.000115484135106\n",
      "Jumlah iterasi :  23\n",
      "Akurasi:  88.44999999999999\n",
      "SD:  9.24\n",
      "[[11  0  0  0  0]\n",
      " [ 1  1  0  0  0]\n",
      " [ 0  0 10  0  2]\n",
      " [ 0  0  0  5  0]\n",
      " [ 0  0  1  0 20]]\n",
      "Akurasi Data Uji: 0.921568627451 = 0.921568627451\n",
      "Akurasi Data Latih: 1.0\n",
      "\n",
      "MLPClassifier(activation='relu', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=70, learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=2000, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
      "       solver='lbfgs', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "Loss Pelatihan :  8.06338785309e-05\n",
      "Jumlah iterasi :  23\n",
      "Akurasi:  88.37\n",
      "SD:  8.36\n",
      "[[11  0  0  0  0]\n",
      " [ 1  1  0  0  0]\n",
      " [ 0  0 11  0  1]\n",
      " [ 0  0  0  5  0]\n",
      " [ 0  0  1  0 20]]\n",
      "Akurasi Data Uji: 0.941176470588 = 0.941176470588\n",
      "Akurasi Data Latih: 1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Latih kecerdasan buatan dengan data latih, menggunakan MLP-NN\n",
    "import pandas as pd\n",
    "df = pd.read_excel('Data-20Fitur-20Citra-20Sel-20Darah.xlsx', header=0, sheet_name ='Data Fitur Citra Sel Darah2')\n",
    "#df = daf.drop(datset[i], axis=1)\n",
    "df = df[datset[4]]\n",
    "print(df[0:0])\n",
    "\n",
    "import numpy as np\n",
    "y= np.array(df)[:,0]           #membuat dataset target y\n",
    "X = np.array(df)[:,1:30]    #membuat dataset input X\n",
    "\n",
    "# Pisahkan dataset menjadi data latih dan uji dengan perbandingan 80:20\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.30, random_state=0)\n",
    "\n",
    "# Penyekalaan fitur dilakukan pada data latih dan uji.\n",
    "# Detail kenapa ini penting dijelaskan di sini: http://scikit-learn.org/stable/auto_examples/preprocessing/plot_scaling_importance.html\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "\n",
    "# Fungsi fit_transform hanya dilakukan di data latih\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "i=10\n",
    "data = [ ]\n",
    "layers = [ ]\n",
    "loss = [ ]\n",
    "iterasi = [ ]\n",
    "cv_score = [ ]\n",
    "std_cv = [ ]\n",
    "while (i<75):\n",
    "    clf = MLPClassifier(activation='relu',solver='lbfgs', alpha=1e-5, max_iter=2000,\n",
    "                    hidden_layer_sizes=(i), random_state=1)\n",
    "    print(clf.fit(X_train, y_train))\n",
    "    if(i>=30):\n",
    "        i=i+5\n",
    "    elif(i<30):  \n",
    "        i=i+1\n",
    "\n",
    "    print('Loss Pelatihan : ', clf.loss_)    \n",
    "    print('Jumlah iterasi : ', clf.n_iter_)\n",
    "    \n",
    "    from sklearn.model_selection import cross_val_score\n",
    "    scoring='accuracy'\n",
    "    accuracies = cross_val_score(estimator=clf, X=X_train, y=y_train, cv=5,scoring=scoring)\n",
    "    avg_accuracy = float('{0:.4f}'.format(accuracies.mean()))*100\n",
    "    std_accuracy =  float('{0:.4f}'.format(accuracies.std()))*100\n",
    "    print('Akurasi: ', avg_accuracy)\n",
    "    print('SD: ', std_accuracy)\n",
    "    \n",
    "    #Prediksi Data Uji\n",
    "    result = clf.predict(X_test)\n",
    "\n",
    "    #Confusion Matriks Hasil Prediksi dengan Nilai Sebenarnya\n",
    "    from sklearn.metrics import classification_report,confusion_matrix\n",
    "    print(confusion_matrix(y_test,result))\n",
    "\n",
    "    # Cek kemampuan kecerdasan buatan dengan data uji \n",
    "    test_accuracy = clf.score(X_test, y_test)\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    akurasi = accuracy_score(y_test, result)\n",
    "    print('Akurasi Data Uji:', test_accuracy , '=', akurasi)\n",
    "\n",
    "    # Cek kemampuan kecerdasan buatan dengan data uji \n",
    "    train_accuracy = clf.score(X_train, y_train)\n",
    "    print('Akurasi Data Latih:', train_accuracy)  \n",
    "\n",
    "    layers.append(i)\n",
    "    data.append( float('{0:.4f}'.format(test_accuracy))*100)\n",
    "    loss.append(clf.loss_)\n",
    "    iterasi.append(clf.n_iter_)\n",
    "    cv_score.append(avg_accuracy)\n",
    "    std_cv.append(std_accuracy)\n",
    "    print()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neuron</th>\n",
       "      <th>akurasi</th>\n",
       "      <th>loss</th>\n",
       "      <th>iter</th>\n",
       "      <th>cv</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11.0</td>\n",
       "      <td>90.20</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>30.0</td>\n",
       "      <td>88.37</td>\n",
       "      <td>8.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12.0</td>\n",
       "      <td>88.24</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>21.0</td>\n",
       "      <td>87.43</td>\n",
       "      <td>7.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.0</td>\n",
       "      <td>90.20</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>25.0</td>\n",
       "      <td>87.50</td>\n",
       "      <td>7.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.0</td>\n",
       "      <td>88.24</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>23.0</td>\n",
       "      <td>84.82</td>\n",
       "      <td>8.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15.0</td>\n",
       "      <td>94.12</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>33.0</td>\n",
       "      <td>89.24</td>\n",
       "      <td>8.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>16.0</td>\n",
       "      <td>94.12</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>27.0</td>\n",
       "      <td>85.76</td>\n",
       "      <td>7.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>17.0</td>\n",
       "      <td>94.12</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>24.0</td>\n",
       "      <td>88.38</td>\n",
       "      <td>9.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>18.0</td>\n",
       "      <td>92.16</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>21.0</td>\n",
       "      <td>87.58</td>\n",
       "      <td>9.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>19.0</td>\n",
       "      <td>90.20</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>26.0</td>\n",
       "      <td>85.76</td>\n",
       "      <td>7.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>20.0</td>\n",
       "      <td>92.16</td>\n",
       "      <td>0.000108</td>\n",
       "      <td>21.0</td>\n",
       "      <td>88.37</td>\n",
       "      <td>8.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>21.0</td>\n",
       "      <td>92.16</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>26.0</td>\n",
       "      <td>89.25</td>\n",
       "      <td>7.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>22.0</td>\n",
       "      <td>92.16</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>26.0</td>\n",
       "      <td>86.63</td>\n",
       "      <td>7.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>23.0</td>\n",
       "      <td>90.20</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>25.0</td>\n",
       "      <td>88.37</td>\n",
       "      <td>8.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>24.0</td>\n",
       "      <td>92.16</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>21.0</td>\n",
       "      <td>88.41</td>\n",
       "      <td>8.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>25.0</td>\n",
       "      <td>90.20</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>22.0</td>\n",
       "      <td>87.47</td>\n",
       "      <td>6.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>26.0</td>\n",
       "      <td>92.16</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>24.0</td>\n",
       "      <td>90.99</td>\n",
       "      <td>8.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>27.0</td>\n",
       "      <td>90.20</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>22.0</td>\n",
       "      <td>89.17</td>\n",
       "      <td>6.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>28.0</td>\n",
       "      <td>88.24</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>23.0</td>\n",
       "      <td>88.41</td>\n",
       "      <td>8.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>29.0</td>\n",
       "      <td>92.16</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>21.0</td>\n",
       "      <td>88.34</td>\n",
       "      <td>6.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>30.0</td>\n",
       "      <td>90.20</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>23.0</td>\n",
       "      <td>90.08</td>\n",
       "      <td>7.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>35.0</td>\n",
       "      <td>92.16</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>24.0</td>\n",
       "      <td>89.32</td>\n",
       "      <td>9.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>40.0</td>\n",
       "      <td>92.16</td>\n",
       "      <td>0.000084</td>\n",
       "      <td>21.0</td>\n",
       "      <td>88.34</td>\n",
       "      <td>6.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>45.0</td>\n",
       "      <td>90.20</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>21.0</td>\n",
       "      <td>90.99</td>\n",
       "      <td>8.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>50.0</td>\n",
       "      <td>90.20</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>23.0</td>\n",
       "      <td>89.24</td>\n",
       "      <td>9.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>55.0</td>\n",
       "      <td>88.24</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>22.0</td>\n",
       "      <td>89.32</td>\n",
       "      <td>9.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>60.0</td>\n",
       "      <td>92.16</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>20.0</td>\n",
       "      <td>88.38</td>\n",
       "      <td>9.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>65.0</td>\n",
       "      <td>90.20</td>\n",
       "      <td>0.000184</td>\n",
       "      <td>18.0</td>\n",
       "      <td>86.63</td>\n",
       "      <td>8.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>70.0</td>\n",
       "      <td>92.16</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>23.0</td>\n",
       "      <td>88.45</td>\n",
       "      <td>9.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>75.0</td>\n",
       "      <td>94.12</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>23.0</td>\n",
       "      <td>88.37</td>\n",
       "      <td>8.36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    neuron  akurasi      loss  iter     cv   std\n",
       "0     11.0    90.20  0.000087  30.0  88.37  8.36\n",
       "1     12.0    88.24  0.000049  21.0  87.43  7.13\n",
       "2     13.0    90.20  0.000043  25.0  87.50  7.76\n",
       "3     14.0    88.24  0.000065  23.0  84.82  8.33\n",
       "4     15.0    94.12  0.000089  33.0  89.24  8.83\n",
       "5     16.0    94.12  0.000069  27.0  85.76  7.69\n",
       "6     17.0    94.12  0.000087  24.0  88.38  9.56\n",
       "7     18.0    92.16  0.000069  21.0  87.58  9.14\n",
       "8     19.0    90.20  0.000057  26.0  85.76  7.18\n",
       "9     20.0    92.16  0.000108  21.0  88.37  8.36\n",
       "10    21.0    92.16  0.000060  26.0  89.25  7.85\n",
       "11    22.0    92.16  0.000040  26.0  86.63  7.53\n",
       "12    23.0    90.20  0.000064  25.0  88.37  8.36\n",
       "13    24.0    92.16  0.000056  21.0  88.41  8.79\n",
       "14    25.0    90.20  0.000058  22.0  87.47  6.58\n",
       "15    26.0    92.16  0.000086  24.0  90.99  8.11\n",
       "16    27.0    90.20  0.000052  22.0  89.17  6.80\n",
       "17    28.0    88.24  0.000057  23.0  88.41  8.35\n",
       "18    29.0    92.16  0.000089  21.0  88.34  6.74\n",
       "19    30.0    90.20  0.000053  23.0  90.08  7.26\n",
       "20    35.0    92.16  0.000052  24.0  89.32  9.26\n",
       "21    40.0    92.16  0.000084  21.0  88.34  6.74\n",
       "22    45.0    90.20  0.000068  21.0  90.99  8.11\n",
       "23    50.0    90.20  0.000041  23.0  89.24  9.25\n",
       "24    55.0    88.24  0.000053  22.0  89.32  9.66\n",
       "25    60.0    92.16  0.000064  20.0  88.38  9.56\n",
       "26    65.0    90.20  0.000184  18.0  86.63  8.47\n",
       "27    70.0    92.16  0.000115  23.0  88.45  9.24\n",
       "28    75.0    94.12  0.000081  23.0  88.37  8.36"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "summary = [ ]\n",
    "i=0\n",
    "while(i<len(layers)):\n",
    "    summary.append([layers[i],data[i],loss[i], iterasi[i], cv_score[i],std_cv[i]]) \n",
    "    i+=1\n",
    "    \n",
    "df = pd.DataFrame(np.array(summary))\n",
    "df.columns = (['neuron','akurasi','loss','iter','cv','std'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Jenis, Granularity_Inti, GranularityP, SolidityP, EntropiP, EnergiP, KontrasP, HomogenitasP, LIperLP , KIperKP, RerataRP, RerataGP, RerataBP, RerataR_Inti, RerataG_Inti, RerataB_Inti]\n",
      "Index: []\n",
      "MLPClassifier(activation='relu', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=14, learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=2000, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
      "       solver='lbfgs', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "Akurasi cv:  89.24\n",
      "SD:  8.83\n",
      "[[11  0  0  0  0]\n",
      " [ 0  2  0  0  0]\n",
      " [ 0  0 10  0  2]\n",
      " [ 0  0  0  5  0]\n",
      " [ 0  0  1  0 20]]\n",
      "akurasi latih:  100.0\n",
      "akurasi uji:  94.12\n",
      "Confusion matrix, without normalization\n",
      "[[11  0  0  0  0]\n",
      " [ 0  2  0  0  0]\n",
      " [ 0  0 10  0  2]\n",
      " [ 0  0  0  5  0]\n",
      " [ 0  0  1  0 20]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    basofil       1.00      1.00      1.00        11\n",
      "  eosinofil       1.00      1.00      1.00         2\n",
      "   netrofil       0.91      0.83      0.87        12\n",
      "    monosit       1.00      1.00      1.00         5\n",
      "   limfosit       0.91      0.95      0.93        21\n",
      "\n",
      "avg / total       0.94      0.94      0.94        51\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_excel('Data-20Fitur-20Citra-20Sel-20Darah.xlsx', header=0,sheet_name='Data Fitur Citra Sel Darah2')\n",
    "#df = daf.drop(datset[i], axis=1)\n",
    "df = df[datset[4]]\n",
    "print(df[0:0])\n",
    "\n",
    "import numpy as np\n",
    "y= np.array(df)[:,0]           #membuat dataset target y\n",
    "X = np.array(df)[:,1:30]    #membuat dataset input X\n",
    "\n",
    "# Pisahkan dataset menjadi data latih dan uji dengan perbandingan 80:20\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.30, random_state=0)\n",
    "\n",
    "# Penyekalaan fitur dilakukan pada data latih dan uji.\n",
    "# Detail kenapa ini penting dijelaskan di sini: http://scikit-learn.org/stable/auto_examples/preprocessing/plot_scaling_importance.html\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "\n",
    "# Fungsi fit_transform hanya dilakukan di data latih\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    " # Latih kecerdasan buatan dengan data latih, menggunakan MLP-NN\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import time\n",
    "\n",
    "clf = MLPClassifier(activation='relu',solver='lbfgs', alpha=1e-5, max_iter=2000,\n",
    "            hidden_layer_sizes=(14), random_state=1)\n",
    "start = time.time()\n",
    "print(clf.fit(X_train, y_train))\n",
    "end = time.time()\n",
    "waktuTrain = end - start\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "scoring='accuracy'\n",
    "accuracies = cross_val_score(estimator=clf, X=X_train, y=y_train, cv=5,scoring=scoring)\n",
    "avg_accuracy = float('{0:.4f}'.format(accuracies.mean()))*100\n",
    "std_accuracy =  float('{0:.4f}'.format(accuracies.std()))*100\n",
    "print('Akurasi cv: ', avg_accuracy)\n",
    "print('SD: ', std_accuracy)\n",
    "\n",
    "#prediksi\n",
    "start = time.time()\n",
    "result = clf.predict(X_test)\n",
    "end = time.time()\n",
    "waktuTest = end - start\n",
    "\n",
    "#Confusion Matriks Hasil Prediksi dengan Nilai Sebenarnya\n",
    "from sklearn.metrics import classification_report,confusion_matrix, roc_auc_score\n",
    "print(confusion_matrix(y_test,result))\n",
    "\n",
    "# Cek kemampuan kecerdasan buatan dengan data uji \n",
    "train_accuracy = float('{0:.4f}'.format(clf.score(X_train, y_train)))*100\n",
    "print(\"akurasi latih: \",train_accuracy)\n",
    "\n",
    "# Cek kemampuan kecerdasan buatan dengan data uji \n",
    "test_accuracy = float('{0:.4f}'.format(clf.score(X_test, y_test)))*100\n",
    "print(\"akurasi uji: \",test_accuracy)\n",
    "\n",
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(y_test, result)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "class_names = ['Basofil', 'Eosinofil','Netrofil','Monosit','Limfosit']\n",
    "\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names,\n",
    "                      title='Confusion matrix')\n",
    "\n",
    "from sklearn.metrics import classification_report,confusion_matrix, roc_auc_score\n",
    "print(classification_report(y_test,result, target_names=['basofil','eosinofil','netrofil','monosit', 'limfosit']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5. 3. 5. 3. 5. 5. 1. 1. 5. 5. 3. 4. 5. 3. 3. 2. 3. 4. 5. 4. 5. 5. 5. 5.\n",
      " 3. 5. 1. 5. 5. 1. 1. 5. 5. 1. 3. 2. 1. 3. 4. 1. 5. 5. 5. 1. 3. 5. 1. 5.\n",
      " 1. 3. 4.]\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5. 3. 5. 3. 5. 3. 1. 1. 3. 5. 3. 4. 5. 5. 3. 2. 3. 4. 5. 4. 5. 5. 5. 5.\n",
      " 3. 5. 1. 5. 5. 1. 1. 5. 5. 1. 3. 2. 1. 3. 4. 1. 5. 5. 5. 1. 3. 5. 1. 5.\n",
      " 1. 3. 4.]\n"
     ]
    }
   ],
   "source": [
    "print(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(15, 14), (14, 5)]\n",
      "weights between input and first hidden layer:\n",
      "[[-2.92 -2.89 -3.15 -0.36 -2.55 -3.26 -1.4  -2.97 -0.37 -0.61 -6.52  3.24\n",
      "  -1.35  1.45]\n",
      " [-1.59  0.95 -1.69  0.59 -2.28 -0.49 -0.12  0.19  0.81  0.14 -0.78  1.6\n",
      "  -2.06  1.63]\n",
      " [ 0.48 -1.66 -2.41 -0.3   0.49 -2.33  0.1   0.52 -0.66 -0.05 -1.02  2.02\n",
      "   0.55  2.58]\n",
      " [ 0.46  2.64  0.31  0.24 -0.04  0.7   0.18  0.08 -0.56  0.24  1.45  0.41\n",
      "  -0.57 -0.64]\n",
      " [-0.64 -2.53 -0.6  -0.14  0.23 -0.87 -0.21 -0.78 -0.52  0.05 -1.26 -0.97\n",
      "   0.91 -0.05]\n",
      " [ 3.82  0.77 -0.36  0.95 -1.25 -1.09  1.04  0.49 -1.34  0.83 -1.    0.2\n",
      "  -0.08  0.3 ]\n",
      " [-0.66 -2.31 -1.17  0.17  0.29 -1.36 -0.64  0.26  0.41 -0.09 -2.06 -0.71\n",
      "   0.85  0.64]\n",
      " [-0.07 -2.38  0.13 -0.31  1.76 -0.72  0.4   0.41 -1.78  0.87 -0.27 -2.18\n",
      "   0.29 -1.4 ]\n",
      " [-3.12  2.83  1.14  0.62  1.81  4.65 -0.03 -2.99 -0.4  -1.01  0.31  1.24\n",
      "   0.04 -0.57]\n",
      " [ 1.12  1.01 -0.02  0.05 -0.53 -0.24  0.22  0.61  0.41 -0.32  0.5   1.96\n",
      "  -0.22  0.71]\n",
      " [ 2.77 -0.54 -1.29 -0.08 -2.3  -1.8   0.43  2.23  0.48 -0.81 -0.28  2.62\n",
      "  -0.45  1.2 ]\n",
      " [ 0.53  1.38 -0.9   0.38 -0.66  0.13 -0.18  0.92  0.52 -0.04 -0.04  1.83\n",
      "  -1.04  0.91]\n",
      " [ 0.65 -3.02  1.76 -0.39  2.12 -1.25  0.09  2.34 -3.97  1.27 -2.6  -5.13\n",
      "   0.37 -3.1 ]\n",
      " [ 2.54  2.02 -6.31  2.35 -2.8  -0.43  1.93  3.77  2.17 -2.26  1.    2.08\n",
      "  -1.51  4.12]\n",
      " [-0.38 -1.96 -1.54  0.15 -1.17 -1.39  0.41 -0.46 -2.42 -0.07 -2.37 -1.73\n",
      "  -0.54 -0.66]]\n",
      "\n",
      "weights between first hidden and second hidden layer:\n",
      "[[-0.39  0.07 -2.61  5.14 -0.98]\n",
      " [ 4.08  4.93 -3.46 -3.08 -1.91]\n",
      " [-2.82 -1.43 -2.35  0.44  5.74]\n",
      " [-1.05 -1.2  -1.5   2.76  1.31]\n",
      " [ 0.74  0.19 -3.77 -0.98  3.88]\n",
      " [ 3.52 -2.2  -1.   -1.22  1.74]\n",
      " [ 0.21 -0.09 -2.04  2.63 -0.24]\n",
      " [-2.09 -2.89  1.11  0.03  5.14]\n",
      " [-3.47  2.34  2.51  0.64 -1.8 ]\n",
      " [ 0.15 -0.06 -2.62  0.24  1.92]\n",
      " [ 2.06 -1.6  -1.03  3.99 -3.27]\n",
      " [-5.29 -0.01  4.13  1.47  0.84]\n",
      " [-1.55 -0.42  0.5  -0.02  2.07]\n",
      " [ 3.11 -1.4   5.27 -1.78 -4.57]]\n",
      "Bias values for first hidden layer:\n",
      "[-2.45  0.62 -2.9  -0.66  2.17  1.83 -1.51  1.72  0.95 -0.22 -1.23 -1.41\n",
      " -1.13  2.2 ]\n",
      "\n",
      "Bias values for second hidden layer:\n",
      "[ 4.46 -2.45  1.63 -3.95 -0.42]\n"
     ]
    }
   ],
   "source": [
    "#Banyak bobot yang digunakan\n",
    "print([coef.shape for coef in clf.coefs_])\n",
    "print(\"weights between input and first hidden layer:\")\n",
    "print(clf.coefs_[0])\n",
    "print(\"\\nweights between first hidden and second hidden layer:\")\n",
    "print(clf.coefs_[1])\n",
    "print(\"Bias values for first hidden layer:\")\n",
    "print(clf.intercepts_[0])\n",
    "print(\"\\nBias values for second hidden layer:\")\n",
    "print(clf.intercepts_[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
