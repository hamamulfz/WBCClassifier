{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "#df = pd.read_excel('Urut-Data-20Fitur-20Citra-20Sel-20Darah.xlsx', header=0)\n",
    "df = pd.read_excel('Data-20Fitur-20Citra-20Sel-20Darah.xlsx', header=0,sheet_name='Data Fitur Citra Sel Darah2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "head = ['Jenis', 'KIperKP', 'KontrasP', 'Solidity_Inti', 'HomogenitasP',\n",
    "        'Circularity_Inti', 'Keliling_Inti', 'LIperLP ', 'KelilingP',\n",
    "        'EntropiP', 'LuasNormal_P', 'EnergiP', 'Homogenitas_Inti',\n",
    "        'KelilingNormal_I', 'Entropi_Inti', 'Granularity_Inti',\n",
    "        'RerataGP', 'SolidityP', 'Energi_Inti', 'RerataRP',\n",
    "        'RerataR_Inti', 'CircularityP', 'LuasP', 'GranularityP',\n",
    "        'RerataG_Inti', 'RerataBP', 'Eccentricity', 'RerataB_Inti',\n",
    "        'Kontras_Inti', 'Luas_Inti']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "k1 =[ 'Luas_Inti','Keliling_Inti']\n",
    "k2 = ['Granularity_Inti','GranularityP']\n",
    "k3 = ['Circularity_Inti','CircularityP','Eccentricity']\n",
    "k4 = ['RerataR_Inti','RerataG_Inti','RerataB_Inti']\n",
    "k5 = ['Solidity_Inti','Entropi_Inti','Energi_Inti','Kontras_Inti','Homogenitas_Inti']\n",
    "k6 = ['LuasP','KelilingP']\n",
    "k7 = ['RerataRP','RerataGP','RerataBP']\n",
    "k8 = ['SolidityP','EntropiP','EnergiP','KontrasP','HomogenitasP']\n",
    "k9 = ['LuasNormal_P','KelilingNormal_I']\n",
    "k10 =[ 'LIperLP ','KIperKP']\n",
    "\n",
    "datset = [k1,k2,k3,k4,k5,k6,k7,k8,k9,k10]\n",
    "\n",
    "#adam\n",
    "#    1          2         3         4         5          6          7          8           9         10\n",
    "#[99.15, 99.15, 99.15, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 99.15]\n",
    "#[88.24, 86.27, 86.27, 88.24, 86.27, 88.24, 88.24, 82.35, 84.31, 86.27]\n",
    "\n",
    "#lbfgs\n",
    "#    1          2         3         4         5          6          7          8           9         10\n",
    "#[100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0]\n",
    "#[90.2, 84.31, 82.35, 86.27, 90.2, 88.24, 86.27, 80.39, 88.24, 80.39]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tolen= 0\n",
    "for i in range(len(datset)):\n",
    "    tolen = tolen +len(datset[i])\n",
    "print(tolen)\n",
    "len(datset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adam finish\n",
    "k2 = ['Jenis','Granularity_Inti','GranularityP']\n",
    "k1 =['Jenis','Granularity_Inti','GranularityP', 'Luas_Inti','Keliling_Inti']\n",
    "k7 = ['Jenis','Granularity_Inti','GranularityP', 'Luas_Inti','Keliling_Inti','RerataRP','RerataGP','RerataBP']\n",
    "k8 = ['Jenis','Granularity_Inti','GranularityP', 'Luas_Inti','Keliling_Inti','RerataRP','RerataGP','RerataBP','SolidityP','EntropiP','EnergiP','KontrasP','HomogenitasP']\n",
    "k4 = ['Jenis','Granularity_Inti','GranularityP', 'Luas_Inti','Keliling_Inti','RerataRP','RerataGP','RerataBP','SolidityP','EntropiP','EnergiP','KontrasP','HomogenitasP','RerataR_Inti','RerataG_Inti','RerataB_Inti']\n",
    "k10 =['Jenis','Granularity_Inti','GranularityP', 'Luas_Inti','Keliling_Inti','RerataRP','RerataGP','RerataBP','SolidityP','EntropiP','EnergiP','KontrasP','HomogenitasP','RerataR_Inti','RerataG_Inti','RerataB_Inti', 'LIperLP ','KIperKP']\n",
    "k9 = ['Jenis','Granularity_Inti','GranularityP', 'Luas_Inti','Keliling_Inti','RerataRP','RerataGP','RerataBP','SolidityP','EntropiP','EnergiP','KontrasP','HomogenitasP','RerataR_Inti','RerataG_Inti','RerataB_Inti', 'LIperLP ','KIperKP','LuasNormal_P','KelilingNormal_I']\n",
    "k6 = ['Jenis','Granularity_Inti','GranularityP', 'Luas_Inti','Keliling_Inti','RerataRP','RerataGP','RerataBP','SolidityP','EntropiP','EnergiP','KontrasP','HomogenitasP','RerataR_Inti','RerataG_Inti','RerataB_Inti', 'LIperLP ','KIperKP','LuasNormal_P','KelilingNormal_I','LuasP','KelilingP']\n",
    "k3 = ['Jenis','Granularity_Inti','GranularityP', 'Luas_Inti','Keliling_Inti','RerataRP','RerataGP','RerataBP','SolidityP','EntropiP','EnergiP','KontrasP','HomogenitasP','RerataR_Inti','RerataG_Inti','RerataB_Inti', 'LIperLP ','KIperKP','LuasNormal_P','KelilingNormal_I','LuasP','KelilingP','Circularity_Inti','CircularityP','Eccentricity']\n",
    "k5 = ['Jenis','Granularity_Inti','GranularityP', 'Luas_Inti','Keliling_Inti','RerataRP','RerataGP','RerataBP','SolidityP','EntropiP','EnergiP','KontrasP','HomogenitasP','RerataR_Inti','RerataG_Inti','RerataB_Inti', 'LIperLP ','KIperKP','LuasNormal_P','KelilingNormal_I','LuasP','KelilingP','Circularity_Inti','CircularityP','Eccentricity','Solidity_Inti','Entropi_Inti','Energi_Inti','Kontras_Inti','Homogenitas_Inti']\n",
    "\n",
    "datset = [k2, k1, k7, k8, k4, k10, k9, k6, k3, k5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reordering Columns by name\n",
    "df = pd.read_excel('Urut-Data-20Fitur-20Citra-20Sel-20Darah.xlsx', header=0)\n",
    "df = df[k2]\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daf = pd.read_excel('Urut-Data-20Fitur-20Citra-20Sel-20Darah.xlsx', header=0)\n",
    "#df = daf.drop(datset[0], axis=1)\n",
    "print(df[0:0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "k7 = ['Jenis','RerataRP','RerataGP','RerataBP']\n",
    "k3 = ['Jenis','RerataRP','RerataGP','RerataBP','Circularity_Inti','CircularityP','Eccentricity']\n",
    "k5 = ['Jenis','RerataRP','RerataGP','RerataBP','Circularity_Inti','CircularityP','Eccentricity','Solidity_Inti','Entropi_Inti','Energi_Inti','Kontras_Inti','Homogenitas_Inti']\n",
    "k10 =['Jenis','RerataRP','RerataGP','RerataBP','Circularity_Inti','CircularityP','Eccentricity','Solidity_Inti','Entropi_Inti','Energi_Inti','Kontras_Inti','Homogenitas_Inti', 'LIperLP ','KIperKP']\n",
    "k8 = ['Jenis','RerataRP','RerataGP','RerataBP','Circularity_Inti','CircularityP','Eccentricity','Solidity_Inti','Entropi_Inti','Energi_Inti','Kontras_Inti','Homogenitas_Inti', 'LIperLP ','KIperKP','SolidityP','EntropiP','EnergiP','KontrasP','HomogenitasP']\n",
    "k9 = ['Jenis','RerataRP','RerataGP','RerataBP','Circularity_Inti','CircularityP','Eccentricity','Solidity_Inti','Entropi_Inti','Energi_Inti','Kontras_Inti','Homogenitas_Inti', 'LIperLP ','KIperKP','SolidityP','EntropiP','EnergiP','KontrasP','HomogenitasP','LuasNormal_P','KelilingNormal_I']\n",
    "k4 = ['Jenis','RerataRP','RerataGP','RerataBP','Circularity_Inti','CircularityP','Eccentricity','Solidity_Inti','Entropi_Inti','Energi_Inti','Kontras_Inti','Homogenitas_Inti', 'LIperLP ','KIperKP','SolidityP','EntropiP','EnergiP','KontrasP','HomogenitasP','LuasNormal_P','KelilingNormal_I','RerataR_Inti','RerataG_Inti','RerataB_Inti']\n",
    "k2 = ['Jenis','RerataRP','RerataGP','RerataBP','Circularity_Inti','CircularityP','Eccentricity','Solidity_Inti','Entropi_Inti','Energi_Inti','Kontras_Inti','Homogenitas_Inti', 'LIperLP ','KIperKP','SolidityP','EntropiP','EnergiP','KontrasP','HomogenitasP','LuasNormal_P','KelilingNormal_I','RerataR_Inti','RerataG_Inti','RerataB_Inti','Granularity_Inti','GranularityP']\n",
    "k6 = ['Jenis','RerataRP','RerataGP','RerataBP','Circularity_Inti','CircularityP','Eccentricity','Solidity_Inti','Entropi_Inti','Energi_Inti','Kontras_Inti','Homogenitas_Inti', 'LIperLP ','KIperKP','SolidityP','EntropiP','EnergiP','KontrasP','HomogenitasP','LuasNormal_P','KelilingNormal_I','RerataR_Inti','RerataG_Inti','RerataB_Inti','Granularity_Inti','GranularityP','LuasP','KelilingP']\n",
    "k1 =['Jenis','RerataRP','RerataGP','RerataBP','Circularity_Inti','CircularityP','Eccentricity','Solidity_Inti','Entropi_Inti','Energi_Inti','Kontras_Inti','Homogenitas_Inti', 'LIperLP ','KIperKP','SolidityP','EntropiP','EnergiP','KontrasP','HomogenitasP','LuasNormal_P','KelilingNormal_I','RerataR_Inti','RerataG_Inti','RerataB_Inti','Granularity_Inti','GranularityP','LuasP','KelilingP', 'Luas_Inti','Keliling_Inti']\n",
    "\n",
    "datset = [k7,k3,k5,k10,k8,k9,k4,k2,k6,k1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Empty DataFrame\n",
      "Columns: [Jenis, RerataRP, RerataGP, RerataBP]\n",
      "Index: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramFiles\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier(activation='tanh', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=28, learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=2000, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramFiles\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "D:\\ProgramFiles\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "D:\\ProgramFiles\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "D:\\ProgramFiles\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Akurasi:  86.52\n",
      "SD:  5.36\n",
      "[[10  1  0  0  0]\n",
      " [ 1  1  0  0  0]\n",
      " [ 1  0 11  0  0]\n",
      " [ 0  0  1  4  0]\n",
      " [ 0  0  5  0 16]]\n",
      "akurasi latih:  91.53\n",
      "akurasi uji:  82.35\n",
      "\n",
      "1\n",
      "Empty DataFrame\n",
      "Columns: [Jenis, RerataRP, RerataGP, RerataBP, Circularity_Inti, CircularityP, Eccentricity]\n",
      "Index: []\n",
      "MLPClassifier(activation='tanh', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=28, learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=2000, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "Akurasi:  86.74\n",
      "SD:  7.68\n",
      "[[ 8  1  2  0  0]\n",
      " [ 1  0  1  0  0]\n",
      " [ 0  0 12  0  0]\n",
      " [ 1  0  0  4  0]\n",
      " [ 0  0  3  0 18]]\n",
      "akurasi latih:  97.46000000000001\n",
      "akurasi uji:  82.35\n",
      "\n",
      "2\n",
      "Empty DataFrame\n",
      "Columns: [Jenis, RerataRP, RerataGP, RerataBP, Circularity_Inti, CircularityP, Eccentricity, Solidity_Inti, Entropi_Inti, Energi_Inti, Kontras_Inti, Homogenitas_Inti]\n",
      "Index: []\n",
      "MLPClassifier(activation='tanh', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=28, learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=2000, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "Akurasi:  86.74\n",
      "SD:  6.63\n",
      "[[ 8  2  0  0  1]\n",
      " [ 1  0  1  0  0]\n",
      " [ 0  0 10  1  1]\n",
      " [ 0  0  2  3  0]\n",
      " [ 0  0  2  0 19]]\n",
      "akurasi latih:  100.0\n",
      "akurasi uji:  78.43\n",
      "\n",
      "3\n",
      "Empty DataFrame\n",
      "Columns: [Jenis, RerataRP, RerataGP, RerataBP, Circularity_Inti, CircularityP, Eccentricity, Solidity_Inti, Entropi_Inti, Energi_Inti, Kontras_Inti, Homogenitas_Inti, LIperLP , KIperKP]\n",
      "Index: []\n",
      "MLPClassifier(activation='tanh', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=28, learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=2000, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "Akurasi:  88.41\n",
      "SD:  6.64\n",
      "[[ 8  2  0  0  1]\n",
      " [ 1  0  1  0  0]\n",
      " [ 0  0 11  0  1]\n",
      " [ 1  0  2  2  0]\n",
      " [ 0  0  2  0 19]]\n",
      "akurasi latih:  100.0\n",
      "akurasi uji:  78.43\n",
      "\n",
      "4\n",
      "Empty DataFrame\n",
      "Columns: [Jenis, RerataRP, RerataGP, RerataBP, Circularity_Inti, CircularityP, Eccentricity, Solidity_Inti, Entropi_Inti, Energi_Inti, Kontras_Inti, Homogenitas_Inti, LIperLP , KIperKP, SolidityP, EntropiP, EnergiP, KontrasP, HomogenitasP]\n",
      "Index: []\n",
      "MLPClassifier(activation='tanh', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=28, learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=2000, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "Akurasi:  90.14999999999999\n",
      "SD:  9.180000000000001\n",
      "[[ 9  1  0  0  1]\n",
      " [ 1  1  0  0  0]\n",
      " [ 0  0 11  0  1]\n",
      " [ 0  1  2  2  0]\n",
      " [ 0  0  1  1 19]]\n",
      "akurasi latih:  100.0\n",
      "akurasi uji:  82.35\n",
      "\n",
      "5\n",
      "Empty DataFrame\n",
      "Columns: [Jenis, RerataRP, RerataGP, RerataBP, Circularity_Inti, CircularityP, Eccentricity, Solidity_Inti, Entropi_Inti, Energi_Inti, Kontras_Inti, Homogenitas_Inti, LIperLP , KIperKP, SolidityP, EntropiP, EnergiP, KontrasP, HomogenitasP, LuasNormal_P, KelilingNormal_I]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 21 columns]\n",
      "MLPClassifier(activation='tanh', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=28, learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=2000, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "Akurasi:  90.95\n",
      "SD:  7.6\n",
      "[[10  1  0  0  0]\n",
      " [ 1  1  0  0  0]\n",
      " [ 0  0 11  0  1]\n",
      " [ 0  0  3  2  0]\n",
      " [ 0  0  1  0 20]]\n",
      "akurasi latih:  100.0\n",
      "akurasi uji:  86.27\n",
      "\n",
      "6\n",
      "Empty DataFrame\n",
      "Columns: [Jenis, RerataRP, RerataGP, RerataBP, Circularity_Inti, CircularityP, Eccentricity, Solidity_Inti, Entropi_Inti, Energi_Inti, Kontras_Inti, Homogenitas_Inti, LIperLP , KIperKP, SolidityP, EntropiP, EnergiP, KontrasP, HomogenitasP, LuasNormal_P, KelilingNormal_I, RerataR_Inti, RerataG_Inti, RerataB_Inti]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 24 columns]\n",
      "MLPClassifier(activation='tanh', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=28, learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=2000, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "Akurasi:  90.95\n",
      "SD:  7.6\n",
      "[[11  0  0  0  0]\n",
      " [ 1  0  1  0  0]\n",
      " [ 0  0 11  0  1]\n",
      " [ 0  1  1  3  0]\n",
      " [ 0  0  1  0 20]]\n",
      "akurasi latih:  100.0\n",
      "akurasi uji:  88.24\n",
      "\n",
      "7\n",
      "Empty DataFrame\n",
      "Columns: [Jenis, RerataRP, RerataGP, RerataBP, Circularity_Inti, CircularityP, Eccentricity, Solidity_Inti, Entropi_Inti, Energi_Inti, Kontras_Inti, Homogenitas_Inti, LIperLP , KIperKP, SolidityP, EntropiP, EnergiP, KontrasP, HomogenitasP, LuasNormal_P, KelilingNormal_I, RerataR_Inti, RerataG_Inti, RerataB_Inti, Granularity_Inti, GranularityP]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 26 columns]\n",
      "MLPClassifier(activation='tanh', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=28, learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=2000, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "Akurasi:  90.01\n",
      "SD:  5.92\n",
      "[[10  0  0  0  1]\n",
      " [ 1  0  1  0  0]\n",
      " [ 0  0 10  0  2]\n",
      " [ 0  0  2  3  0]\n",
      " [ 0  0  1  0 20]]\n",
      "akurasi latih:  100.0\n",
      "akurasi uji:  84.31\n",
      "\n",
      "8\n",
      "Empty DataFrame\n",
      "Columns: [Jenis, RerataRP, RerataGP, RerataBP, Circularity_Inti, CircularityP, Eccentricity, Solidity_Inti, Entropi_Inti, Energi_Inti, Kontras_Inti, Homogenitas_Inti, LIperLP , KIperKP, SolidityP, EntropiP, EnergiP, KontrasP, HomogenitasP, LuasNormal_P, KelilingNormal_I, RerataR_Inti, RerataG_Inti, RerataB_Inti, Granularity_Inti, GranularityP, LuasP, KelilingP]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 28 columns]\n",
      "MLPClassifier(activation='tanh', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=28, learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=2000, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "Akurasi:  93.53\n",
      "SD:  7.3999999999999995\n",
      "[[10  1  0  0  0]\n",
      " [ 1  0  1  0  0]\n",
      " [ 0  0 11  0  1]\n",
      " [ 0  0  2  3  0]\n",
      " [ 0  0  1  0 20]]\n",
      "akurasi latih:  100.0\n",
      "akurasi uji:  86.27\n",
      "\n",
      "9\n",
      "Empty DataFrame\n",
      "Columns: [Jenis, RerataRP, RerataGP, RerataBP, Circularity_Inti, CircularityP, Eccentricity, Solidity_Inti, Entropi_Inti, Energi_Inti, Kontras_Inti, Homogenitas_Inti, LIperLP , KIperKP, SolidityP, EntropiP, EnergiP, KontrasP, HomogenitasP, LuasNormal_P, KelilingNormal_I, RerataR_Inti, RerataG_Inti, RerataB_Inti, Granularity_Inti, GranularityP, LuasP, KelilingP, Luas_Inti, Keliling_Inti]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 30 columns]\n",
      "MLPClassifier(activation='tanh', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=28, learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=2000, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "Akurasi:  92.66\n",
      "SD:  6.819999999999999\n",
      "[[11  0  0  0  0]\n",
      " [ 1  0  1  0  0]\n",
      " [ 0  0 10  0  2]\n",
      " [ 0  1  1  3  0]\n",
      " [ 1  0  1  0 19]]\n",
      "akurasi latih:  100.0\n",
      "akurasi uji:  84.31\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train = [ ]\n",
    "test = [ ]\n",
    "cv_score = [ ]\n",
    "cv_std = [ ]\n",
    "for i in range(10):\n",
    "    print(i)\n",
    "\n",
    "    daf = pd.read_excel('Data-20Fitur-20Citra-20Sel-20Darah.xlsx', header=0, sheet_name ='Data Fitur Citra Sel Darah2')\n",
    "    #df = daf.drop(datset[i], axis=1)\n",
    "    df = daf[datset[i]]\n",
    "    print(df[0:0])\n",
    "\n",
    "    import numpy as np\n",
    "    y= np.array(df)[:,0]           #membuat dataset target y\n",
    "    X = np.array(df)[:,1:30]    #membuat dataset input X\n",
    "\n",
    "    # Pisahkan dataset menjadi data latih dan uji dengan perbandingan 80:20\n",
    "    from sklearn.cross_validation import train_test_split\n",
    "    X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.30, random_state=0)\n",
    "\n",
    "    # Penyekalaan fitur dilakukan pada data latih dan uji.\n",
    "    # Detail kenapa ini penting dijelaskan di sini: http://scikit-learn.org/stable/auto_examples/preprocessing/plot_scaling_importance.html\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    sc = StandardScaler()\n",
    "\n",
    "    # Fungsi fit_transform hanya dilakukan di data latih\n",
    "    X_train = sc.fit_transform(X_train)\n",
    "    X_test = sc.transform(X_test)\n",
    "\n",
    "    # Latih kecerdasan buatan dengan data latih, menggunakan MLP-NN\n",
    "    from sklearn.neural_network import MLPClassifier\n",
    "    import time\n",
    "\n",
    "    clf = MLPClassifier(activation='tanh',solver='adam', alpha=1e-5, max_iter=2000,\n",
    "                hidden_layer_sizes=(28), random_state=1)\n",
    "    start = time.time()\n",
    "    print(clf.fit(X_train, y_train))\n",
    "    end = time.time()\n",
    "    waktuTrain = end - start\n",
    "\n",
    "    from sklearn.model_selection import cross_val_score\n",
    "    scoring='accuracy'\n",
    "    accuracies = cross_val_score(estimator=clf, X=X_train, y=y_train, cv=5,scoring=scoring)\n",
    "    avg_accuracy = float('{0:.4f}'.format(accuracies.mean()))*100\n",
    "    std_accuracy =  float('{0:.4f}'.format(accuracies.std()))*100\n",
    "    print('Akurasi: ', avg_accuracy)\n",
    "    print('SD: ', std_accuracy)\n",
    "\n",
    "    #prediksi\n",
    "    start = time.time()\n",
    "    result = clf.predict(X_test)\n",
    "    end = time.time()\n",
    "    waktuTest = end - start\n",
    "\n",
    "    #Confusion Matriks Hasil Prediksi dengan Nilai Sebenarnya\n",
    "    from sklearn.metrics import classification_report,confusion_matrix, roc_auc_score\n",
    "    print(confusion_matrix(y_test,result))\n",
    "\n",
    "    # Cek kemampuan kecerdasan buatan dengan data uji \n",
    "    train_accuracy = float('{0:.4f}'.format(clf.score(X_train, y_train)))*100\n",
    "    print(\"akurasi latih: \",train_accuracy)\n",
    "\n",
    "    # Cek kemampuan kecerdasan buatan dengan data uji \n",
    "    test_accuracy = float('{0:.4f}'.format(clf.score(X_test, y_test)))*100\n",
    "    print(\"akurasi uji: \",test_accuracy)\n",
    "\n",
    "    train.append(train_accuracy)\n",
    "    cv_score.append(avg_accuracy)\n",
    "    cv_std.append(std_accuracy)\n",
    "    test.append(test_accuracy)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[91.53,\n",
       " 97.46000000000001,\n",
       " 100.0,\n",
       " 100.0,\n",
       " 100.0,\n",
       " 100.0,\n",
       " 100.0,\n",
       " 100.0,\n",
       " 100.0,\n",
       " 100.0]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[86.52,\n",
       " 86.74,\n",
       " 86.74,\n",
       " 88.41,\n",
       " 90.14999999999999,\n",
       " 90.95,\n",
       " 90.95,\n",
       " 90.01,\n",
       " 93.53,\n",
       " 92.66]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[82.35, 82.35, 78.43, 78.43, 82.35, 86.27, 88.24, 84.31, 86.27, 84.31]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''#adam finish\n",
    "k2 = ['Jenis','Granularity_Inti','GranularityP']\n",
    "k1 =['Jenis','Granularity_Inti','GranularityP', 'Luas_Inti','Keliling_Inti']\n",
    "k7 = ['Jenis','Granularity_Inti','GranularityP', 'Luas_Inti','Keliling_Inti','RerataRP','RerataGP','RerataBP']\n",
    "k8 = ['Jenis','Granularity_Inti','GranularityP', 'Luas_Inti','Keliling_Inti','RerataRP','RerataGP','RerataBP','SolidityP','EntropiP','EnergiP','KontrasP','HomogenitasP']\n",
    "k4 = ['Jenis','Granularity_Inti','GranularityP', 'Luas_Inti','Keliling_Inti','RerataRP','RerataGP','RerataBP','SolidityP','EntropiP','EnergiP','KontrasP','HomogenitasP','RerataR_Inti','RerataG_Inti','RerataB_Inti']\n",
    "k10 =['Jenis','Granularity_Inti','GranularityP', 'Luas_Inti','Keliling_Inti','RerataRP','RerataGP','RerataBP','SolidityP','EntropiP','EnergiP','KontrasP','HomogenitasP','RerataR_Inti','RerataG_Inti','RerataB_Inti', 'LIperLP ','KIperKP']\n",
    "k9 = ['Jenis','Granularity_Inti','GranularityP', 'Luas_Inti','Keliling_Inti','RerataRP','RerataGP','RerataBP','SolidityP','EntropiP','EnergiP','KontrasP','HomogenitasP','RerataR_Inti','RerataG_Inti','RerataB_Inti', 'LIperLP ','KIperKP','LuasNormal_P','KelilingNormal_I']\n",
    "k6 = ['Jenis','Granularity_Inti','GranularityP', 'Luas_Inti','Keliling_Inti','RerataRP','RerataGP','RerataBP','SolidityP','EntropiP','EnergiP','KontrasP','HomogenitasP','RerataR_Inti','RerataG_Inti','RerataB_Inti', 'LIperLP ','KIperKP','LuasNormal_P','KelilingNormal_I','LuasP','KelilingP']\n",
    "k3 = ['Jenis','Granularity_Inti','GranularityP', 'Luas_Inti','Keliling_Inti','RerataRP','RerataGP','RerataBP','SolidityP','EntropiP','EnergiP','KontrasP','HomogenitasP','RerataR_Inti','RerataG_Inti','RerataB_Inti', 'LIperLP ','KIperKP','LuasNormal_P','KelilingNormal_I','LuasP','KelilingP','Circularity_Inti','CircularityP','Eccentricity']\n",
    "k5 = ['Jenis','Granularity_Inti','GranularityP', 'Luas_Inti','Keliling_Inti','RerataRP','RerataGP','RerataBP','SolidityP','EntropiP','EnergiP','KontrasP','HomogenitasP','RerataR_Inti','RerataG_Inti','RerataB_Inti', 'LIperLP ','KIperKP','LuasNormal_P','KelilingNormal_I','LuasP','KelilingP','Circularity_Inti','CircularityP','Eccentricity','Solidity_Inti','Entropi_Inti','Energi_Inti','Kontras_Inti','Homogenitas_Inti']\n",
    "\n",
    "datset = [k2, k1, k7, k8, k4, k10, k9, k6, k3, k5]'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "k7 = ['Jenis','RerataRP','RerataGP','RerataBP']\n",
    "k3 = ['Jenis','RerataRP','RerataGP','RerataBP','Circularity_Inti','CircularityP','Eccentricity']\n",
    "k5 = ['Jenis','RerataRP','RerataGP','RerataBP','Circularity_Inti','CircularityP','Eccentricity','Solidity_Inti','Entropi_Inti','Energi_Inti','Kontras_Inti','Homogenitas_Inti']\n",
    "k10 =['Jenis','RerataRP','RerataGP','RerataBP','Circularity_Inti','CircularityP','Eccentricity','Solidity_Inti','Entropi_Inti','Energi_Inti','Kontras_Inti','Homogenitas_Inti', 'LIperLP ','KIperKP']\n",
    "k8 = ['Jenis','RerataRP','RerataGP','RerataBP','Circularity_Inti','CircularityP','Eccentricity','Solidity_Inti','Entropi_Inti','Energi_Inti','Kontras_Inti','Homogenitas_Inti', 'LIperLP ','KIperKP','SolidityP','EntropiP','EnergiP','KontrasP','HomogenitasP']\n",
    "k9 = ['Jenis','RerataRP','RerataGP','RerataBP','Circularity_Inti','CircularityP','Eccentricity','Solidity_Inti','Entropi_Inti','Energi_Inti','Kontras_Inti','Homogenitas_Inti', 'LIperLP ','KIperKP','SolidityP','EntropiP','EnergiP','KontrasP','HomogenitasP','LuasNormal_P','KelilingNormal_I']\n",
    "k4 = ['Jenis','RerataRP','RerataGP','RerataBP','Circularity_Inti','CircularityP','Eccentricity','Solidity_Inti','Entropi_Inti','Energi_Inti','Kontras_Inti','Homogenitas_Inti', 'LIperLP ','KIperKP','SolidityP','EntropiP','EnergiP','KontrasP','HomogenitasP','LuasNormal_P','KelilingNormal_I','RerataR_Inti','RerataG_Inti','RerataB_Inti']\n",
    "k2 = ['Jenis','RerataRP','RerataGP','RerataBP','Circularity_Inti','CircularityP','Eccentricity','Solidity_Inti','Entropi_Inti','Energi_Inti','Kontras_Inti','Homogenitas_Inti', 'LIperLP ','KIperKP','SolidityP','EntropiP','EnergiP','KontrasP','HomogenitasP','LuasNormal_P','KelilingNormal_I','RerataR_Inti','RerataG_Inti','RerataB_Inti','Granularity_Inti','GranularityP']\n",
    "k6 = ['Jenis','RerataRP','RerataGP','RerataBP','Circularity_Inti','CircularityP','Eccentricity','Solidity_Inti','Entropi_Inti','Energi_Inti','Kontras_Inti','Homogenitas_Inti', 'LIperLP ','KIperKP','SolidityP','EntropiP','EnergiP','KontrasP','HomogenitasP','LuasNormal_P','KelilingNormal_I','RerataR_Inti','RerataG_Inti','RerataB_Inti','Granularity_Inti','GranularityP','LuasP','KelilingP']\n",
    "k1 =['Jenis','RerataRP','RerataGP','RerataBP','Circularity_Inti','CircularityP','Eccentricity','Solidity_Inti','Entropi_Inti','Energi_Inti','Kontras_Inti','Homogenitas_Inti', 'LIperLP ','KIperKP','SolidityP','EntropiP','EnergiP','KontrasP','HomogenitasP','LuasNormal_P','KelilingNormal_I','RerataR_Inti','RerataG_Inti','RerataB_Inti','Granularity_Inti','GranularityP','LuasP','KelilingP', 'Luas_Inti','Keliling_Inti']\n",
    "\n",
    "datset = [k7,k3,k5,k10,k8,k9,k4,k2,k6,k1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Jenis, Solidity_Inti, Granularity_Inti, Circularity_Inti, RerataR_Inti, RerataG_Inti, RerataB_Inti, Entropi_Inti, Energi_Inti, Kontras_Inti, Homogenitas_Inti, LuasP, KelilingP, SolidityP, GranularityP, CircularityP, RerataRP, RerataGP, RerataBP, EntropiP, EnergiP, KontrasP, HomogenitasP, LuasNormal_P, KelilingNormal_I, Eccentricity, LIperLP , KIperKP]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 28 columns]\n",
      "MLPClassifier(activation='tanh', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=10, learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=2000, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "Loss Pelatihan :  0.049219748435098847\n",
      "Jumlah iterasi :  1018\n",
      "Akurasi:  93.53\n",
      "SD:  7.3999999999999995\n",
      "[[10  1  0  0  0]\n",
      " [ 1  1  0  0  0]\n",
      " [ 0  0 11  0  1]\n",
      " [ 0  0  2  3  0]\n",
      " [ 0  0  1  0 20]]\n",
      "Akurasi Data Uji: 0.8823529411764706 = 0.8823529411764706\n",
      "Akurasi Data Latih: 1.0\n",
      "\n",
      "MLPClassifier(activation='tanh', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=11, learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=2000, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "Loss Pelatihan :  0.045746155514912186\n",
      "Jumlah iterasi :  990\n",
      "Akurasi:  91.86\n",
      "SD:  8.33\n",
      "[[10  1  0  0  0]\n",
      " [ 1  1  0  0  0]\n",
      " [ 0  0 11  0  1]\n",
      " [ 1  0  2  2  0]\n",
      " [ 0  0  1  0 20]]\n",
      "Akurasi Data Uji: 0.8627450980392157 = 0.8627450980392157\n",
      "Akurasi Data Latih: 1.0\n",
      "\n",
      "MLPClassifier(activation='tanh', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=12, learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=2000, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "Loss Pelatihan :  0.046901712130816724\n",
      "Jumlah iterasi :  911\n",
      "Akurasi:  91.75\n",
      "SD:  7.88\n",
      "[[11  0  0  0  0]\n",
      " [ 1  1  0  0  0]\n",
      " [ 0  0 11  0  1]\n",
      " [ 1  1  0  3  0]\n",
      " [ 1  0  1  0 19]]\n",
      "Akurasi Data Uji: 0.8823529411764706 = 0.8823529411764706\n",
      "Akurasi Data Latih: 1.0\n",
      "\n",
      "MLPClassifier(activation='tanh', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=13, learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=2000, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "Loss Pelatihan :  0.041818075579975446\n",
      "Jumlah iterasi :  792\n",
      "Akurasi:  92.66\n",
      "SD:  5.81\n",
      "[[10  1  0  0  0]\n",
      " [ 1  0  1  0  0]\n",
      " [ 0  0 11  0  1]\n",
      " [ 0  1  0  4  0]\n",
      " [ 1  0  1  0 19]]\n",
      "Akurasi Data Uji: 0.8627450980392157 = 0.8627450980392157\n",
      "Akurasi Data Latih: 1.0\n",
      "\n",
      "MLPClassifier(activation='tanh', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=14, learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=2000, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "Loss Pelatihan :  0.04534682098213559\n",
      "Jumlah iterasi :  761\n",
      "Akurasi:  91.82000000000001\n",
      "SD:  7.06\n",
      "[[11  0  0  0  0]\n",
      " [ 1  0  1  0  0]\n",
      " [ 0  0 11  0  1]\n",
      " [ 0  1  0  4  0]\n",
      " [ 0  0  1  0 20]]\n",
      "Akurasi Data Uji: 0.9019607843137255 = 0.9019607843137255\n",
      "Akurasi Data Latih: 1.0\n",
      "\n",
      "MLPClassifier(activation='tanh', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=15, learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=2000, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "Loss Pelatihan :  0.04155859666184608\n",
      "Jumlah iterasi :  790\n",
      "Akurasi:  93.46\n",
      "SD:  5.37\n",
      "[[10  0  0  0  1]\n",
      " [ 1  0  1  0  0]\n",
      " [ 0  0 11  0  1]\n",
      " [ 0  1  0  4  0]\n",
      " [ 1  0  1  0 19]]\n",
      "Akurasi Data Uji: 0.8627450980392157 = 0.8627450980392157\n",
      "Akurasi Data Latih: 1.0\n",
      "\n",
      "MLPClassifier(activation='tanh', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=16, learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=2000, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "Loss Pelatihan :  0.03860391308289133\n",
      "Jumlah iterasi :  787\n",
      "Akurasi:  90.08\n",
      "SD:  7.26\n",
      "[[11  0  0  0  0]\n",
      " [ 1  0  1  0  0]\n",
      " [ 0  0 11  0  1]\n",
      " [ 0  0  0  5  0]\n",
      " [ 0  0  1  0 20]]\n",
      "Akurasi Data Uji: 0.9215686274509803 = 0.9215686274509803\n",
      "Akurasi Data Latih: 1.0\n",
      "\n",
      "MLPClassifier(activation='tanh', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=17, learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=2000, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "Loss Pelatihan :  0.04321175376959026\n",
      "Jumlah iterasi :  795\n",
      "Akurasi:  92.62\n",
      "SD:  6.800000000000001\n",
      "[[10  1  0  0  0]\n",
      " [ 1  0  1  0  0]\n",
      " [ 0  0 10  0  2]\n",
      " [ 0  0  2  3  0]\n",
      " [ 0  0  1  0 20]]\n",
      "Akurasi Data Uji: 0.8431372549019608 = 0.8431372549019608\n",
      "Akurasi Data Latih: 1.0\n",
      "\n",
      "MLPClassifier(activation='tanh', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=18, learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=2000, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "Loss Pelatihan :  0.03652287119603323\n",
      "Jumlah iterasi :  688\n",
      "Akurasi:  91.06\n",
      "SD:  9.86\n",
      "[[10  1  0  0  0]\n",
      " [ 1  1  0  0  0]\n",
      " [ 0  0 11  0  1]\n",
      " [ 1  0  2  2  0]\n",
      " [ 1  0  1  0 19]]\n",
      "Akurasi Data Uji: 0.8431372549019608 = 0.8431372549019608\n",
      "Akurasi Data Latih: 1.0\n",
      "\n",
      "MLPClassifier(activation='tanh', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=19, learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=2000, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "Loss Pelatihan :  0.043473547075213566\n",
      "Jumlah iterasi :  751\n",
      "Akurasi:  91.75\n",
      "SD:  6.04\n",
      "[[10  1  0  0  0]\n",
      " [ 1  0  1  0  0]\n",
      " [ 0  0 10  0  2]\n",
      " [ 0  1  0  4  0]\n",
      " [ 0  0  1  0 20]]\n",
      "Akurasi Data Uji: 0.8627450980392157 = 0.8627450980392157\n",
      "Akurasi Data Latih: 1.0\n",
      "\n",
      "MLPClassifier(activation='tanh', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=20, learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=2000, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "Loss Pelatihan :  0.03540303010138721\n",
      "Jumlah iterasi :  692\n",
      "Akurasi:  94.33\n",
      "SD:  5.970000000000001\n",
      "[[11  0  0  0  0]\n",
      " [ 1  0  1  0  0]\n",
      " [ 0  0 10  0  2]\n",
      " [ 0  0  2  3  0]\n",
      " [ 0  0  1  0 20]]\n",
      "Akurasi Data Uji: 0.8627450980392157 = 0.8627450980392157\n",
      "Akurasi Data Latih: 1.0\n",
      "\n",
      "MLPClassifier(activation='tanh', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=21, learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=2000, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "Loss Pelatihan :  0.03918264424891401\n",
      "Jumlah iterasi :  736\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Akurasi:  94.33\n",
      "SD:  5.970000000000001\n",
      "[[11  0  0  0  0]\n",
      " [ 1  0  1  0  0]\n",
      " [ 0  0 10  0  2]\n",
      " [ 0  1  0  4  0]\n",
      " [ 0  0  1  0 20]]\n",
      "Akurasi Data Uji: 0.8823529411764706 = 0.8823529411764706\n",
      "Akurasi Data Latih: 1.0\n",
      "\n",
      "MLPClassifier(activation='tanh', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=22, learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=2000, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "Loss Pelatihan :  0.03367665311829022\n",
      "Jumlah iterasi :  639\n",
      "Akurasi:  92.73\n",
      "SD:  8.88\n",
      "[[10  1  0  0  0]\n",
      " [ 1  0  1  0  0]\n",
      " [ 0  0 11  0  1]\n",
      " [ 0  1  0  4  0]\n",
      " [ 0  0  1  0 20]]\n",
      "Akurasi Data Uji: 0.8823529411764706 = 0.8823529411764706\n",
      "Akurasi Data Latih: 1.0\n",
      "\n",
      "MLPClassifier(activation='tanh', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=23, learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=2000, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "Loss Pelatihan :  0.03509086197213051\n",
      "Jumlah iterasi :  643\n",
      "Akurasi:  91.82000000000001\n",
      "SD:  8.309999999999999\n",
      "[[10  1  0  0  0]\n",
      " [ 1  0  1  0  0]\n",
      " [ 0  0 10  0  2]\n",
      " [ 0  1  0  4  0]\n",
      " [ 1  0  1  0 19]]\n",
      "Akurasi Data Uji: 0.8431372549019608 = 0.8431372549019608\n",
      "Akurasi Data Latih: 1.0\n",
      "\n",
      "MLPClassifier(activation='tanh', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=24, learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=2000, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "Loss Pelatihan :  0.036466221712179975\n",
      "Jumlah iterasi :  664\n",
      "Akurasi:  95.13000000000001\n",
      "SD:  4.65\n",
      "[[10  1  0  0  0]\n",
      " [ 1  1  0  0  0]\n",
      " [ 0  0 10  0  2]\n",
      " [ 1  0  0  4  0]\n",
      " [ 0  0  1  0 20]]\n",
      "Akurasi Data Uji: 0.8823529411764706 = 0.8823529411764706\n",
      "Akurasi Data Latih: 1.0\n",
      "\n",
      "MLPClassifier(activation='tanh', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=25, learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=2000, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "Loss Pelatihan :  0.035145904855677104\n",
      "Jumlah iterasi :  638\n",
      "Akurasi:  92.62\n",
      "SD:  5.79\n",
      "[[11  0  0  0  0]\n",
      " [ 1  0  1  0  0]\n",
      " [ 0  0 10  0  2]\n",
      " [ 0  1  0  4  0]\n",
      " [ 0  0  1  0 20]]\n",
      "Akurasi Data Uji: 0.8823529411764706 = 0.8823529411764706\n",
      "Akurasi Data Latih: 1.0\n",
      "\n",
      "MLPClassifier(activation='tanh', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=26, learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=2000, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "Loss Pelatihan :  0.032688105171226334\n",
      "Jumlah iterasi :  664\n",
      "Akurasi:  92.66\n",
      "SD:  6.819999999999999\n",
      "[[11  0  0  0  0]\n",
      " [ 1  1  0  0  0]\n",
      " [ 0  0 10  0  2]\n",
      " [ 0  0  1  4  0]\n",
      " [ 0  0  1  0 20]]\n",
      "Akurasi Data Uji: 0.9019607843137255 = 0.9019607843137255\n",
      "Akurasi Data Latih: 1.0\n",
      "\n",
      "MLPClassifier(activation='tanh', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=27, learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=2000, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "Loss Pelatihan :  0.03061595115826095\n",
      "Jumlah iterasi :  594\n",
      "Akurasi:  92.55\n",
      "SD:  4.5\n",
      "[[11  0  0  0  0]\n",
      " [ 1  0  1  0  0]\n",
      " [ 0  0 11  0  1]\n",
      " [ 0  1  1  3  0]\n",
      " [ 0  0  1  0 20]]\n",
      "Akurasi Data Uji: 0.8823529411764706 = 0.8823529411764706\n",
      "Akurasi Data Latih: 1.0\n",
      "\n",
      "MLPClassifier(activation='tanh', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=28, learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=2000, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "Loss Pelatihan :  0.029367141579808163\n",
      "Jumlah iterasi :  576\n",
      "Akurasi:  92.66\n",
      "SD:  6.819999999999999\n",
      "[[11  0  0  0  0]\n",
      " [ 1  0  1  0  0]\n",
      " [ 0  0 10  0  2]\n",
      " [ 0  1  1  3  0]\n",
      " [ 1  0  1  0 19]]\n",
      "Akurasi Data Uji: 0.8431372549019608 = 0.8431372549019608\n",
      "Akurasi Data Latih: 1.0\n",
      "\n",
      "MLPClassifier(activation='tanh', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=29, learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=2000, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "Loss Pelatihan :  0.03478550663920002\n",
      "Jumlah iterasi :  615\n",
      "Akurasi:  92.62\n",
      "SD:  6.800000000000001\n",
      "[[10  1  0  0  0]\n",
      " [ 1  1  0  0  0]\n",
      " [ 0  0 11  0  1]\n",
      " [ 0  0  1  4  0]\n",
      " [ 0  0  1  0 20]]\n",
      "Akurasi Data Uji: 0.9019607843137255 = 0.9019607843137255\n",
      "Akurasi Data Latih: 1.0\n",
      "\n",
      "MLPClassifier(activation='tanh', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=30, learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=2000, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "Loss Pelatihan :  0.030996452848015433\n",
      "Jumlah iterasi :  624\n",
      "Akurasi:  92.55\n",
      "SD:  5.27\n",
      "[[11  0  0  0  0]\n",
      " [ 1  1  0  0  0]\n",
      " [ 0  0 11  0  1]\n",
      " [ 0  1  0  4  0]\n",
      " [ 0  0  1  0 20]]\n",
      "Akurasi Data Uji: 0.9215686274509803 = 0.9215686274509803\n",
      "Akurasi Data Latih: 1.0\n",
      "\n",
      "MLPClassifier(activation='tanh', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=35, learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=2000, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "Loss Pelatihan :  0.03164414944180954\n",
      "Jumlah iterasi :  602\n",
      "Akurasi:  93.42\n",
      "SD:  5.35\n",
      "[[10  0  0  0  1]\n",
      " [ 1  0  1  0  0]\n",
      " [ 0  0 10  0  2]\n",
      " [ 1  1  1  2  0]\n",
      " [ 0  0  1  0 20]]\n",
      "Akurasi Data Uji: 0.8235294117647058 = 0.8235294117647058\n",
      "Akurasi Data Latih: 1.0\n",
      "\n",
      "MLPClassifier(activation='tanh', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=40, learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=2000, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "Loss Pelatihan :  0.026362329397920044\n",
      "Jumlah iterasi :  533\n",
      "Akurasi:  93.53\n",
      "SD:  8.959999999999999\n",
      "[[11  0  0  0  0]\n",
      " [ 1  0  1  0  0]\n",
      " [ 0  0 10  0  2]\n",
      " [ 0  0  0  5  0]\n",
      " [ 1  0  1  0 19]]\n",
      "Akurasi Data Uji: 0.8823529411764706 = 0.8823529411764706\n",
      "Akurasi Data Latih: 1.0\n",
      "\n",
      "MLPClassifier(activation='tanh', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=45, learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=2000, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "Loss Pelatihan :  0.028986019591782448\n",
      "Jumlah iterasi :  548\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Akurasi:  93.42\n",
      "SD:  5.35\n",
      "[[10  1  0  0  0]\n",
      " [ 1  0  1  0  0]\n",
      " [ 0  0 11  0  1]\n",
      " [ 0  1  0  4  0]\n",
      " [ 1  0  1  0 19]]\n",
      "Akurasi Data Uji: 0.8627450980392157 = 0.8627450980392157\n",
      "Akurasi Data Latih: 1.0\n",
      "\n",
      "MLPClassifier(activation='tanh', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=50, learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=2000, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "Loss Pelatihan :  0.023527017257979645\n",
      "Jumlah iterasi :  481\n",
      "Akurasi:  92.62\n",
      "SD:  6.800000000000001\n",
      "[[10  1  0  0  0]\n",
      " [ 1  0  1  0  0]\n",
      " [ 0  0 10  0  2]\n",
      " [ 0  1  1  3  0]\n",
      " [ 1  0  1  0 19]]\n",
      "Akurasi Data Uji: 0.8235294117647058 = 0.8235294117647058\n",
      "Akurasi Data Latih: 1.0\n",
      "\n",
      "MLPClassifier(activation='tanh', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=55, learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=2000, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "Loss Pelatihan :  0.0239625931589153\n",
      "Jumlah iterasi :  480\n",
      "Akurasi:  94.22\n",
      "SD:  4.01\n",
      "[[10  1  0  0  0]\n",
      " [ 1  0  1  0  0]\n",
      " [ 0  0 10  0  2]\n",
      " [ 0  0  1  4  0]\n",
      " [ 0  0  1  0 20]]\n",
      "Akurasi Data Uji: 0.8627450980392157 = 0.8627450980392157\n",
      "Akurasi Data Latih: 1.0\n",
      "\n",
      "MLPClassifier(activation='tanh', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=60, learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=2000, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "Loss Pelatihan :  0.02212084865293471\n",
      "Jumlah iterasi :  429\n",
      "Akurasi:  92.62\n",
      "SD:  6.800000000000001\n",
      "[[11  0  0  0  0]\n",
      " [ 1  0  1  0  0]\n",
      " [ 0  0 10  0  2]\n",
      " [ 0  1  0  4  0]\n",
      " [ 1  0  1  0 19]]\n",
      "Akurasi Data Uji: 0.8627450980392157 = 0.8627450980392157\n",
      "Akurasi Data Latih: 1.0\n",
      "\n",
      "MLPClassifier(activation='tanh', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=65, learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=2000, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "Loss Pelatihan :  0.022299576273871198\n",
      "Jumlah iterasi :  432\n",
      "Akurasi:  92.62\n",
      "SD:  6.800000000000001\n",
      "[[ 9  1  0  0  1]\n",
      " [ 1  0  1  0  0]\n",
      " [ 0  0 10  0  2]\n",
      " [ 0  1  1  3  0]\n",
      " [ 0  0  1  0 20]]\n",
      "Akurasi Data Uji: 0.8235294117647058 = 0.8235294117647058\n",
      "Akurasi Data Latih: 1.0\n",
      "\n",
      "MLPClassifier(activation='tanh', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=70, learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=2000, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "Loss Pelatihan :  0.025874384609564968\n",
      "Jumlah iterasi :  506\n",
      "Akurasi:  94.33\n",
      "SD:  5.970000000000001\n",
      "[[10  1  0  0  0]\n",
      " [ 1  0  1  0  0]\n",
      " [ 0  0 10  0  2]\n",
      " [ 0  1  0  4  0]\n",
      " [ 1  0  1  0 19]]\n",
      "Akurasi Data Uji: 0.8431372549019608 = 0.8431372549019608\n",
      "Akurasi Data Latih: 1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Latih kecerdasan buatan dengan data latih, menggunakan MLP-NN\n",
    "df = pd.read_excel('Data-20Fitur-20Citra-20Sel-20Darah.xlsx', header=0, sheet_name ='Data Fitur Citra Sel Darah2')\n",
    "df = df.drop(datset[0], axis=1)\n",
    "#df = df[datset[6]]\n",
    "print(df[0:0])\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "i=10\n",
    "data = [ ]\n",
    "layers = [ ]\n",
    "loss = [ ]\n",
    "iterasi = [ ]\n",
    "cv_score = [ ]\n",
    "std_cv = [ ]\n",
    "while (i<75):\n",
    "    clf = MLPClassifier(activation='tanh',solver='adam', alpha=1e-5, max_iter=2000,\n",
    "                    hidden_layer_sizes=(i), random_state=1)\n",
    "    print(clf.fit(X_train, y_train))\n",
    "    if(i>=30):\n",
    "        i=i+5\n",
    "    elif(i<30):  \n",
    "        i=i+1\n",
    "\n",
    "    print('Loss Pelatihan : ', clf.loss_)    \n",
    "    print('Jumlah iterasi : ', clf.n_iter_)\n",
    "    \n",
    "    from sklearn.model_selection import cross_val_score\n",
    "    scoring='accuracy'\n",
    "    accuracies = cross_val_score(estimator=clf, X=X_train, y=y_train, cv=5,scoring=scoring)\n",
    "    avg_accuracy = float('{0:.4f}'.format(accuracies.mean()))*100\n",
    "    std_accuracy =  float('{0:.4f}'.format(accuracies.std()))*100\n",
    "    print('Akurasi: ', avg_accuracy)\n",
    "    print('SD: ', std_accuracy)\n",
    "    \n",
    "    #Prediksi Data Uji\n",
    "    result = clf.predict(X_test)\n",
    "\n",
    "    #Confusion Matriks Hasil Prediksi dengan Nilai Sebenarnya\n",
    "    from sklearn.metrics import classification_report,confusion_matrix\n",
    "    print(confusion_matrix(y_test,result))\n",
    "\n",
    "    # Cek kemampuan kecerdasan buatan dengan data uji \n",
    "    test_accuracy = clf.score(X_test, y_test)\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    akurasi = accuracy_score(y_test, result)\n",
    "    print('Akurasi Data Uji:', test_accuracy , '=', akurasi)\n",
    "\n",
    "    # Cek kemampuan kecerdasan buatan dengan data uji \n",
    "    train_accuracy = clf.score(X_train, y_train)\n",
    "    print('Akurasi Data Latih:', train_accuracy)  \n",
    "\n",
    "    layers.append(i)\n",
    "    data.append( float('{0:.4f}'.format(test_accuracy))*100)\n",
    "    loss.append(clf.loss_)\n",
    "    iterasi.append(clf.n_iter_)\n",
    "    cv_score.append(avg_accuracy)\n",
    "    std_cv.append(std_accuracy)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[88.24,\n",
       " 86.27,\n",
       " 88.24,\n",
       " 86.27,\n",
       " 90.2,\n",
       " 86.27,\n",
       " 92.16,\n",
       " 84.31,\n",
       " 84.31,\n",
       " 86.27,\n",
       " 86.27,\n",
       " 88.24,\n",
       " 88.24,\n",
       " 84.31,\n",
       " 88.24,\n",
       " 88.24,\n",
       " 90.2,\n",
       " 88.24,\n",
       " 84.31,\n",
       " 90.2,\n",
       " 92.16,\n",
       " 82.35,\n",
       " 88.24,\n",
       " 86.27,\n",
       " 82.35,\n",
       " 86.27,\n",
       " 86.27,\n",
       " 82.35,\n",
       " 84.31]"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neuron</th>\n",
       "      <th>akurasi</th>\n",
       "      <th>loss</th>\n",
       "      <th>iter</th>\n",
       "      <th>cv</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11.0</td>\n",
       "      <td>88.24</td>\n",
       "      <td>0.049220</td>\n",
       "      <td>1018.0</td>\n",
       "      <td>93.53</td>\n",
       "      <td>7.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12.0</td>\n",
       "      <td>86.27</td>\n",
       "      <td>0.045746</td>\n",
       "      <td>990.0</td>\n",
       "      <td>91.86</td>\n",
       "      <td>8.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.0</td>\n",
       "      <td>88.24</td>\n",
       "      <td>0.046902</td>\n",
       "      <td>911.0</td>\n",
       "      <td>91.75</td>\n",
       "      <td>7.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.0</td>\n",
       "      <td>86.27</td>\n",
       "      <td>0.041818</td>\n",
       "      <td>792.0</td>\n",
       "      <td>92.66</td>\n",
       "      <td>5.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15.0</td>\n",
       "      <td>90.20</td>\n",
       "      <td>0.045347</td>\n",
       "      <td>761.0</td>\n",
       "      <td>91.82</td>\n",
       "      <td>7.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>16.0</td>\n",
       "      <td>86.27</td>\n",
       "      <td>0.041559</td>\n",
       "      <td>790.0</td>\n",
       "      <td>93.46</td>\n",
       "      <td>5.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>17.0</td>\n",
       "      <td>92.16</td>\n",
       "      <td>0.038604</td>\n",
       "      <td>787.0</td>\n",
       "      <td>90.08</td>\n",
       "      <td>7.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>18.0</td>\n",
       "      <td>84.31</td>\n",
       "      <td>0.043212</td>\n",
       "      <td>795.0</td>\n",
       "      <td>92.62</td>\n",
       "      <td>6.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>19.0</td>\n",
       "      <td>84.31</td>\n",
       "      <td>0.036523</td>\n",
       "      <td>688.0</td>\n",
       "      <td>91.06</td>\n",
       "      <td>9.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>20.0</td>\n",
       "      <td>86.27</td>\n",
       "      <td>0.043474</td>\n",
       "      <td>751.0</td>\n",
       "      <td>91.75</td>\n",
       "      <td>6.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>21.0</td>\n",
       "      <td>86.27</td>\n",
       "      <td>0.035403</td>\n",
       "      <td>692.0</td>\n",
       "      <td>94.33</td>\n",
       "      <td>5.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>22.0</td>\n",
       "      <td>88.24</td>\n",
       "      <td>0.039183</td>\n",
       "      <td>736.0</td>\n",
       "      <td>94.33</td>\n",
       "      <td>5.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>23.0</td>\n",
       "      <td>88.24</td>\n",
       "      <td>0.033677</td>\n",
       "      <td>639.0</td>\n",
       "      <td>92.73</td>\n",
       "      <td>8.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>24.0</td>\n",
       "      <td>84.31</td>\n",
       "      <td>0.035091</td>\n",
       "      <td>643.0</td>\n",
       "      <td>91.82</td>\n",
       "      <td>8.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>25.0</td>\n",
       "      <td>88.24</td>\n",
       "      <td>0.036466</td>\n",
       "      <td>664.0</td>\n",
       "      <td>95.13</td>\n",
       "      <td>4.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>26.0</td>\n",
       "      <td>88.24</td>\n",
       "      <td>0.035146</td>\n",
       "      <td>638.0</td>\n",
       "      <td>92.62</td>\n",
       "      <td>5.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>27.0</td>\n",
       "      <td>90.20</td>\n",
       "      <td>0.032688</td>\n",
       "      <td>664.0</td>\n",
       "      <td>92.66</td>\n",
       "      <td>6.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>28.0</td>\n",
       "      <td>88.24</td>\n",
       "      <td>0.030616</td>\n",
       "      <td>594.0</td>\n",
       "      <td>92.55</td>\n",
       "      <td>4.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>29.0</td>\n",
       "      <td>84.31</td>\n",
       "      <td>0.029367</td>\n",
       "      <td>576.0</td>\n",
       "      <td>92.66</td>\n",
       "      <td>6.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>30.0</td>\n",
       "      <td>90.20</td>\n",
       "      <td>0.034786</td>\n",
       "      <td>615.0</td>\n",
       "      <td>92.62</td>\n",
       "      <td>6.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>35.0</td>\n",
       "      <td>92.16</td>\n",
       "      <td>0.030996</td>\n",
       "      <td>624.0</td>\n",
       "      <td>92.55</td>\n",
       "      <td>5.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>40.0</td>\n",
       "      <td>82.35</td>\n",
       "      <td>0.031644</td>\n",
       "      <td>602.0</td>\n",
       "      <td>93.42</td>\n",
       "      <td>5.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>45.0</td>\n",
       "      <td>88.24</td>\n",
       "      <td>0.026362</td>\n",
       "      <td>533.0</td>\n",
       "      <td>93.53</td>\n",
       "      <td>8.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>50.0</td>\n",
       "      <td>86.27</td>\n",
       "      <td>0.028986</td>\n",
       "      <td>548.0</td>\n",
       "      <td>93.42</td>\n",
       "      <td>5.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>55.0</td>\n",
       "      <td>82.35</td>\n",
       "      <td>0.023527</td>\n",
       "      <td>481.0</td>\n",
       "      <td>92.62</td>\n",
       "      <td>6.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>60.0</td>\n",
       "      <td>86.27</td>\n",
       "      <td>0.023963</td>\n",
       "      <td>480.0</td>\n",
       "      <td>94.22</td>\n",
       "      <td>4.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>65.0</td>\n",
       "      <td>86.27</td>\n",
       "      <td>0.022121</td>\n",
       "      <td>429.0</td>\n",
       "      <td>92.62</td>\n",
       "      <td>6.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>70.0</td>\n",
       "      <td>82.35</td>\n",
       "      <td>0.022300</td>\n",
       "      <td>432.0</td>\n",
       "      <td>92.62</td>\n",
       "      <td>6.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>75.0</td>\n",
       "      <td>84.31</td>\n",
       "      <td>0.025874</td>\n",
       "      <td>506.0</td>\n",
       "      <td>94.33</td>\n",
       "      <td>5.97</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    neuron  akurasi      loss    iter     cv   std\n",
       "0     11.0    88.24  0.049220  1018.0  93.53  7.40\n",
       "1     12.0    86.27  0.045746   990.0  91.86  8.33\n",
       "2     13.0    88.24  0.046902   911.0  91.75  7.88\n",
       "3     14.0    86.27  0.041818   792.0  92.66  5.81\n",
       "4     15.0    90.20  0.045347   761.0  91.82  7.06\n",
       "5     16.0    86.27  0.041559   790.0  93.46  5.37\n",
       "6     17.0    92.16  0.038604   787.0  90.08  7.26\n",
       "7     18.0    84.31  0.043212   795.0  92.62  6.80\n",
       "8     19.0    84.31  0.036523   688.0  91.06  9.86\n",
       "9     20.0    86.27  0.043474   751.0  91.75  6.04\n",
       "10    21.0    86.27  0.035403   692.0  94.33  5.97\n",
       "11    22.0    88.24  0.039183   736.0  94.33  5.97\n",
       "12    23.0    88.24  0.033677   639.0  92.73  8.88\n",
       "13    24.0    84.31  0.035091   643.0  91.82  8.31\n",
       "14    25.0    88.24  0.036466   664.0  95.13  4.65\n",
       "15    26.0    88.24  0.035146   638.0  92.62  5.79\n",
       "16    27.0    90.20  0.032688   664.0  92.66  6.82\n",
       "17    28.0    88.24  0.030616   594.0  92.55  4.50\n",
       "18    29.0    84.31  0.029367   576.0  92.66  6.82\n",
       "19    30.0    90.20  0.034786   615.0  92.62  6.80\n",
       "20    35.0    92.16  0.030996   624.0  92.55  5.27\n",
       "21    40.0    82.35  0.031644   602.0  93.42  5.35\n",
       "22    45.0    88.24  0.026362   533.0  93.53  8.96\n",
       "23    50.0    86.27  0.028986   548.0  93.42  5.35\n",
       "24    55.0    82.35  0.023527   481.0  92.62  6.80\n",
       "25    60.0    86.27  0.023963   480.0  94.22  4.01\n",
       "26    65.0    86.27  0.022121   429.0  92.62  6.80\n",
       "27    70.0    82.35  0.022300   432.0  92.62  6.80\n",
       "28    75.0    84.31  0.025874   506.0  94.33  5.97"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "summary = [ ]\n",
    "i=0\n",
    "while(i<len(layers)):\n",
    "    summary.append([layers[i],data[i],loss[i], iterasi[i], cv_score[i],std_cv[i]]) \n",
    "    i+=1\n",
    "    \n",
    "df = pd.DataFrame(np.array(summary))\n",
    "df.columns = (['neuron','akurasi','loss','iter','cv','std'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29\n",
      "21 84.31 0.035938884777448554 694 92.66 7.88\n",
      "[11, 90.2, 0.050450511668717224, 930, 86.52, 6.58]\n",
      "[12, 82.35, 0.05680783821934331, 988, 86.74, 7.449999999999999]\n",
      "[13, 92.16, 0.047442964212159246, 931, 86.74, 7.42]\n",
      "[14, 86.27, 0.044520075628349226, 802, 88.41, 4.9399999999999995]\n",
      "[15, 84.31, 0.049718365090960795, 830, 90.14999999999999, 6.18]\n",
      "[16, 84.31, 0.046359916223405566, 829, 90.95, 6.87]\n",
      "[17, 84.31, 0.039116989957169765, 749, 90.95, 5.91]\n",
      "[18, 90.2, 0.038685165424984694, 724, 90.01, 6.510000000000001]\n",
      "[19, 88.24, 0.04457548773684558, 808, 93.53, 5.58]\n",
      "[20, 84.31, 0.035938884777448554, 694, 92.66, 7.88]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-152-ad6b0ee04601>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mwhile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m<\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterasi\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv_score\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstd_cv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mi\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "print(len(layers))\n",
    "print(layers[10],data[9],loss[9], iterasi[9], cv_score[9],std_cv[9])\n",
    "i=0\n",
    "while(i<len(layers)):\n",
    "    print([layers[i],data[i],loss[i], iterasi[i], cv_score[i],std_cv[i]]) \n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Jenis, Solidity_Inti, Granularity_Inti, Circularity_Inti, RerataR_Inti, RerataG_Inti, RerataB_Inti, Entropi_Inti, Energi_Inti, Kontras_Inti, Homogenitas_Inti, LuasP, KelilingP, SolidityP, GranularityP, CircularityP, RerataRP, RerataGP, RerataBP, EntropiP, EnergiP, KontrasP, HomogenitasP, LuasNormal_P, KelilingNormal_I, Eccentricity, LIperLP , KIperKP]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 28 columns]\n",
      "MLPClassifier(activation='tanh', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=28, learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=2000, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "Akurasi:  93.35\n",
      "SD:  3.02\n",
      "[[10  1  0  0  0]\n",
      " [ 1  1  0  0  0]\n",
      " [ 0  0 12  0  0]\n",
      " [ 0  0  0  5  0]\n",
      " [ 0  0  1  0 20]]\n",
      "akurasi latih:  100.0\n",
      "akurasi uji:  94.12\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_excel('Data-20Fitur-20Citra-20Sel-20Darah.xlsx', header=0,sheet_name='Data Fitur Citra Sel Darah2')\n",
    "df = df.drop(datset[0], axis=1)\n",
    "#df = df[Jenis, k1]\n",
    "print(df[0:0])\n",
    "\n",
    "import numpy as np\n",
    "y= np.array(df)[:,0]           #membuat dataset target y\n",
    "X = np.array(df)[:,1:30]    #membuat dataset input X\n",
    "\n",
    "# Pisahkan dataset menjadi data latih dan uji dengan perbandingan 80:20\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.30, random_state=0)\n",
    "\n",
    "# Penyekalaan fitur dilakukan pada data latih dan uji.\n",
    "# Detail kenapa ini penting dijelaskan di sini: http://scikit-learn.org/stable/auto_examples/preprocessing/plot_scaling_importance.html\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "\n",
    "# Fungsi fit_transform hanya dilakukan di data latih\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    " # Latih kecerdasan buatan dengan data latih, menggunakan MLP-NN\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import time\n",
    "\n",
    "clf = MLPClassifier(activation='tanh',solver='adam', alpha=1e-5, max_iter=2000,\n",
    "            hidden_layer_sizes=(28), random_state=1)\n",
    "start = time.time()\n",
    "print(clf.fit(X_train, y_train))\n",
    "end = time.time()\n",
    "waktuTrain = end - start\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "scoring='accuracy'\n",
    "accuracies = cross_val_score(estimator=clf, X=X_train, y=y_train, cv=5,scoring=scoring)\n",
    "avg_accuracy = float('{0:.4f}'.format(accuracies.mean()))*100\n",
    "std_accuracy =  float('{0:.4f}'.format(accuracies.std()))*100\n",
    "print('Akurasi: ', avg_accuracy)\n",
    "print('SD: ', std_accuracy)\n",
    "\n",
    "\n",
    "#prediksi\n",
    "start = time.time()\n",
    "result = clf.predict(X_test)\n",
    "end = time.time()\n",
    "waktuTest = end - start\n",
    "\n",
    "#Confusion Matriks Hasil Prediksi dengan Nilai Sebenarnya\n",
    "from sklearn.metrics import classification_report,confusion_matrix, roc_auc_score\n",
    "print(confusion_matrix(y_test,result))\n",
    "\n",
    "# Cek kemampuan kecerdasan buatan dengan data uji \n",
    "train_accuracy = float('{0:.4f}'.format(clf.score(X_train, y_train)))*100\n",
    "print(\"akurasi latih: \",train_accuracy)\n",
    "\n",
    "# Cek kemampuan kecerdasan buatan dengan data uji \n",
    "test_accuracy = float('{0:.4f}'.format(clf.score(X_test, y_test)))*100\n",
    "print(\"akurasi uji: \",test_accuracy)\n",
    "\n",
    "train.append(train_accuracy)\n",
    "cv_score.append(avg_accuracy)\n",
    "cv_std.append(std_accuracy)\n",
    "test.append(test_accuracy)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
