{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#adam\n",
    "k1 =[ 'Luas_Inti','Keliling_Inti']\n",
    "k2 = ['Granularity_Inti','GranularityP']\n",
    "k3 = ['Circularity_Inti','CircularityP','Eccentricity']\n",
    "k4 = ['RerataR_Inti','RerataG_Inti','RerataB_Inti']\n",
    "k5 = ['Solidity_Inti','Entropi_Inti','Energi_Inti','Kontras_Inti','Homogenitas_Inti']\n",
    "k6 = ['LuasP','KelilingP']\n",
    "k7 = ['RerataRP','RerataGP','RerataBP']\n",
    "k8 = ['SolidityP','EntropiP','EnergiP','KontrasP','HomogenitasP']\n",
    "k9 = ['LuasNormal_P','KelilingNormal_I']\n",
    "k10 =[ 'LIperLP ','KIperKP']\n",
    "\n",
    "datset = [k1,k2,k3,k4,k5,k6,k7,k8,k9,k10]\n",
    "\n",
    "#[90.2, 84.31, 82.35, 86.27, 90.2, 88.24, 86.27, 80.39, 88.24, 80.39]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#lbfgs\n",
    "k2 = ['Jenis','Granularity_Inti','GranularityP']\n",
    "k8 = ['Jenis','Granularity_Inti','GranularityP','SolidityP','EntropiP','EnergiP','KontrasP','HomogenitasP']\n",
    "k10 =['Jenis','Granularity_Inti','GranularityP','SolidityP','EntropiP','EnergiP','KontrasP','HomogenitasP', 'LIperLP ','KIperKP']\n",
    "k7 = ['Granularity_Inti','GranularityP','SolidityP','EntropiP','EnergiP','KontrasP','HomogenitasP', 'LIperLP ','KIperKP','RerataRP','RerataGP','RerataBP']\n",
    "k4 = ['Granularity_Inti','GranularityP','SolidityP','EntropiP','EnergiP','KontrasP','HomogenitasP', 'LIperLP ','KIperKP','RerataRP','RerataGP','RerataBP','RerataR_Inti','RerataG_Inti','RerataB_Inti']\n",
    "k9 = ['Granularity_Inti','GranularityP','SolidityP','EntropiP','EnergiP','KontrasP','HomogenitasP', 'LIperLP ','KIperKP','RerataRP','RerataGP','RerataBP','RerataR_Inti','RerataG_Inti','RerataB_Inti','LuasNormal_P','KelilingNormal_I']\n",
    "k3 = ['Jenis','Granularity_Inti','GranularityP','SolidityP','EntropiP','EnergiP','KontrasP','HomogenitasP', 'LIperLP ','KIperKP','RerataRP','RerataGP','RerataBP','RerataR_Inti','RerataG_Inti','RerataB_Inti','LuasNormal_P','KelilingNormal_I','Circularity_Inti','CircularityP','Eccentricity']\n",
    "k1 =[ 'Jenis','Granularity_Inti','GranularityP','SolidityP','EntropiP','EnergiP','KontrasP','HomogenitasP', 'LIperLP ','KIperKP','RerataRP','RerataGP','RerataBP','RerataR_Inti','RerataG_Inti','RerataB_Inti','LuasNormal_P','KelilingNormal_I','Circularity_Inti','CircularityP','Eccentricity','Luas_Inti','Keliling_Inti']\n",
    "k6 = ['Jenis','Granularity_Inti','GranularityP','SolidityP','EntropiP','EnergiP','KontrasP','HomogenitasP', 'LIperLP ','KIperKP','RerataRP','RerataGP','RerataBP','RerataR_Inti','RerataG_Inti','RerataB_Inti','LuasNormal_P','KelilingNormal_I','Circularity_Inti','CircularityP','Eccentricity','Luas_Inti','Keliling_Inti','LuasP','KelilingP']\n",
    "k5 = ['Jenis','Granularity_Inti','GranularityP','SolidityP','EntropiP','EnergiP','KontrasP','HomogenitasP', 'LIperLP ','KIperKP','RerataRP','RerataGP','RerataBP','RerataR_Inti','RerataG_Inti','RerataB_Inti','LuasNormal_P','KelilingNormal_I','Circularity_Inti','CircularityP','Eccentricity','Luas_Inti','Keliling_Inti','LuasP','KelilingP','Solidity_Inti','Entropi_Inti','Energi_Inti','Kontras_Inti','Homogenitas_Inti']\n",
    "\n",
    "datset = [k2, k8, k10, k7, k4, k9, k3, k1, k6, k5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "head = ['Luas_Inti','Keliling_Inti','Solidity_Inti','Granularity_Inti',\n",
    "        'Circularity_Inti','RerataR_Inti','RerataG_Inti','RerataB_Inti','Entropi_Inti',\n",
    "        'Energi_Inti','Kontras_Inti','Homogenitas_Inti','LuasP','KelilingP','SolidityP',\n",
    "        'GranularityP','CircularityP','RerataRP','RerataGP','RerataBP','EntropiP','EnergiP',\n",
    "        'KontrasP','HomogenitasP','LuasNormal_P','KelilingNormal_I','Eccentricity','LIperLP ','KIperKP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Jenis, Luas_Inti, Keliling_Inti, Solidity_Inti, Granularity_Inti, Circularity_Inti, RerataR_Inti, RerataG_Inti, RerataB_Inti, Entropi_Inti, Energi_Inti, Kontras_Inti, Homogenitas_Inti, LuasP, KelilingP, SolidityP, GranularityP, CircularityP, RerataRP, RerataGP, RerataBP, EntropiP, EnergiP, KontrasP, HomogenitasP, LuasNormal_P, KelilingNormal_I, Eccentricity, LIperLP , KIperKP]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 30 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramFiles\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_excel('Data-20Fitur-20Citra-20Sel-20Darah.xlsx', header=0,sheet_name='Data Fitur Citra Sel Darah2')\n",
    "#df = daf.drop(datset[i], axis=1)\n",
    "#df = df[datset[4]]\n",
    "print(df[0:0])\n",
    "\n",
    "import numpy as np\n",
    "y= np.array(df)[:,0]           #membuat dataset target y\n",
    "X = np.array(df)[:,1:30]    #membuat dataset input X\n",
    "\n",
    "# Pisahkan dataset menjadi data latih dan uji dengan perbandingan 80:20\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.30, random_state=0)\n",
    "\n",
    "# Penyekalaan fitur dilakukan pada data latih dan uji.\n",
    "# Detail kenapa ini penting dijelaskan di sini: http://scikit-learn.org/stable/auto_examples/preprocessing/plot_scaling_importance.html\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "\n",
    "# Fungsi fit_transform hanya dilakukan di data latih\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15, 35]\n",
      "[19, 35, 36, 62, 117]\n"
     ]
    }
   ],
   "source": [
    "def cariRow(dataIn,  dataOut ):\n",
    "    np.ravel(dataIn)\n",
    "    x=0\n",
    "    while x < len(dataIn):\n",
    "        if dataIn[x] == 2:\n",
    "            dataOut.append(x)\n",
    "        x=x+1\n",
    "\n",
    "index_test = [ ]\n",
    "index_train = [ ]\n",
    "cariRow(y_train,index_train)\n",
    "cariRow(y_test,index_test)\n",
    "print(index_test)\n",
    "print(index_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5.,  3.,  5.,  3.,  5.,  3.,  1.,  1.,  3.,  5.,  3.,  4.,  5.,\n",
       "        5.,  3.,  3.,  4.,  5.,  4.,  5.,  5.,  5.,  5.,  3.,  5.,  1.,\n",
       "        5.,  5.,  1.,  1.,  5.,  5.,  1.,  3.,  1.,  3.,  4.,  1.,  5.,\n",
       "        5.,  5.,  1.,  3.,  5.,  1.,  5.,  1.,  3.,  4.])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Remove Eosinofil Feature from X_train\n",
    "df = pd.DataFrame(np.array(X_train))\n",
    "df.columns = (head)\n",
    "df = df[datset[4]]\n",
    "df = df.drop(df.index[[19,35,36,62,117]])\n",
    "X_train= np.array(df)\n",
    "X_train\n",
    "\n",
    "#Remove Eosinofil Feature from y_train\n",
    "df = pd.DataFrame(np.array(y_train))\n",
    "new_df = df.drop(df.index[[19,35,36,62,117]])\n",
    "y_train= np.ravel(np.array(new_df))\n",
    "y_train\n",
    "\n",
    "#Remove Eosinofil Feature from X_test\n",
    "df = pd.DataFrame(np.array(X_test))\n",
    "df.columns = (head)\n",
    "df = df[datset[4]]\n",
    "new_df = df.drop(df.index[[15,35]])\n",
    "X_test= np.array(new_df)\n",
    "X_test\n",
    "\n",
    "#Remove Eosinofil Feature from y_test\n",
    "df = pd.DataFrame(np.array(y_test))\n",
    "new_df = df.drop(df.index[[15,35]])\n",
    "y_test= np.ravel(np.array(new_df))\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'indeks' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-27cc4da95486>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mindeks\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'indeks' is not defined"
     ]
    }
   ],
   "source": [
    "indeks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier(activation='relu', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=10, learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=2000, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
      "       solver='lbfgs', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "Loss Pelatihan :  6.98126363658e-05\n",
      "Jumlah iterasi :  27\n",
      "Akurasi:  89.53\n",
      "SD:  5.47\n",
      "[[11  0  0  0]\n",
      " [ 0 11  0  1]\n",
      " [ 1  1  3  0]\n",
      " [ 1  1  0 19]]\n",
      "Akurasi Data Uji: 0.897959183673 = 0.897959183673\n",
      "Akurasi Data Latih: 1.0\n",
      "\n",
      "MLPClassifier(activation='relu', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=11, learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=2000, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
      "       solver='lbfgs', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "Loss Pelatihan :  4.77573116441e-05\n",
      "Jumlah iterasi :  22\n",
      "Akurasi:  90.56\n",
      "SD:  7.91\n",
      "[[11  0  0  0]\n",
      " [ 0 11  0  1]\n",
      " [ 1  0  4  0]\n",
      " [ 0  1  0 20]]\n",
      "Akurasi Data Uji: 0.938775510204 = 0.938775510204\n",
      "Akurasi Data Latih: 1.0\n",
      "\n",
      "MLPClassifier(activation='relu', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=12, learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=2000, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
      "       solver='lbfgs', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "Loss Pelatihan :  4.78688474062e-05\n",
      "Jumlah iterasi :  24\n",
      "Akurasi:  90.61\n",
      "SD:  8.44\n",
      "[[11  0  0  0]\n",
      " [ 0 11  0  1]\n",
      " [ 0  0  5  0]\n",
      " [ 0  1  0 20]]\n",
      "Akurasi Data Uji: 0.959183673469 = 0.959183673469\n",
      "Akurasi Data Latih: 1.0\n",
      "\n",
      "MLPClassifier(activation='relu', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=13, learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=2000, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
      "       solver='lbfgs', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "Loss Pelatihan :  6.19780164586e-05\n",
      "Jumlah iterasi :  21\n",
      "Akurasi:  86.97\n",
      "SD:  8.51\n",
      "[[11  0  0  0]\n",
      " [ 0 11  0  1]\n",
      " [ 0  0  5  0]\n",
      " [ 0  1  0 20]]\n",
      "Akurasi Data Uji: 0.959183673469 = 0.959183673469\n",
      "Akurasi Data Latih: 1.0\n",
      "\n",
      "MLPClassifier(activation='relu', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=14, learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=2000, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
      "       solver='lbfgs', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "Loss Pelatihan :  7.84804200522e-05\n",
      "Jumlah iterasi :  20\n",
      "Akurasi:  89.7\n",
      "SD:  8.110000000000001\n",
      "[[11  0  0  0]\n",
      " [ 0  9  0  3]\n",
      " [ 0  0  5  0]\n",
      " [ 0  1  0 20]]\n",
      "Akurasi Data Uji: 0.918367346939 = 0.918367346939\n",
      "Akurasi Data Latih: 1.0\n",
      "\n",
      "MLPClassifier(activation='relu', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=15, learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=2000, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
      "       solver='lbfgs', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "Loss Pelatihan :  8.12099319936e-05\n",
      "Jumlah iterasi :  21\n",
      "Akurasi:  88.7\n",
      "SD:  7.07\n",
      "[[11  0  0  0]\n",
      " [ 0 11  0  1]\n",
      " [ 1  0  4  0]\n",
      " [ 0  1  0 20]]\n",
      "Akurasi Data Uji: 0.938775510204 = 0.938775510204\n",
      "Akurasi Data Latih: 1.0\n",
      "\n",
      "MLPClassifier(activation='relu', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=16, learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=2000, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
      "       solver='lbfgs', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "Loss Pelatihan :  8.48311177263e-05\n",
      "Jumlah iterasi :  21\n",
      "Akurasi:  88.74\n",
      "SD:  5.38\n",
      "[[11  0  0  0]\n",
      " [ 0 10  0  2]\n",
      " [ 0  1  4  0]\n",
      " [ 1  1  0 19]]\n",
      "Akurasi Data Uji: 0.897959183673 = 0.897959183673\n",
      "Akurasi Data Latih: 1.0\n",
      "\n",
      "MLPClassifier(activation='relu', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=17, learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=2000, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
      "       solver='lbfgs', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "Loss Pelatihan :  3.60670345083e-05\n",
      "Jumlah iterasi :  22\n",
      "Akurasi:  88.7\n",
      "SD:  7.07\n",
      "[[11  0  0  0]\n",
      " [ 0 10  0  2]\n",
      " [ 0  0  5  0]\n",
      " [ 0  1  0 20]]\n",
      "Akurasi Data Uji: 0.938775510204 = 0.938775510204\n",
      "Akurasi Data Latih: 1.0\n",
      "\n",
      "MLPClassifier(activation='relu', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=18, learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=2000, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
      "       solver='lbfgs', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "Loss Pelatihan :  5.10727442494e-05\n",
      "Jumlah iterasi :  22\n",
      "Akurasi:  91.52\n",
      "SD:  9.13\n",
      "[[11  0  0  0]\n",
      " [ 0 10  0  2]\n",
      " [ 0  1  4  0]\n",
      " [ 0  1  0 20]]\n",
      "Akurasi Data Uji: 0.918367346939 = 0.918367346939\n",
      "Akurasi Data Latih: 1.0\n",
      "\n",
      "MLPClassifier(activation='relu', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=19, learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=2000, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
      "       solver='lbfgs', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "Loss Pelatihan :  6.40394677992e-05\n",
      "Jumlah iterasi :  19\n",
      "Akurasi:  89.61\n",
      "SD:  7.57\n",
      "[[11  0  0  0]\n",
      " [ 0 11  0  1]\n",
      " [ 0  0  5  0]\n",
      " [ 1  1  0 19]]\n",
      "Akurasi Data Uji: 0.938775510204 = 0.938775510204\n",
      "Akurasi Data Latih: 1.0\n",
      "\n",
      "MLPClassifier(activation='relu', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=20, learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=2000, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
      "       solver='lbfgs', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "Loss Pelatihan :  3.34758201506e-05\n",
      "Jumlah iterasi :  22\n",
      "Akurasi:  87.79\n",
      "SD:  6.41\n",
      "[[11  0  0  0]\n",
      " [ 0 10  0  2]\n",
      " [ 0  0  5  0]\n",
      " [ 0  1  0 20]]\n",
      "Akurasi Data Uji: 0.938775510204 = 0.938775510204\n",
      "Akurasi Data Latih: 1.0\n",
      "\n",
      "MLPClassifier(activation='relu', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=21, learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=2000, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
      "       solver='lbfgs', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "Loss Pelatihan :  0.000100371208074\n",
      "Jumlah iterasi :  20\n",
      "Akurasi:  91.52\n",
      "SD:  8.67\n",
      "[[11  0  0  0]\n",
      " [ 1 10  0  1]\n",
      " [ 0  0  5  0]\n",
      " [ 1  1  0 19]]\n",
      "Akurasi Data Uji: 0.918367346939 = 0.918367346939\n",
      "Akurasi Data Latih: 1.0\n",
      "\n",
      "MLPClassifier(activation='relu', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=22, learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=2000, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
      "       solver='lbfgs', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "Loss Pelatihan :  4.45697584763e-05\n",
      "Jumlah iterasi :  21\n",
      "Akurasi:  89.61\n",
      "SD:  7.57\n",
      "[[11  0  0  0]\n",
      " [ 0 10  0  2]\n",
      " [ 0  0  5  0]\n",
      " [ 0  1  0 20]]\n",
      "Akurasi Data Uji: 0.938775510204 = 0.938775510204\n",
      "Akurasi Data Latih: 1.0\n",
      "\n",
      "MLPClassifier(activation='relu', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=23, learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=2000, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
      "       solver='lbfgs', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "Loss Pelatihan :  0.000128235832126\n",
      "Jumlah iterasi :  20\n",
      "Akurasi:  88.7\n",
      "SD:  7.07\n",
      "[[11  0  0  0]\n",
      " [ 0 10  0  2]\n",
      " [ 0  0  5  0]\n",
      " [ 1  1  0 19]]\n",
      "Akurasi Data Uji: 0.918367346939 = 0.918367346939\n",
      "Akurasi Data Latih: 1.0\n",
      "\n",
      "MLPClassifier(activation='relu', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=24, learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=2000, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
      "       solver='lbfgs', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "Loss Pelatihan :  5.99472954192e-05\n",
      "Jumlah iterasi :  20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Akurasi:  91.4\n",
      "SD:  6.909999999999999\n",
      "[[11  0  0  0]\n",
      " [ 0  8  0  4]\n",
      " [ 0  0  5  0]\n",
      " [ 1  1  0 19]]\n",
      "Akurasi Data Uji: 0.877551020408 = 0.877551020408\n",
      "Akurasi Data Latih: 1.0\n",
      "\n",
      "MLPClassifier(activation='relu', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=25, learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=2000, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
      "       solver='lbfgs', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "Loss Pelatihan :  6.38220325253e-05\n",
      "Jumlah iterasi :  20\n",
      "Akurasi:  89.64999999999999\n",
      "SD:  7.55\n",
      "[[11  0  0  0]\n",
      " [ 0 10  0  2]\n",
      " [ 1  1  3  0]\n",
      " [ 1  1  0 19]]\n",
      "Akurasi Data Uji: 0.877551020408 = 0.877551020408\n",
      "Akurasi Data Latih: 1.0\n",
      "\n",
      "MLPClassifier(activation='relu', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=26, learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=2000, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
      "       solver='lbfgs', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "Loss Pelatihan :  0.000104402334554\n",
      "Jumlah iterasi :  18\n",
      "Akurasi:  91.47\n",
      "SD:  8.649999999999999\n",
      "[[11  0  0  0]\n",
      " [ 0  9  0  3]\n",
      " [ 0  0  5  0]\n",
      " [ 1  1  0 19]]\n",
      "Akurasi Data Uji: 0.897959183673 = 0.897959183673\n",
      "Akurasi Data Latih: 1.0\n",
      "\n",
      "MLPClassifier(activation='relu', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=27, learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=2000, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
      "       solver='lbfgs', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "Loss Pelatihan :  4.95081970626e-05\n",
      "Jumlah iterasi :  20\n",
      "Akurasi:  90.56\n",
      "SD:  7.91\n",
      "[[11  0  0  0]\n",
      " [ 0 10  0  2]\n",
      " [ 0  0  5  0]\n",
      " [ 0  1  0 20]]\n",
      "Akurasi Data Uji: 0.938775510204 = 0.938775510204\n",
      "Akurasi Data Latih: 1.0\n",
      "\n",
      "MLPClassifier(activation='relu', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=28, learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=2000, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
      "       solver='lbfgs', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "Loss Pelatihan :  0.000106213415618\n",
      "Jumlah iterasi :  19\n",
      "Akurasi:  89.7\n",
      "SD:  8.61\n",
      "[[11  0  0  0]\n",
      " [ 0 11  0  1]\n",
      " [ 1  0  4  0]\n",
      " [ 0  1  0 20]]\n",
      "Akurasi Data Uji: 0.938775510204 = 0.938775510204\n",
      "Akurasi Data Latih: 1.0\n",
      "\n",
      "MLPClassifier(activation='relu', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=29, learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=2000, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
      "       solver='lbfgs', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "Loss Pelatihan :  3.95247429996e-05\n",
      "Jumlah iterasi :  20\n",
      "Akurasi:  89.61\n",
      "SD:  8.1\n",
      "[[11  0  0  0]\n",
      " [ 0 11  0  1]\n",
      " [ 0  0  5  0]\n",
      " [ 1  1  0 19]]\n",
      "Akurasi Data Uji: 0.938775510204 = 0.938775510204\n",
      "Akurasi Data Latih: 1.0\n",
      "\n",
      "MLPClassifier(activation='relu', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=30, learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=2000, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
      "       solver='lbfgs', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "Loss Pelatihan :  0.000113775756447\n",
      "Jumlah iterasi :  20\n",
      "Akurasi:  88.7\n",
      "SD:  7.07\n",
      "[[11  0  0  0]\n",
      " [ 0 11  0  1]\n",
      " [ 1  0  4  0]\n",
      " [ 0  1  0 20]]\n",
      "Akurasi Data Uji: 0.938775510204 = 0.938775510204\n",
      "Akurasi Data Latih: 1.0\n",
      "\n",
      "MLPClassifier(activation='relu', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=35, learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=2000, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
      "       solver='lbfgs', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "Loss Pelatihan :  8.93164876727e-05\n",
      "Jumlah iterasi :  18\n",
      "Akurasi:  89.64999999999999\n",
      "SD:  7.55\n",
      "[[11  0  0  0]\n",
      " [ 0 10  0  2]\n",
      " [ 1  1  3  0]\n",
      " [ 1  1  0 19]]\n",
      "Akurasi Data Uji: 0.877551020408 = 0.877551020408\n",
      "Akurasi Data Latih: 1.0\n",
      "\n",
      "MLPClassifier(activation='relu', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=40, learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=2000, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
      "       solver='lbfgs', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "Loss Pelatihan :  0.000153945936792\n",
      "Jumlah iterasi :  18\n",
      "Akurasi:  89.64999999999999\n",
      "SD:  7.55\n",
      "[[11  0  0  0]\n",
      " [ 0 10  0  2]\n",
      " [ 1  0  4  0]\n",
      " [ 1  1  0 19]]\n",
      "Akurasi Data Uji: 0.897959183673 = 0.897959183673\n",
      "Akurasi Data Latih: 1.0\n",
      "\n",
      "MLPClassifier(activation='relu', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=45, learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=2000, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
      "       solver='lbfgs', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "Loss Pelatihan :  3.51599502921e-05\n",
      "Jumlah iterasi :  19\n",
      "Akurasi:  91.47\n",
      "SD:  8.649999999999999\n",
      "[[11  0  0  0]\n",
      " [ 0 11  0  1]\n",
      " [ 1  0  4  0]\n",
      " [ 1  1  0 19]]\n",
      "Akurasi Data Uji: 0.918367346939 = 0.918367346939\n",
      "Akurasi Data Latih: 1.0\n",
      "\n",
      "MLPClassifier(activation='relu', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=50, learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=2000, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
      "       solver='lbfgs', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "Loss Pelatihan :  6.36179191919e-05\n",
      "Jumlah iterasi :  21\n",
      "Akurasi:  88.74\n",
      "SD:  7.06\n",
      "[[11  0  0  0]\n",
      " [ 0  9  0  3]\n",
      " [ 1  1  3  0]\n",
      " [ 1  1  0 19]]\n",
      "Akurasi Data Uji: 0.857142857143 = 0.857142857143\n",
      "Akurasi Data Latih: 1.0\n",
      "\n",
      "MLPClassifier(activation='relu', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=55, learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=2000, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
      "       solver='lbfgs', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "Loss Pelatihan :  9.59126651057e-05\n",
      "Jumlah iterasi :  19\n",
      "Akurasi:  89.64999999999999\n",
      "SD:  7.55\n",
      "[[11  0  0  0]\n",
      " [ 0 11  0  1]\n",
      " [ 2  1  2  0]\n",
      " [ 0  1  0 20]]\n",
      "Akurasi Data Uji: 0.897959183673 = 0.897959183673\n",
      "Akurasi Data Latih: 1.0\n",
      "\n",
      "MLPClassifier(activation='relu', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=60, learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=2000, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
      "       solver='lbfgs', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "Loss Pelatihan :  0.000121016257178\n",
      "Jumlah iterasi :  18\n",
      "Akurasi:  91.52\n",
      "SD:  8.67\n",
      "[[11  0  0  0]\n",
      " [ 0 11  0  1]\n",
      " [ 1  0  4  0]\n",
      " [ 1  1  0 19]]\n",
      "Akurasi Data Uji: 0.918367346939 = 0.918367346939\n",
      "Akurasi Data Latih: 1.0\n",
      "\n",
      "MLPClassifier(activation='relu', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=65, learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=2000, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
      "       solver='lbfgs', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "Loss Pelatihan :  9.27641032302e-05\n",
      "Jumlah iterasi :  20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Akurasi:  89.64999999999999\n",
      "SD:  7.55\n",
      "[[11  0  0  0]\n",
      " [ 0 10  0  2]\n",
      " [ 0  0  5  0]\n",
      " [ 1  1  0 19]]\n",
      "Akurasi Data Uji: 0.918367346939 = 0.918367346939\n",
      "Akurasi Data Latih: 1.0\n",
      "\n",
      "MLPClassifier(activation='relu', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=70, learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=2000, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
      "       solver='lbfgs', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "Loss Pelatihan :  4.3756950425e-05\n",
      "Jumlah iterasi :  19\n",
      "Akurasi:  90.56\n",
      "SD:  7.91\n",
      "[[11  0  0  0]\n",
      " [ 0 10  0  2]\n",
      " [ 1  0  4  0]\n",
      " [ 1  1  0 19]]\n",
      "Akurasi Data Uji: 0.897959183673 = 0.897959183673\n",
      "Akurasi Data Latih: 1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "i=10\n",
    "data = [ ]\n",
    "layers = [ ]\n",
    "loss = [ ]\n",
    "iterasi = [ ]\n",
    "cv_score = [ ]\n",
    "std_cv = [ ]\n",
    "while (i<75):\n",
    "    clf = MLPClassifier(activation='relu',solver='lbfgs', alpha=1e-5, max_iter=2000,\n",
    "                    hidden_layer_sizes=(i), random_state=1)\n",
    "    print(clf.fit(X_train, y_train))\n",
    "    if(i>=30):\n",
    "        i=i+5\n",
    "    elif(i<30):  \n",
    "        i=i+1\n",
    "\n",
    "    print('Loss Pelatihan : ', clf.loss_)    \n",
    "    print('Jumlah iterasi : ', clf.n_iter_)\n",
    "    \n",
    "    \n",
    "    from sklearn.model_selection import cross_val_score\n",
    "    scoring='accuracy'\n",
    "    accuracies = cross_val_score(estimator=clf, X=X_train, y=y_train, cv=5,scoring=scoring)\n",
    "    avg_accuracy = float('{0:.4f}'.format(accuracies.mean()))*100\n",
    "    std_accuracy =  float('{0:.4f}'.format(accuracies.std()))*100\n",
    "    print('Akurasi: ', avg_accuracy)\n",
    "    print('SD: ', std_accuracy)\n",
    "    \n",
    "    \n",
    "    #Prediksi Data Uji\n",
    "    result = clf.predict(X_test)\n",
    "\n",
    "    #Confusion Matriks Hasil Prediksi dengan Nilai Sebenarnya\n",
    "    from sklearn.metrics import classification_report,confusion_matrix\n",
    "    print(confusion_matrix(y_test,result))\n",
    "\n",
    "    # Cek kemampuan kecerdasan buatan dengan data uji \n",
    "    test_accuracy = clf.score(X_test, y_test)\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    akurasi = accuracy_score(y_test, result)\n",
    "    print('Akurasi Data Uji:', test_accuracy , '=', akurasi)\n",
    "\n",
    "    # Cek kemampuan kecerdasan buatan dengan data uji \n",
    "    train_accuracy = clf.score(X_train, y_train)\n",
    "    print('Akurasi Data Latih:', train_accuracy)  \n",
    "\n",
    "    layers.append(i)\n",
    "    data.append( float('{0:.4f}'.format(test_accuracy))*100)\n",
    "    loss.append(clf.loss_)\n",
    "    iterasi.append(clf.n_iter_)\n",
    "    cv_score.append(avg_accuracy)\n",
    "    std_cv.append(std_accuracy)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[89.8,\n",
       " 93.88,\n",
       " 95.92,\n",
       " 95.92,\n",
       " 91.84,\n",
       " 93.88,\n",
       " 89.8,\n",
       " 93.88,\n",
       " 91.84,\n",
       " 93.88,\n",
       " 93.88,\n",
       " 91.84,\n",
       " 93.88,\n",
       " 91.84,\n",
       " 87.76,\n",
       " 87.76,\n",
       " 89.8,\n",
       " 93.88,\n",
       " 93.88,\n",
       " 93.88,\n",
       " 93.88,\n",
       " 87.76,\n",
       " 89.8,\n",
       " 91.84,\n",
       " 85.71,\n",
       " 89.8,\n",
       " 91.84,\n",
       " 91.84,\n",
       " 89.8]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neuron</th>\n",
       "      <th>akurasi</th>\n",
       "      <th>loss</th>\n",
       "      <th>iter</th>\n",
       "      <th>cv</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11.0</td>\n",
       "      <td>89.80</td>\n",
       "      <td>0.000070</td>\n",
       "      <td>27.0</td>\n",
       "      <td>89.53</td>\n",
       "      <td>5.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12.0</td>\n",
       "      <td>93.88</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>22.0</td>\n",
       "      <td>90.56</td>\n",
       "      <td>7.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.0</td>\n",
       "      <td>95.92</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>24.0</td>\n",
       "      <td>90.61</td>\n",
       "      <td>8.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.0</td>\n",
       "      <td>95.92</td>\n",
       "      <td>0.000062</td>\n",
       "      <td>21.0</td>\n",
       "      <td>86.97</td>\n",
       "      <td>8.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15.0</td>\n",
       "      <td>91.84</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>20.0</td>\n",
       "      <td>89.70</td>\n",
       "      <td>8.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>16.0</td>\n",
       "      <td>93.88</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>21.0</td>\n",
       "      <td>88.70</td>\n",
       "      <td>7.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>17.0</td>\n",
       "      <td>89.80</td>\n",
       "      <td>0.000085</td>\n",
       "      <td>21.0</td>\n",
       "      <td>88.74</td>\n",
       "      <td>5.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>18.0</td>\n",
       "      <td>93.88</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>22.0</td>\n",
       "      <td>88.70</td>\n",
       "      <td>7.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>19.0</td>\n",
       "      <td>91.84</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>22.0</td>\n",
       "      <td>91.52</td>\n",
       "      <td>9.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>20.0</td>\n",
       "      <td>93.88</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>19.0</td>\n",
       "      <td>89.61</td>\n",
       "      <td>7.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>21.0</td>\n",
       "      <td>93.88</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>22.0</td>\n",
       "      <td>87.79</td>\n",
       "      <td>6.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>22.0</td>\n",
       "      <td>91.84</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>20.0</td>\n",
       "      <td>91.52</td>\n",
       "      <td>8.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>23.0</td>\n",
       "      <td>93.88</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>21.0</td>\n",
       "      <td>89.61</td>\n",
       "      <td>7.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>24.0</td>\n",
       "      <td>91.84</td>\n",
       "      <td>0.000128</td>\n",
       "      <td>20.0</td>\n",
       "      <td>88.70</td>\n",
       "      <td>7.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>25.0</td>\n",
       "      <td>87.76</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>20.0</td>\n",
       "      <td>91.40</td>\n",
       "      <td>6.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>26.0</td>\n",
       "      <td>87.76</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>20.0</td>\n",
       "      <td>89.65</td>\n",
       "      <td>7.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>27.0</td>\n",
       "      <td>89.80</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>18.0</td>\n",
       "      <td>91.47</td>\n",
       "      <td>8.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>28.0</td>\n",
       "      <td>93.88</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>20.0</td>\n",
       "      <td>90.56</td>\n",
       "      <td>7.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>29.0</td>\n",
       "      <td>93.88</td>\n",
       "      <td>0.000106</td>\n",
       "      <td>19.0</td>\n",
       "      <td>89.70</td>\n",
       "      <td>8.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>30.0</td>\n",
       "      <td>93.88</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>20.0</td>\n",
       "      <td>89.61</td>\n",
       "      <td>8.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>35.0</td>\n",
       "      <td>93.88</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>20.0</td>\n",
       "      <td>88.70</td>\n",
       "      <td>7.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>40.0</td>\n",
       "      <td>87.76</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>18.0</td>\n",
       "      <td>89.65</td>\n",
       "      <td>7.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>45.0</td>\n",
       "      <td>89.80</td>\n",
       "      <td>0.000154</td>\n",
       "      <td>18.0</td>\n",
       "      <td>89.65</td>\n",
       "      <td>7.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>50.0</td>\n",
       "      <td>91.84</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>19.0</td>\n",
       "      <td>91.47</td>\n",
       "      <td>8.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>55.0</td>\n",
       "      <td>85.71</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>21.0</td>\n",
       "      <td>88.74</td>\n",
       "      <td>7.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>60.0</td>\n",
       "      <td>89.80</td>\n",
       "      <td>0.000096</td>\n",
       "      <td>19.0</td>\n",
       "      <td>89.65</td>\n",
       "      <td>7.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>65.0</td>\n",
       "      <td>91.84</td>\n",
       "      <td>0.000121</td>\n",
       "      <td>18.0</td>\n",
       "      <td>91.52</td>\n",
       "      <td>8.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>70.0</td>\n",
       "      <td>91.84</td>\n",
       "      <td>0.000093</td>\n",
       "      <td>20.0</td>\n",
       "      <td>89.65</td>\n",
       "      <td>7.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>75.0</td>\n",
       "      <td>89.80</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>19.0</td>\n",
       "      <td>90.56</td>\n",
       "      <td>7.91</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    neuron  akurasi      loss  iter     cv   std\n",
       "0     11.0    89.80  0.000070  27.0  89.53  5.47\n",
       "1     12.0    93.88  0.000048  22.0  90.56  7.91\n",
       "2     13.0    95.92  0.000048  24.0  90.61  8.44\n",
       "3     14.0    95.92  0.000062  21.0  86.97  8.51\n",
       "4     15.0    91.84  0.000078  20.0  89.70  8.11\n",
       "5     16.0    93.88  0.000081  21.0  88.70  7.07\n",
       "6     17.0    89.80  0.000085  21.0  88.74  5.38\n",
       "7     18.0    93.88  0.000036  22.0  88.70  7.07\n",
       "8     19.0    91.84  0.000051  22.0  91.52  9.13\n",
       "9     20.0    93.88  0.000064  19.0  89.61  7.57\n",
       "10    21.0    93.88  0.000033  22.0  87.79  6.41\n",
       "11    22.0    91.84  0.000100  20.0  91.52  8.67\n",
       "12    23.0    93.88  0.000045  21.0  89.61  7.57\n",
       "13    24.0    91.84  0.000128  20.0  88.70  7.07\n",
       "14    25.0    87.76  0.000060  20.0  91.40  6.91\n",
       "15    26.0    87.76  0.000064  20.0  89.65  7.55\n",
       "16    27.0    89.80  0.000104  18.0  91.47  8.65\n",
       "17    28.0    93.88  0.000050  20.0  90.56  7.91\n",
       "18    29.0    93.88  0.000106  19.0  89.70  8.61\n",
       "19    30.0    93.88  0.000040  20.0  89.61  8.10\n",
       "20    35.0    93.88  0.000114  20.0  88.70  7.07\n",
       "21    40.0    87.76  0.000089  18.0  89.65  7.55\n",
       "22    45.0    89.80  0.000154  18.0  89.65  7.55\n",
       "23    50.0    91.84  0.000035  19.0  91.47  8.65\n",
       "24    55.0    85.71  0.000064  21.0  88.74  7.06\n",
       "25    60.0    89.80  0.000096  19.0  89.65  7.55\n",
       "26    65.0    91.84  0.000121  18.0  91.52  8.67\n",
       "27    70.0    91.84  0.000093  20.0  89.65  7.55\n",
       "28    75.0    89.80  0.000044  19.0  90.56  7.91"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "summary = [ ]\n",
    "i=0\n",
    "while(i<len(layers)):\n",
    "    summary.append([layers[i],data[i],loss[i], iterasi[i], cv_score[i],std_cv[i]]) \n",
    "    i+=1\n",
    "    \n",
    "df = pd.DataFrame(np.array(summary))\n",
    "df.columns = (['neuron','akurasi','loss','iter','cv','std'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier(activation='relu', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=12, learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=2000, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
      "       solver='lbfgs', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "Akurasi:  90.61\n",
      "SD:  8.44\n",
      "[[11  0  0  0]\n",
      " [ 0 11  0  1]\n",
      " [ 0  0  5  0]\n",
      " [ 0  1  0 20]]\n",
      "akurasi latih:  100.0\n",
      "akurasi uji:  95.92\n",
      "Confusion matrix, without normalization\n",
      "[[11  0  0  0]\n",
      " [ 0 11  0  1]\n",
      " [ 0  0  5  0]\n",
      " [ 0  1  0 20]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramFiles\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1428: UserWarning: labels size, 4, does not match size of target_names, 5\n",
      "  .format(len(labels), len(target_names))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "    basofil       1.00      1.00      1.00        11\n",
      "  eosinofil       0.92      0.92      0.92        12\n",
      "   netrofil       1.00      1.00      1.00         5\n",
      "    monosit       0.95      0.95      0.95        21\n",
      "\n",
      "avg / total       0.96      0.96      0.96        49\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xb1c0b70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    " # Latih kecerdasan buatan dengan data latih, menggunakan MLP-NN\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import time\n",
    "\n",
    "clf = MLPClassifier(activation='relu',solver='lbfgs', alpha=1e-5, max_iter=2000,\n",
    "            hidden_layer_sizes=(12), random_state=1)\n",
    "start = time.time()\n",
    "print(clf.fit(X_train, y_train))\n",
    "end = time.time()\n",
    "waktuTrain = end - start\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "scoring='accuracy'\n",
    "accuracies = cross_val_score(estimator=clf, X=X_train, y=y_train, cv=5,scoring=scoring)\n",
    "avg_accuracy = float('{0:.4f}'.format(accuracies.mean()))*100\n",
    "std_accuracy =  float('{0:.4f}'.format(accuracies.std()))*100\n",
    "print('Akurasi: ', avg_accuracy)\n",
    "print('SD: ', std_accuracy)\n",
    "\n",
    "\n",
    "#prediksi\n",
    "start = time.time()\n",
    "result = clf.predict(X_test)\n",
    "end = time.time()\n",
    "waktuTest = end - start\n",
    "\n",
    "#Confusion Matriks Hasil Prediksi dengan Nilai Sebenarnya\n",
    "from sklearn.metrics import classification_report,confusion_matrix, roc_auc_score\n",
    "print(confusion_matrix(y_test,result))\n",
    "\n",
    "# Cek kemampuan kecerdasan buatan dengan data uji \n",
    "train_accuracy = float('{0:.4f}'.format(clf.score(X_train, y_train)))*100\n",
    "print(\"akurasi latih: \",train_accuracy)\n",
    "\n",
    "# Cek kemampuan kecerdasan buatan dengan data uji \n",
    "test_accuracy = float('{0:.4f}'.format(clf.score(X_test, y_test)))*100\n",
    "print(\"akurasi uji: \",test_accuracy)\n",
    "\n",
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(y_test, result)\n",
    "np.set_printoptions(precision=2)\n",
    "class_names = ['Basofil', 'Eosinofil','Netrofil','Monosit','Limfosit']\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names,\n",
    "                      title='Confusion matrix')\n",
    "\n",
    "from sklearn.metrics import classification_report,confusion_matrix, roc_auc_score\n",
    "print(classification_report(y_test,result, target_names=['basofil','eosinofil','netrofil','monosit', 'limfosit']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
