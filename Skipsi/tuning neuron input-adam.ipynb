{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "#df = pd.read_excel('Urut-Data-20Fitur-20Citra-20Sel-20Darah.xlsx', header=0)\n",
    "df = pd.read_excel('Data-20Fitur-20Citra-20Sel-20Darah.xlsx', header=0,sheet_name='Data Fitur Citra Sel Darah2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "head = ['Jenis', 'KIperKP', 'KontrasP', 'Solidity_Inti', 'HomogenitasP',\n",
    "        'Circularity_Inti', 'Keliling_Inti', 'LIperLP ', 'KelilingP',\n",
    "        'EntropiP', 'LuasNormal_P', 'EnergiP', 'Homogenitas_Inti',\n",
    "        'KelilingNormal_I', 'Entropi_Inti', 'Granularity_Inti',\n",
    "        'RerataGP', 'SolidityP', 'Energi_Inti', 'RerataRP',\n",
    "        'RerataR_Inti', 'CircularityP', 'LuasP', 'GranularityP',\n",
    "        'RerataG_Inti', 'RerataBP', 'Eccentricity', 'RerataB_Inti',\n",
    "        'Kontras_Inti', 'Luas_Inti']\n",
    "\n",
    "head = ['Luas_Inti','Keliling_Inti','Solidity_Inti','Granularity_Inti',\n",
    "        'Circularity_Inti','RerataR_Inti','RerataG_Inti','RerataB_Inti','Entropi_Inti',\n",
    "        'Energi_Inti','Kontras_Inti','Homogenitas_Inti','LuasP','KelilingP','SolidityP',\n",
    "        'GranularityP','CircularityP','RerataRP','RerataGP','RerataBP','EntropiP','EnergiP',\n",
    "        'KontrasP','HomogenitasP','LuasNormal_P','KelilingNormal_I','Eccentricity','LIperLP ','KIperKP']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k1 =[ 'Luas_Inti','Keliling_Inti']\n",
    "k2 = ['Granularity_Inti','GranularityP']\n",
    "k3 = ['Circularity_Inti','CircularityP','Eccentricity']\n",
    "k4 = ['RerataR_Inti','RerataG_Inti','RerataB_Inti']\n",
    "k5 = ['Solidity_Inti','Entropi_Inti','Energi_Inti','Kontras_Inti','Homogenitas_Inti']\n",
    "k6 = ['LuasP','KelilingP']\n",
    "k7 = ['RerataRP','RerataGP','RerataBP']\n",
    "k8 = ['SolidityP','EntropiP','EnergiP','KontrasP','HomogenitasP']\n",
    "k9 = ['LuasNormal_P','KelilingNormal_I']\n",
    "k10 =[ 'LIperLP ','KIperKP']\n",
    "\n",
    "datset = [k1,k2,k3,k4,k5,k6,k7,k8,k9,k10]\n",
    "\n",
    "#adam\n",
    "#    1          2         3         4         5          6          7          8           9         10\n",
    "#[99.15, 99.15, 99.15, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 99.15]\n",
    "#[88.24, 86.27, 86.27, 88.24, 86.27, 88.24, 88.24, 82.35, 84.31, 86.27]\n",
    "\n",
    "#lbfgs\n",
    "#    1          2         3         4         5          6          7          8           9         10\n",
    "#[100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0]\n",
    "#[90.2, 84.31, 82.35, 86.27, 90.2, 88.24, 86.27, 80.39, 88.24, 80.39]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tolen= 0\n",
    "for i in range(len(datset)):\n",
    "    tolen = tolen +len(datset[i])\n",
    "print(tolen)\n",
    "len(datset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#adam finish\n",
    "k2 = ['Jenis','Granularity_Inti','GranularityP']\n",
    "k1 =['Jenis','Granularity_Inti','GranularityP', 'Luas_Inti','Keliling_Inti']\n",
    "k7 = ['Jenis','Granularity_Inti','GranularityP', 'Luas_Inti','Keliling_Inti','RerataRP','RerataGP','RerataBP']\n",
    "k8 = ['Jenis','Granularity_Inti','GranularityP', 'Luas_Inti','Keliling_Inti','RerataRP','RerataGP','RerataBP','SolidityP','EntropiP','EnergiP','KontrasP','HomogenitasP']\n",
    "k4 = ['Jenis','Granularity_Inti','GranularityP', 'Luas_Inti','Keliling_Inti','RerataRP','RerataGP','RerataBP','SolidityP','EntropiP','EnergiP','KontrasP','HomogenitasP','RerataR_Inti','RerataG_Inti','RerataB_Inti']\n",
    "k10 =['Jenis','Granularity_Inti','GranularityP', 'Luas_Inti','Keliling_Inti','RerataRP','RerataGP','RerataBP','SolidityP','EntropiP','EnergiP','KontrasP','HomogenitasP','RerataR_Inti','RerataG_Inti','RerataB_Inti', 'LIperLP ','KIperKP']\n",
    "k9 = ['Jenis','Granularity_Inti','GranularityP', 'Luas_Inti','Keliling_Inti','RerataRP','RerataGP','RerataBP','SolidityP','EntropiP','EnergiP','KontrasP','HomogenitasP','RerataR_Inti','RerataG_Inti','RerataB_Inti', 'LIperLP ','KIperKP','LuasNormal_P','KelilingNormal_I']\n",
    "k6 = ['Jenis','Granularity_Inti','GranularityP', 'Luas_Inti','Keliling_Inti','RerataRP','RerataGP','RerataBP','SolidityP','EntropiP','EnergiP','KontrasP','HomogenitasP','RerataR_Inti','RerataG_Inti','RerataB_Inti', 'LIperLP ','KIperKP','LuasNormal_P','KelilingNormal_I','LuasP','KelilingP']\n",
    "k3 = ['Jenis','Granularity_Inti','GranularityP', 'Luas_Inti','Keliling_Inti','RerataRP','RerataGP','RerataBP','SolidityP','EntropiP','EnergiP','KontrasP','HomogenitasP','RerataR_Inti','RerataG_Inti','RerataB_Inti', 'LIperLP ','KIperKP','LuasNormal_P','KelilingNormal_I','LuasP','KelilingP','Circularity_Inti','CircularityP','Eccentricity']\n",
    "k5 = ['Jenis','Granularity_Inti','GranularityP', 'Luas_Inti','Keliling_Inti','RerataRP','RerataGP','RerataBP','SolidityP','EntropiP','EnergiP','KontrasP','HomogenitasP','RerataR_Inti','RerataG_Inti','RerataB_Inti', 'LIperLP ','KIperKP','LuasNormal_P','KelilingNormal_I','LuasP','KelilingP','Circularity_Inti','CircularityP','Eccentricity','Solidity_Inti','Entropi_Inti','Energi_Inti','Kontras_Inti','Homogenitas_Inti']\n",
    "\n",
    "datset = [k2, k1, k7, k8, k4, k10, k9, k6, k3, k5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Reordering Columns by name\n",
    "df = pd.read_excel('Urut-Data-20Fitur-20Citra-20Sel-20Darah.xlsx', header=0)\n",
    "df = df[k2]\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "daf = pd.read_excel('Urut-Data-20Fitur-20Citra-20Sel-20Darah.xlsx', header=0)\n",
    "#df = daf.drop(datset[0], axis=1)\n",
    "print(df[0:0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "k7 = ['Jenis','RerataRP','RerataGP','RerataBP']\n",
    "k3 = ['Jenis','RerataRP','RerataGP','RerataBP','Circularity_Inti','CircularityP','Eccentricity']\n",
    "k5 = ['Jenis','RerataRP','RerataGP','RerataBP','Circularity_Inti','CircularityP','Eccentricity','Solidity_Inti','Entropi_Inti','Energi_Inti','Kontras_Inti','Homogenitas_Inti']\n",
    "k10 =['Jenis','RerataRP','RerataGP','RerataBP','Circularity_Inti','CircularityP','Eccentricity','Solidity_Inti','Entropi_Inti','Energi_Inti','Kontras_Inti','Homogenitas_Inti', 'LIperLP ','KIperKP']\n",
    "k8 = ['Jenis','RerataRP','RerataGP','RerataBP','Circularity_Inti','CircularityP','Eccentricity','Solidity_Inti','Entropi_Inti','Energi_Inti','Kontras_Inti','Homogenitas_Inti', 'LIperLP ','KIperKP','SolidityP','EntropiP','EnergiP','KontrasP','HomogenitasP']\n",
    "k9 = ['Jenis','RerataRP','RerataGP','RerataBP','Circularity_Inti','CircularityP','Eccentricity','Solidity_Inti','Entropi_Inti','Energi_Inti','Kontras_Inti','Homogenitas_Inti', 'LIperLP ','KIperKP','SolidityP','EntropiP','EnergiP','KontrasP','HomogenitasP','LuasNormal_P','KelilingNormal_I']\n",
    "k4 = ['Jenis','RerataRP','RerataGP','RerataBP','Circularity_Inti','CircularityP','Eccentricity','Solidity_Inti','Entropi_Inti','Energi_Inti','Kontras_Inti','Homogenitas_Inti', 'LIperLP ','KIperKP','SolidityP','EntropiP','EnergiP','KontrasP','HomogenitasP','LuasNormal_P','KelilingNormal_I','RerataR_Inti','RerataG_Inti','RerataB_Inti']\n",
    "k2 = ['Jenis','RerataRP','RerataGP','RerataBP','Circularity_Inti','CircularityP','Eccentricity','Solidity_Inti','Entropi_Inti','Energi_Inti','Kontras_Inti','Homogenitas_Inti', 'LIperLP ','KIperKP','SolidityP','EntropiP','EnergiP','KontrasP','HomogenitasP','LuasNormal_P','KelilingNormal_I','RerataR_Inti','RerataG_Inti','RerataB_Inti','Granularity_Inti','GranularityP']\n",
    "k6 = ['Jenis','RerataRP','RerataGP','RerataBP','Circularity_Inti','CircularityP','Eccentricity','Solidity_Inti','Entropi_Inti','Energi_Inti','Kontras_Inti','Homogenitas_Inti', 'LIperLP ','KIperKP','SolidityP','EntropiP','EnergiP','KontrasP','HomogenitasP','LuasNormal_P','KelilingNormal_I','RerataR_Inti','RerataG_Inti','RerataB_Inti','Granularity_Inti','GranularityP','LuasP','KelilingP']\n",
    "k1 =['Jenis','RerataRP','RerataGP','RerataBP','Circularity_Inti','CircularityP','Eccentricity','Solidity_Inti','Entropi_Inti','Energi_Inti','Kontras_Inti','Homogenitas_Inti', 'LIperLP ','KIperKP','SolidityP','EntropiP','EnergiP','KontrasP','HomogenitasP','LuasNormal_P','KelilingNormal_I','RerataR_Inti','RerataG_Inti','RerataB_Inti','Granularity_Inti','GranularityP','LuasP','KelilingP', 'Luas_Inti','Keliling_Inti']\n",
    "\n",
    "datset = [k7,k3,k5,k10,k8,k9,k4,k2,k6,k1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Empty DataFrame\n",
      "Columns: [Jenis, Solidity_Inti, Granularity_Inti, Circularity_Inti, RerataR_Inti, RerataG_Inti, RerataB_Inti, Entropi_Inti, Energi_Inti, Kontras_Inti, Homogenitas_Inti, LuasP, KelilingP, SolidityP, GranularityP, CircularityP, RerataRP, RerataGP, RerataBP, EntropiP, EnergiP, KontrasP, HomogenitasP, LuasNormal_P, KelilingNormal_I, Eccentricity, LIperLP , KIperKP]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 28 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramFiles\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier(activation='tanh', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=28, learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=2000, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "Akurasi:  93.35\n",
      "SD:  3.02\n",
      "[[10  1  0  0  0]\n",
      " [ 1  1  0  0  0]\n",
      " [ 0  0 12  0  0]\n",
      " [ 0  0  0  5  0]\n",
      " [ 0  0  1  0 20]]\n",
      "akurasi latih:  100.0\n",
      "akurasi uji:  94.12\n",
      "\n",
      "1\n",
      "Empty DataFrame\n",
      "Columns: [Jenis, Luas_Inti, Keliling_Inti, Solidity_Inti, Circularity_Inti, RerataR_Inti, RerataG_Inti, RerataB_Inti, Entropi_Inti, Energi_Inti, Kontras_Inti, Homogenitas_Inti, LuasP, KelilingP, SolidityP, CircularityP, RerataRP, RerataGP, RerataBP, EntropiP, EnergiP, KontrasP, HomogenitasP, LuasNormal_P, KelilingNormal_I, Eccentricity, LIperLP , KIperKP]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 28 columns]\n",
      "MLPClassifier(activation='tanh', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=28, learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=2000, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "Akurasi:  93.53\n",
      "SD:  7.3999999999999995\n",
      "[[11  0  0  0  0]\n",
      " [ 1  0  1  0  0]\n",
      " [ 0  0 11  0  1]\n",
      " [ 0  0  0  5  0]\n",
      " [ 1  0  1  0 19]]\n",
      "akurasi latih:  100.0\n",
      "akurasi uji:  90.2\n",
      "\n",
      "2\n",
      "Empty DataFrame\n",
      "Columns: [Jenis, Luas_Inti, Keliling_Inti, Solidity_Inti, Granularity_Inti, RerataR_Inti, RerataG_Inti, RerataB_Inti, Entropi_Inti, Energi_Inti, Kontras_Inti, Homogenitas_Inti, LuasP, KelilingP, SolidityP, GranularityP, RerataRP, RerataGP, RerataBP, EntropiP, EnergiP, KontrasP, HomogenitasP, LuasNormal_P, KelilingNormal_I, LIperLP , KIperKP]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 27 columns]\n",
      "MLPClassifier(activation='tanh', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=28, learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=2000, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "Akurasi:  91.75\n",
      "SD:  6.63\n",
      "[[10  1  0  0  0]\n",
      " [ 1  0  1  0  0]\n",
      " [ 0  0 10  0  2]\n",
      " [ 0  1  0  4  0]\n",
      " [ 1  0  1  0 19]]\n",
      "akurasi latih:  100.0\n",
      "akurasi uji:  84.31\n",
      "\n",
      "3\n",
      "Empty DataFrame\n",
      "Columns: [Jenis, Luas_Inti, Keliling_Inti, Solidity_Inti, Granularity_Inti, Circularity_Inti, Entropi_Inti, Energi_Inti, Kontras_Inti, Homogenitas_Inti, LuasP, KelilingP, SolidityP, GranularityP, CircularityP, RerataRP, RerataGP, RerataBP, EntropiP, EnergiP, KontrasP, HomogenitasP, LuasNormal_P, KelilingNormal_I, Eccentricity, LIperLP , KIperKP]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 27 columns]\n",
      "MLPClassifier(activation='tanh', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=28, learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=2000, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "Akurasi:  91.82000000000001\n",
      "SD:  7.06\n",
      "[[11  0  0  0  0]\n",
      " [ 1  0  1  0  0]\n",
      " [ 0  0 11  0  1]\n",
      " [ 0  1  0  4  0]\n",
      " [ 0  0  1  0 20]]\n",
      "akurasi latih:  100.0\n",
      "akurasi uji:  90.2\n",
      "\n",
      "4\n",
      "Empty DataFrame\n",
      "Columns: [Jenis, Luas_Inti, Keliling_Inti, Granularity_Inti, Circularity_Inti, RerataR_Inti, RerataG_Inti, RerataB_Inti, LuasP, KelilingP, SolidityP, GranularityP, CircularityP, RerataRP, RerataGP, RerataBP, EntropiP, EnergiP, KontrasP, HomogenitasP, LuasNormal_P, KelilingNormal_I, Eccentricity, LIperLP , KIperKP]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 25 columns]\n",
      "MLPClassifier(activation='tanh', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=28, learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=2000, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "Akurasi:  93.46\n",
      "SD:  5.37\n",
      "[[10  1  0  0  0]\n",
      " [ 1  0  1  0  0]\n",
      " [ 0  0 11  0  1]\n",
      " [ 0  0  1  4  0]\n",
      " [ 1  0  1  0 19]]\n",
      "akurasi latih:  100.0\n",
      "akurasi uji:  86.27\n",
      "\n",
      "5\n",
      "Empty DataFrame\n",
      "Columns: [Jenis, Luas_Inti, Keliling_Inti, Solidity_Inti, Granularity_Inti, Circularity_Inti, RerataR_Inti, RerataG_Inti, RerataB_Inti, Entropi_Inti, Energi_Inti, Kontras_Inti, Homogenitas_Inti, SolidityP, GranularityP, CircularityP, RerataRP, RerataGP, RerataBP, EntropiP, EnergiP, KontrasP, HomogenitasP, LuasNormal_P, KelilingNormal_I, Eccentricity, LIperLP , KIperKP]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 28 columns]\n",
      "MLPClassifier(activation='tanh', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=28, learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=2000, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "Akurasi:  92.62\n",
      "SD:  6.800000000000001\n",
      "[[10  1  0  0  0]\n",
      " [ 1  1  0  0  0]\n",
      " [ 0  0 11  0  1]\n",
      " [ 0  0  0  5  0]\n",
      " [ 0  0  1  0 20]]\n",
      "akurasi latih:  100.0\n",
      "akurasi uji:  92.16\n",
      "\n",
      "6\n",
      "Empty DataFrame\n",
      "Columns: [Jenis, Luas_Inti, Keliling_Inti, Solidity_Inti, Granularity_Inti, Circularity_Inti, RerataR_Inti, RerataG_Inti, RerataB_Inti, Entropi_Inti, Energi_Inti, Kontras_Inti, Homogenitas_Inti, LuasP, KelilingP, SolidityP, GranularityP, CircularityP, EntropiP, EnergiP, KontrasP, HomogenitasP, LuasNormal_P, KelilingNormal_I, Eccentricity, LIperLP , KIperKP]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 27 columns]\n",
      "MLPClassifier(activation='tanh', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=28, learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=2000, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "Akurasi:  93.53\n",
      "SD:  7.3999999999999995\n",
      "[[10  1  0  0  0]\n",
      " [ 1  0  1  0  0]\n",
      " [ 0  0 10  0  2]\n",
      " [ 1  1  0  3  0]\n",
      " [ 1  0  1  0 19]]\n",
      "akurasi latih:  100.0\n",
      "akurasi uji:  82.35\n",
      "\n",
      "7\n",
      "Empty DataFrame\n",
      "Columns: [Jenis, Luas_Inti, Keliling_Inti, Solidity_Inti, Granularity_Inti, Circularity_Inti, RerataR_Inti, RerataG_Inti, RerataB_Inti, Entropi_Inti, Energi_Inti, Kontras_Inti, Homogenitas_Inti, LuasP, KelilingP, GranularityP, CircularityP, RerataRP, RerataGP, RerataBP, LuasNormal_P, KelilingNormal_I, Eccentricity, LIperLP , KIperKP]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 25 columns]\n",
      "MLPClassifier(activation='tanh', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=28, learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=2000, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "Akurasi:  91.82000000000001\n",
      "SD:  8.309999999999999\n",
      "[[ 9  1  0  0  1]\n",
      " [ 1  0  1  0  0]\n",
      " [ 0  0 11  0  1]\n",
      " [ 0  0  0  5  0]\n",
      " [ 0  0  2  0 19]]\n",
      "akurasi latih:  100.0\n",
      "akurasi uji:  86.27\n",
      "\n",
      "8\n",
      "Empty DataFrame\n",
      "Columns: [Jenis, Luas_Inti, Keliling_Inti, Solidity_Inti, Granularity_Inti, Circularity_Inti, RerataR_Inti, RerataG_Inti, RerataB_Inti, Entropi_Inti, Energi_Inti, Kontras_Inti, Homogenitas_Inti, LuasP, KelilingP, SolidityP, GranularityP, CircularityP, RerataRP, RerataGP, RerataBP, EntropiP, EnergiP, KontrasP, HomogenitasP, Eccentricity, LIperLP , KIperKP]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 28 columns]\n",
      "MLPClassifier(activation='tanh', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=28, learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=2000, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Akurasi:  94.22\n",
      "SD:  5.38\n",
      "[[10  1  0  0  0]\n",
      " [ 1  1  0  0  0]\n",
      " [ 0  0 11  0  1]\n",
      " [ 0  0  1  4  0]\n",
      " [ 1  0  1  0 19]]\n",
      "akurasi latih:  100.0\n",
      "akurasi uji:  88.24\n",
      "\n",
      "9\n",
      "Empty DataFrame\n",
      "Columns: [Jenis, Luas_Inti, Keliling_Inti, Solidity_Inti, Granularity_Inti, Circularity_Inti, RerataR_Inti, RerataG_Inti, RerataB_Inti, Entropi_Inti, Energi_Inti, Kontras_Inti, Homogenitas_Inti, LuasP, KelilingP, SolidityP, GranularityP, CircularityP, RerataRP, RerataGP, RerataBP, EntropiP, EnergiP, KontrasP, HomogenitasP, LuasNormal_P, KelilingNormal_I, Eccentricity]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 28 columns]\n",
      "MLPClassifier(activation='tanh', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=28, learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=2000, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "Akurasi:  93.42\n",
      "SD:  5.35\n",
      "[[10  1  0  0  0]\n",
      " [ 1  0  1  0  0]\n",
      " [ 0  0 11  0  1]\n",
      " [ 0  0  1  4  0]\n",
      " [ 1  0  1  0 19]]\n",
      "akurasi latih:  100.0\n",
      "akurasi uji:  86.27\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train = [ ]\n",
    "test = [ ]\n",
    "cv_score = [ ]\n",
    "cv_std = [ ]\n",
    "for i in range(10):\n",
    "    print(i)\n",
    "\n",
    "    daf = pd.read_excel('Data-20Fitur-20Citra-20Sel-20Darah.xlsx', header=0, sheet_name ='Data Fitur Citra Sel Darah2')\n",
    "    df = daf.drop(datset[i], axis=1)\n",
    "    #df = daf[datset[i]]\n",
    "    print(df[0:0])\n",
    "\n",
    "    import numpy as np\n",
    "    y= np.array(df)[:,0]           #membuat dataset target y\n",
    "    X = np.array(df)[:,1:30]    #membuat dataset input X\n",
    "\n",
    "    # Pisahkan dataset menjadi data latih dan uji dengan perbandingan 80:20\n",
    "    from sklearn.cross_validation import train_test_split\n",
    "    X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.30, random_state=0)\n",
    "\n",
    "    # Penyekalaan fitur dilakukan pada data latih dan uji.\n",
    "    # Detail kenapa ini penting dijelaskan di sini: http://scikit-learn.org/stable/auto_examples/preprocessing/plot_scaling_importance.html\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    sc = StandardScaler()\n",
    "\n",
    "    # Fungsi fit_transform hanya dilakukan di data latih\n",
    "    X_train = sc.fit_transform(X_train)\n",
    "    X_test = sc.transform(X_test)\n",
    "\n",
    "    # Latih kecerdasan buatan dengan data latih, menggunakan MLP-NN\n",
    "    from sklearn.neural_network import MLPClassifier\n",
    "    import time\n",
    "\n",
    "    clf = MLPClassifier(activation='tanh',solver='adam', alpha=1e-5, max_iter=2000,\n",
    "                hidden_layer_sizes=(28), random_state=1)\n",
    "    start = time.time()\n",
    "    print(clf.fit(X_train, y_train))\n",
    "    end = time.time()\n",
    "    waktuTrain = end - start\n",
    "\n",
    "    from sklearn.model_selection import cross_val_score\n",
    "    scoring='accuracy'\n",
    "    accuracies = cross_val_score(estimator=clf, X=X_train, y=y_train, cv=5,scoring=scoring)\n",
    "    avg_accuracy = float('{0:.4f}'.format(accuracies.mean()))*100\n",
    "    std_accuracy =  float('{0:.4f}'.format(accuracies.std()))*100\n",
    "    print('Akurasi: ', avg_accuracy)\n",
    "    print('SD: ', std_accuracy)\n",
    "\n",
    "    #prediksi\n",
    "    start = time.time()\n",
    "    result = clf.predict(X_test)\n",
    "    end = time.time()\n",
    "    waktuTest = end - start\n",
    "\n",
    "    #Confusion Matriks Hasil Prediksi dengan Nilai Sebenarnya\n",
    "    from sklearn.metrics import classification_report,confusion_matrix, roc_auc_score\n",
    "    print(confusion_matrix(y_test,result))\n",
    "\n",
    "    # Cek kemampuan kecerdasan buatan dengan data uji \n",
    "    train_accuracy = float('{0:.4f}'.format(clf.score(X_train, y_train)))*100\n",
    "    print(\"akurasi latih: \",train_accuracy)\n",
    "\n",
    "    # Cek kemampuan kecerdasan buatan dengan data uji \n",
    "    test_accuracy = float('{0:.4f}'.format(clf.score(X_test, y_test)))*100\n",
    "    print(\"akurasi uji: \",test_accuracy)\n",
    "\n",
    "    train.append(train_accuracy)\n",
    "    cv_score.append(avg_accuracy)\n",
    "    cv_std.append(std_accuracy)\n",
    "    test.append(test_accuracy)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[93.35,\n",
       " 93.53,\n",
       " 91.75,\n",
       " 91.82000000000001,\n",
       " 93.46,\n",
       " 92.62,\n",
       " 93.53,\n",
       " 91.82000000000001,\n",
       " 94.22,\n",
       " 93.42]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[94.12, 90.2, 84.31, 90.2, 86.27, 92.16, 82.35, 86.27, 88.24, 86.27]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''#adam finish\n",
    "k2 = ['Jenis','Granularity_Inti','GranularityP']\n",
    "k1 =['Jenis','Granularity_Inti','GranularityP', 'Luas_Inti','Keliling_Inti']\n",
    "k7 = ['Jenis','Granularity_Inti','GranularityP', 'Luas_Inti','Keliling_Inti','RerataRP','RerataGP','RerataBP']\n",
    "k8 = ['Jenis','Granularity_Inti','GranularityP', 'Luas_Inti','Keliling_Inti','RerataRP','RerataGP','RerataBP','SolidityP','EntropiP','EnergiP','KontrasP','HomogenitasP']\n",
    "k4 = ['Jenis','Granularity_Inti','GranularityP', 'Luas_Inti','Keliling_Inti','RerataRP','RerataGP','RerataBP','SolidityP','EntropiP','EnergiP','KontrasP','HomogenitasP','RerataR_Inti','RerataG_Inti','RerataB_Inti']\n",
    "k10 =['Jenis','Granularity_Inti','GranularityP', 'Luas_Inti','Keliling_Inti','RerataRP','RerataGP','RerataBP','SolidityP','EntropiP','EnergiP','KontrasP','HomogenitasP','RerataR_Inti','RerataG_Inti','RerataB_Inti', 'LIperLP ','KIperKP']\n",
    "k9 = ['Jenis','Granularity_Inti','GranularityP', 'Luas_Inti','Keliling_Inti','RerataRP','RerataGP','RerataBP','SolidityP','EntropiP','EnergiP','KontrasP','HomogenitasP','RerataR_Inti','RerataG_Inti','RerataB_Inti', 'LIperLP ','KIperKP','LuasNormal_P','KelilingNormal_I']\n",
    "k6 = ['Jenis','Granularity_Inti','GranularityP', 'Luas_Inti','Keliling_Inti','RerataRP','RerataGP','RerataBP','SolidityP','EntropiP','EnergiP','KontrasP','HomogenitasP','RerataR_Inti','RerataG_Inti','RerataB_Inti', 'LIperLP ','KIperKP','LuasNormal_P','KelilingNormal_I','LuasP','KelilingP']\n",
    "k3 = ['Jenis','Granularity_Inti','GranularityP', 'Luas_Inti','Keliling_Inti','RerataRP','RerataGP','RerataBP','SolidityP','EntropiP','EnergiP','KontrasP','HomogenitasP','RerataR_Inti','RerataG_Inti','RerataB_Inti', 'LIperLP ','KIperKP','LuasNormal_P','KelilingNormal_I','LuasP','KelilingP','Circularity_Inti','CircularityP','Eccentricity']\n",
    "k5 = ['Jenis','Granularity_Inti','GranularityP', 'Luas_Inti','Keliling_Inti','RerataRP','RerataGP','RerataBP','SolidityP','EntropiP','EnergiP','KontrasP','HomogenitasP','RerataR_Inti','RerataG_Inti','RerataB_Inti', 'LIperLP ','KIperKP','LuasNormal_P','KelilingNormal_I','LuasP','KelilingP','Circularity_Inti','CircularityP','Eccentricity','Solidity_Inti','Entropi_Inti','Energi_Inti','Kontras_Inti','Homogenitas_Inti']\n",
    "\n",
    "datset = [k2, k1, k7, k8, k4, k10, k9, k6, k3, k5]'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "k7 = ['Jenis','RerataRP','RerataGP','RerataBP']\n",
    "k3 = ['Jenis','RerataRP','RerataGP','RerataBP','Circularity_Inti','CircularityP','Eccentricity']\n",
    "k5 = ['Jenis','RerataRP','RerataGP','RerataBP','Circularity_Inti','CircularityP','Eccentricity','Solidity_Inti','Entropi_Inti','Energi_Inti','Kontras_Inti','Homogenitas_Inti']\n",
    "k10 =['Jenis','RerataRP','RerataGP','RerataBP','Circularity_Inti','CircularityP','Eccentricity','Solidity_Inti','Entropi_Inti','Energi_Inti','Kontras_Inti','Homogenitas_Inti', 'LIperLP ','KIperKP']\n",
    "k8 = ['Jenis','RerataRP','RerataGP','RerataBP','Circularity_Inti','CircularityP','Eccentricity','Solidity_Inti','Entropi_Inti','Energi_Inti','Kontras_Inti','Homogenitas_Inti', 'LIperLP ','KIperKP','SolidityP','EntropiP','EnergiP','KontrasP','HomogenitasP']\n",
    "k9 = ['Jenis','RerataRP','RerataGP','RerataBP','Circularity_Inti','CircularityP','Eccentricity','Solidity_Inti','Entropi_Inti','Energi_Inti','Kontras_Inti','Homogenitas_Inti', 'LIperLP ','KIperKP','SolidityP','EntropiP','EnergiP','KontrasP','HomogenitasP','LuasNormal_P','KelilingNormal_I']\n",
    "k4 = ['Jenis','RerataRP','RerataGP','RerataBP','Circularity_Inti','CircularityP','Eccentricity','Solidity_Inti','Entropi_Inti','Energi_Inti','Kontras_Inti','Homogenitas_Inti', 'LIperLP ','KIperKP','SolidityP','EntropiP','EnergiP','KontrasP','HomogenitasP','LuasNormal_P','KelilingNormal_I','RerataR_Inti','RerataG_Inti','RerataB_Inti']\n",
    "k2 = ['Jenis','RerataRP','RerataGP','RerataBP','Circularity_Inti','CircularityP','Eccentricity','Solidity_Inti','Entropi_Inti','Energi_Inti','Kontras_Inti','Homogenitas_Inti', 'LIperLP ','KIperKP','SolidityP','EntropiP','EnergiP','KontrasP','HomogenitasP','LuasNormal_P','KelilingNormal_I','RerataR_Inti','RerataG_Inti','RerataB_Inti','Granularity_Inti','GranularityP']\n",
    "k6 = ['Jenis','RerataRP','RerataGP','RerataBP','Circularity_Inti','CircularityP','Eccentricity','Solidity_Inti','Entropi_Inti','Energi_Inti','Kontras_Inti','Homogenitas_Inti', 'LIperLP ','KIperKP','SolidityP','EntropiP','EnergiP','KontrasP','HomogenitasP','LuasNormal_P','KelilingNormal_I','RerataR_Inti','RerataG_Inti','RerataB_Inti','Granularity_Inti','GranularityP','LuasP','KelilingP']\n",
    "k1 =['Jenis','RerataRP','RerataGP','RerataBP','Circularity_Inti','CircularityP','Eccentricity','Solidity_Inti','Entropi_Inti','Energi_Inti','Kontras_Inti','Homogenitas_Inti', 'LIperLP ','KIperKP','SolidityP','EntropiP','EnergiP','KontrasP','HomogenitasP','LuasNormal_P','KelilingNormal_I','RerataR_Inti','RerataG_Inti','RerataB_Inti','Granularity_Inti','GranularityP','LuasP','KelilingP', 'Luas_Inti','Keliling_Inti']\n",
    "\n",
    "datset = [k7,k3,k5,k10,k8,k9,k4,k2,k6,k1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Latih kecerdasan buatan dengan data latih, menggunakan MLP-NN\n",
    "df = pd.read_excel('Data-20Fitur-20Citra-20Sel-20Darah.xlsx', header=0, sheet_name ='Data Fitur Citra Sel Darah2')\n",
    "df = df.drop(datset[0], axis=1)\n",
    "#df = df[datset[6]]\n",
    "print(df[0:0])\n",
    "\n",
    "import numpy as np\n",
    "y= np.array(df)[:,0]           #membuat dataset target y\n",
    "X = np.array(df)[:,1:30]    #membuat dataset input X\n",
    "\n",
    "# Pisahkan dataset menjadi data latih dan uji dengan perbandingan 80:20\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.30, random_state=0)\n",
    "\n",
    "# Penyekalaan fitur dilakukan pada data latih dan uji.\n",
    "# Detail kenapa ini penting dijelaskan di sini: http://scikit-learn.org/stable/auto_examples/preprocessing/plot_scaling_importance.html\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "\n",
    "# Fungsi fit_transform hanya dilakukan di data latih\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "i=10\n",
    "data = [ ]\n",
    "layers = [ ]\n",
    "loss = [ ]\n",
    "iterasi = [ ]\n",
    "cv_score = [ ]\n",
    "std_cv = [ ]\n",
    "while (i<75):\n",
    "    clf = MLPClassifier(activation='tanh',solver='adam', alpha=1e-5, max_iter=2000,\n",
    "                    hidden_layer_sizes=(i), random_state=1)\n",
    "    print(clf.fit(X_train, y_train))\n",
    "    if(i>=30):\n",
    "        i=i+5\n",
    "    elif(i<30):  \n",
    "        i=i+1\n",
    "\n",
    "    print('Loss Pelatihan : ', clf.loss_)    \n",
    "    print('Jumlah iterasi : ', clf.n_iter_)\n",
    "    \n",
    "    from sklearn.model_selection import cross_val_score\n",
    "    scoring='accuracy'\n",
    "    accuracies = cross_val_score(estimator=clf, X=X_train, y=y_train, cv=5,scoring=scoring)\n",
    "    avg_accuracy = float('{0:.4f}'.format(accuracies.mean()))*100\n",
    "    std_accuracy =  float('{0:.4f}'.format(accuracies.std()))*100\n",
    "    print('Akurasi: ', avg_accuracy)\n",
    "    print('SD: ', std_accuracy)\n",
    "    \n",
    "    #Prediksi Data Uji\n",
    "    result = clf.predict(X_test)\n",
    "\n",
    "    #Confusion Matriks Hasil Prediksi dengan Nilai Sebenarnya\n",
    "    from sklearn.metrics import classification_report,confusion_matrix\n",
    "    print(confusion_matrix(y_test,result))\n",
    "\n",
    "    # Cek kemampuan kecerdasan buatan dengan data uji \n",
    "    test_accuracy = clf.score(X_test, y_test)\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    akurasi = accuracy_score(y_test, result)\n",
    "    print('Akurasi Data Uji:', test_accuracy , '=', akurasi)\n",
    "\n",
    "    # Cek kemampuan kecerdasan buatan dengan data uji \n",
    "    train_accuracy = clf.score(X_train, y_train)\n",
    "    print('Akurasi Data Latih:', train_accuracy)  \n",
    "\n",
    "    layers.append(i)\n",
    "    data.append( float('{0:.4f}'.format(test_accuracy))*100)\n",
    "    loss.append(clf.loss_)\n",
    "    iterasi.append(clf.n_iter_)\n",
    "    cv_score.append(avg_accuracy)\n",
    "    std_cv.append(std_accuracy)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "summary = [ ]\n",
    "i=0\n",
    "while(i<len(layers)):\n",
    "    summary.append([layers[i],data[i],loss[i], iterasi[i], cv_score[i],std_cv[i]]) \n",
    "    i+=1\n",
    "    \n",
    "df = pd.DataFrame(np.array(summary))\n",
    "df.columns = (['neuron','akurasi','loss','iter','cv','std'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(len(layers))\n",
    "print(layers[10],data[9],loss[9], iterasi[9], cv_score[9],std_cv[9])\n",
    "i=0\n",
    "while(i<len(layers)):\n",
    "    print([layers[i],data[i],loss[i], iterasi[i], cv_score[i],std_cv[i]]) \n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_excel('Data-20Fitur-20Citra-20Sel-20Darah.xlsx', header=0,sheet_name='Data Fitur Citra Sel Darah2')\n",
    "df = df.drop(datset[0], axis=1)\n",
    "#df = df[Jenis, k1]\n",
    "print(df[0:0])\n",
    "\n",
    "import numpy as np\n",
    "y= np.array(df)[:,0]           #membuat dataset target y\n",
    "X = np.array(df)[:,1:30]    #membuat dataset input X\n",
    "\n",
    "# Pisahkan dataset menjadi data latih dan uji dengan perbandingan 80:20\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.30, random_state=0)\n",
    "\n",
    "# Penyekalaan fitur dilakukan pada data latih dan uji.\n",
    "# Detail kenapa ini penting dijelaskan di sini: http://scikit-learn.org/stable/auto_examples/preprocessing/plot_scaling_importance.html\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "\n",
    "# Fungsi fit_transform hanya dilakukan di data latih\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    " # Latih kecerdasan buatan dengan data latih, menggunakan MLP-NN\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import time\n",
    "\n",
    "clf = MLPClassifier(activation='tanh',solver='adam', alpha=1e-5, max_iter=2000,\n",
    "            hidden_layer_sizes=(28), random_state=1)\n",
    "start = time.time()\n",
    "print(clf.fit(X_train, y_train))\n",
    "end = time.time()\n",
    "waktuTrain = end - start\n",
    "'''\n",
    "from sklearn.model_selection import cross_val_score\n",
    "scoring='accuracy'\n",
    "accuracies = cross_val_score(estimator=clf, X=X_train, y=y_train, cv=10,scoring=scoring)\n",
    "avg_accuracy = float('{0:.4f}'.format(accuracies.mean()))*100\n",
    "std_accuracy =  float('{0:.4f}'.format(accuracies.std()))*100\n",
    "print('Akurasi: ', avg_accuracy)\n",
    "print('SD: ', std_accuracy)\n",
    "'''\n",
    "\n",
    "#prediksi\n",
    "start = time.time()\n",
    "result = clf.predict(X_test)\n",
    "end = time.time()\n",
    "waktuTest = end - start\n",
    "\n",
    "#Confusion Matriks Hasil Prediksi dengan Nilai Sebenarnya\n",
    "from sklearn.metrics import classification_report,confusion_matrix, roc_auc_score\n",
    "print(confusion_matrix(y_test,result))\n",
    "\n",
    "# Cek kemampuan kecerdasan buatan dengan data uji \n",
    "train_accuracy = float('{0:.4f}'.format(clf.score(X_train, y_train)))*100\n",
    "print(\"akurasi latih: \",train_accuracy)\n",
    "\n",
    "# Cek kemampuan kecerdasan buatan dengan data uji \n",
    "test_accuracy = float('{0:.4f}'.format(clf.score(X_test, y_test)))*100\n",
    "print(\"akurasi uji: \",test_accuracy)\n",
    "\n",
    "\n",
    "print()\n",
    "\n",
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(y_test, result)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "class_names = ['Basofil', 'Eosinofil','Netrofil','Monosit','Limfosit']\n",
    "\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names,\n",
    "                      title='Confusion matrix')\n",
    "\n",
    "from sklearn.metrics import classification_report,confusion_matrix, roc_auc_score\n",
    "print(classification_report(y_test,result, target_names=['basofil','eosinofil','netrofil','monosit', 'limfosit']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
